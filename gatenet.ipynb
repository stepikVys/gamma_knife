{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1amt2nUo3DFm7PNSd9L9PQ1sKZBK8PDKd?usp=sharing"
      ],
      "metadata": {
        "id": "qFcmooGAU8Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sympy\n",
        "# AttributeError: module 'sympy' has no attribute 'printing'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc4fo0E1BbL2",
        "outputId": "bfd9e598-6bb4-49fd-9421-190d6145db53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.14.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PGbIRFj0Oar",
        "outputId": "f52c1fa4-1db6-486d-f29f-110b0b1657d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm, colors\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score,\n",
        "                            f1_score, precision_score, recall_score, balanced_accuracy_score,\n",
        "                            roc_auc_score)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import catboost"
      ],
      "metadata": {
        "id": "1maZ_25s0rm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert to one-hot vectors\n",
        "def convert_to_one_hot(vector, num_classes=None):\n",
        "    \"\"\"\n",
        "    Converts an input 1-D vector of integers into an output\n",
        "    2-D array of one-hot vectors.\n",
        "    \"\"\"\n",
        "    assert isinstance(vector, np.ndarray)\n",
        "    assert len(vector) > 0\n",
        "\n",
        "    if num_classes is None:\n",
        "        num_classes = np.max(vector) + 1\n",
        "    else:\n",
        "        assert num_classes > 0\n",
        "        assert num_classes >= np.max(vector)\n",
        "\n",
        "    result = np.zeros(shape=(len(vector), num_classes))\n",
        "    result[np.arange(len(vector)), vector] = 1\n",
        "    return result.astype(int)"
      ],
      "metadata": {
        "id": "XHOMdT_vz4nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_categorical(y, num_classes=None):\n",
        "    \"\"\"Convert class vector to one-hot matrix.\"\"\"\n",
        "    y = np.array(y, dtype='int')\n",
        "    input_shape = y.shape\n",
        "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
        "        input_shape = tuple(input_shape[:-1])\n",
        "    y = y.ravel()\n",
        "    if not num_classes:\n",
        "        num_classes = np.max(y) + 1\n",
        "    n = y.shape[0]\n",
        "    categorical = np.zeros((n, num_classes), dtype=np.float32)\n",
        "    categorical[np.arange(n), y] = 1\n",
        "    return categorical"
      ],
      "metadata": {
        "id": "WkKxFu9zz934"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class for LSPIN\n",
        "class LSPINDataset(Dataset):\n",
        "    def __init__(self, data, labels, meta):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.labels = torch.FloatTensor(labels)\n",
        "        self.meta = torch.FloatTensor(meta)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx], self.meta[idx]"
      ],
      "metadata": {
        "id": "9ZAtw1bO0A2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate squared distance matrix\n",
        "def squared_distance(X):\n",
        "    \"\"\"\n",
        "    Calculates the squared Euclidean distance matrix.\n",
        "    X: an n-by-p tensor, which includes n samples in dimension p\n",
        "    returns: n x n pairwise squared Euclidean distance matrix\n",
        "    \"\"\"\n",
        "    r = torch.sum(X * X, 1, keepdim=True)\n",
        "    D = r - 2 * torch.mm(X, X.t()) + r.t()\n",
        "    return D"
      ],
      "metadata": {
        "id": "oEaBdAnV0Fvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gating Network\n",
        "class GatingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, activation='tanh', stddev=0.1):\n",
        "        super(GatingNetwork, self).__init__()\n",
        "\n",
        "        self.activation_name = activation\n",
        "        if activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'l_relu':\n",
        "            self.activation = nn.LeakyReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        else:  # 'none'\n",
        "            self.activation = nn.Identity()\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        # Hidden layers\n",
        "        for hidden_dim in hidden_layers:\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(self.activation)\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(prev_dim, input_dim))\n",
        "        layers.append(self.activation)\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=stddev)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "# Prediction Network\n",
        "class PredictionNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim, activation='relu', batch_norm=False, stddev=0.1):\n",
        "        super(PredictionNetwork, self).__init__()\n",
        "\n",
        "        self.batch_norm = batch_norm\n",
        "        self.activation_name = activation\n",
        "\n",
        "        if activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 'l_relu':\n",
        "            self.activation = nn.LeakyReLU()\n",
        "        elif activation == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif activation == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        else:  # 'none'\n",
        "            self.activation = nn.Identity()\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        # Hidden layers\n",
        "        for i, hidden_dim in enumerate(hidden_layers):\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            if batch_norm:\n",
        "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            layers.append(self.activation)\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        # Output layer\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(prev_dim, output_dim)\n",
        "\n",
        "        # Initialize weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=stddev)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "\n",
        "# LSPIN Model\n",
        "class LSPINModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_node,\n",
        "                 hidden_layers_node,\n",
        "                 output_node,\n",
        "                 gating_net_hidden_layers_node,\n",
        "                 activation_gating='tanh',\n",
        "                 activation_pred='relu',\n",
        "                 feature_selection=True,\n",
        "                 batch_normalization=False,\n",
        "                 a=1,\n",
        "                 sigma=0.5,\n",
        "                 lam=0.5,\n",
        "                 gamma1=0,\n",
        "                 gamma2=0,\n",
        "                 stddev_input=0.1,\n",
        "                 stddev_input_gates=0.1):\n",
        "        super(LSPINModel, self).__init__()\n",
        "\n",
        "        # Register hyperparameters\n",
        "        self.a = a\n",
        "        self.sigma = sigma\n",
        "        self.lam = lam\n",
        "        self.gamma1 = gamma1\n",
        "        self.gamma2 = gamma2\n",
        "        self.feature_selection = feature_selection\n",
        "        self.output_node = output_node\n",
        "\n",
        "        # Create networks\n",
        "        if feature_selection:\n",
        "            self.gating_network = GatingNetwork(\n",
        "                input_dim=input_node,\n",
        "                hidden_layers=gating_net_hidden_layers_node,\n",
        "                activation=activation_gating,\n",
        "                stddev=stddev_input_gates\n",
        "            )\n",
        "\n",
        "        self.prediction_network = PredictionNetwork(\n",
        "            input_dim=input_node,\n",
        "            hidden_layers=hidden_layers_node,\n",
        "            output_dim=output_node,\n",
        "            activation=activation_pred,\n",
        "            batch_norm=batch_normalization,\n",
        "            stddev=stddev_input\n",
        "        )\n",
        "\n",
        "    def hard_sigmoid(self, x, a):\n",
        "        \"\"\"Segment-wise linear approximation of sigmoid.\"\"\"\n",
        "        x = a * x + 0.5\n",
        "        return torch.clamp(x, min=0, max=1)\n",
        "\n",
        "    def get_stochastic_gate(self, x, train_gates=True):\n",
        "        \"\"\"Compute the stochastic gates.\"\"\"\n",
        "        alpha = self.gating_network(x)\n",
        "\n",
        "        if train_gates and self.training:\n",
        "            # Gaussian reparametrization\n",
        "            noise = torch.randn_like(x) * self.sigma\n",
        "            z = alpha + noise\n",
        "        else:\n",
        "            z = alpha\n",
        "\n",
        "        stochastic_gate = self.hard_sigmoid(z, self.a)\n",
        "        return stochastic_gate, alpha\n",
        "\n",
        "    def forward(self, x, compute_sim=False, train_gates=True, meta=None):\n",
        "        if self.feature_selection:\n",
        "            stochastic_gate, self.alpha = self.get_stochastic_gate(x, train_gates)\n",
        "            x_masked = x * stochastic_gate\n",
        "            self.stochastic_gates = stochastic_gate\n",
        "        else:\n",
        "            x_masked = x\n",
        "            self.alpha = None\n",
        "            self.stochastic_gates = None\n",
        "\n",
        "        # Prediction network\n",
        "        logits = self.prediction_network(x_masked)\n",
        "\n",
        "        if self.output_node == 1:\n",
        "            # Regression\n",
        "            prediction = logits\n",
        "        else:\n",
        "            # Classification\n",
        "            prediction = F.softmax(logits, dim=1)\n",
        "\n",
        "        return prediction, logits\n",
        "\n",
        "    def get_raw_alpha(self, x):\n",
        "        \"\"\"Get raw alpha values (before activation).\"\"\"\n",
        "        if self.feature_selection:\n",
        "            with torch.no_grad():\n",
        "                self.eval()\n",
        "                alpha = self.gating_network(x)\n",
        "                return alpha.detach().cpu().numpy()\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_prob_alpha(self, x):\n",
        "        \"\"\"Get probability values for gates.\"\"\"\n",
        "        if self.feature_selection:\n",
        "            alpha = self.get_raw_alpha(x)\n",
        "            return self.compute_learned_prob(alpha)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def compute_learned_prob(self, alpha):\n",
        "        \"\"\"Convert raw alpha to probabilities.\"\"\"\n",
        "        return np.minimum(1, np.maximum(0, self.a * alpha + 0.5))\n",
        "\n",
        "\n",
        "# Loss function for LSPIN\n",
        "class LSPINLoss(nn.Module):\n",
        "    def __init__(self, lam=0.5, gamma1=0, gamma2=0, output_node=2):\n",
        "        super(LSPINLoss, self).__init__()\n",
        "        self.lam = lam\n",
        "        self.gamma1 = gamma1\n",
        "        self.gamma2 = gamma2\n",
        "        self.output_node = output_node\n",
        "\n",
        "    def forward(self, pred, y, alpha, stochastic_gates, Z=None, compute_sim=False):\n",
        "        # Main prediction loss\n",
        "        if self.output_node == 1:\n",
        "            loss_fun = F.mse_loss(pred, y)\n",
        "        else:\n",
        "            loss_fun = F.cross_entropy(pred, torch.argmax(y, dim=1))\n",
        "\n",
        "        # L0 regularization for gates\n",
        "        if alpha is not None:\n",
        "            # Probability of a gate being non-zero\n",
        "            prob_nonzero = torch.sigmoid(alpha)\n",
        "            reg_gates = self.lam * prob_nonzero.mean()\n",
        "\n",
        "            # Similarity regularization\n",
        "            if compute_sim and Z is not None:\n",
        "                # Similarity matrix based on Z\n",
        "                K_batch = 1.0 - squared_distance(Z) / 2.0\n",
        "                # Distance matrix of gates\n",
        "                D_batch = squared_distance(stochastic_gates)\n",
        "\n",
        "                # Encourage similar samples to select similar features\n",
        "                sim_term = self.gamma1 * torch.mean(K_batch * D_batch)\n",
        "                # Encourage dissimilar samples to select dissimilar features\n",
        "                dissim_term = self.gamma2 * torch.mean((1.0 - K_batch) * (-D_batch))\n",
        "\n",
        "                reg_sim = sim_term + dissim_term\n",
        "            else:\n",
        "                reg_sim = torch.tensor(0.0, device=pred.device)\n",
        "\n",
        "            total_loss = loss_fun + reg_gates + reg_sim\n",
        "            return total_loss, loss_fun, reg_gates, reg_sim\n",
        "        else:\n",
        "            return loss_fun, loss_fun, torch.tensor(0.0), torch.tensor(0.0)\n",
        "\n",
        "\n",
        "class LocallySparse:\n",
        "    \"\"\"\n",
        "    Uses the LSPIN model for classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, n_classes):\n",
        "        \"\"\"\n",
        "        Initialize the LocallySparse model.\n",
        "\n",
        "        Args:\n",
        "            data: raw dataframe of data\n",
        "            n_classes: number of classes in the dataset\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.n_classes = n_classes\n",
        "        self.model = None\n",
        "        self.best_model = None\n",
        "        self.model_params = {}\n",
        "        self.training_params = {}\n",
        "        self.class_names = {}\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.trial_logs = []\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Preprocess data\n",
        "        self.x_train, self.y_train, self.x_val, self.y_val, self.x_test, self.y_test = self._preprocess_data()\n",
        "\n",
        "    def _preprocess_data(self):\n",
        "        \"\"\"Preprocess data for model training.\"\"\"\n",
        "        db = self.data.dropna(axis=1, how='all')\n",
        "        db = db.dropna(axis=0)\n",
        "\n",
        "        db['Прогрессия'] = pd.Categorical(db['Прогрессия'])\n",
        "        self.class_names = dict(enumerate(db['Прогрессия'].cat.categories))\n",
        "        db['Прогрессия'] = db['Прогрессия'].cat.codes\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        y = db.pop('Прогрессия')\n",
        "        y = y.values.astype(np.float32)\n",
        "        y = to_categorical(y, num_classes=self.n_classes)\n",
        "\n",
        "        x = db.values.astype(np.float32)\n",
        "\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=1)\n",
        "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.8, random_state=1)\n",
        "\n",
        "        return (np.array(x_train), np.array(y_train),\n",
        "                np.array(x_val), np.array(y_val),\n",
        "                np.array(x_test), np.array(y_test))\n",
        "\n",
        "    def _create_data_loaders(self, batch_size):\n",
        "        \"\"\"Create PyTorch DataLoaders for training.\"\"\"\n",
        "        train_dataset = LSPINDataset(self.x_train, self.y_train, self.y_train)\n",
        "        val_dataset = LSPINDataset(self.x_val, self.y_val, self.y_val)\n",
        "        test_dataset = LSPINDataset(self.x_test, self.y_test, self.y_test)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
        "\n",
        "        return train_loader, val_loader, test_loader\n",
        "\n",
        "    def create_model(self, feature_selection):\n",
        "        \"\"\"Initialize model parameters.\"\"\"\n",
        "        self.model_params = {\n",
        "            \"input_node\": self.x_train.shape[1],\n",
        "            \"output_node\": self.n_classes,\n",
        "            \"feature_selection\": feature_selection,\n",
        "            \"activation_gating\": 'tanh'\n",
        "        }\n",
        "        self.training_params = {'batch_size': min(self.x_train.shape[0], 32)}\n",
        "\n",
        "    def train_model(self, model, optimizer, criterion, train_loader, val_loader, epochs, compute_sim=False):\n",
        "        \"\"\"Train the model.\"\"\"\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        val_accuracies = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            epoch_loss = 0\n",
        "\n",
        "            for x_batch, y_batch, z_batch in train_loader:\n",
        "                x_batch, y_batch, z_batch = x_batch.to(self.device), y_batch.to(self.device), z_batch.to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                predictions, logits = model(x_batch, compute_sim=compute_sim, meta=z_batch)\n",
        "\n",
        "                # Compute loss\n",
        "                loss, _, _, _ = criterion(logits, y_batch, model.alpha, model.stochastic_gates,\n",
        "                                        Z=z_batch, compute_sim=compute_sim)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            train_losses.append(epoch_loss / len(train_loader))\n",
        "\n",
        "            # Validation\n",
        "            if (epoch + 1) % 100 == 0: # display step\n",
        "                val_loss, val_acc, _, _, _,_ = self.evaluate(model, criterion, val_loader, compute_sim)\n",
        "                val_losses.append(val_loss)\n",
        "                val_accuracies.append(val_acc)\n",
        "\n",
        "                print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.6f}, \"\n",
        "                      f\"Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.6f}\")\n",
        "\n",
        "        return train_losses, val_losses, val_accuracies\n",
        "\n",
        "    def evaluate(self, model, criterion, data_loader, compute_sim=False):\n",
        "        \"\"\"Evaluate the model.\"\"\"\n",
        "        model.eval()\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_batch, y_batch, z_batch in data_loader:\n",
        "                x_batch, y_batch, z_batch = x_batch.to(self.device), y_batch.to(self.device), z_batch.to(self.device)\n",
        "\n",
        "                predictions, logits = model(x_batch, compute_sim=False, train_gates=False)\n",
        "                loss, _, _, _ = criterion(logits, y_batch, model.alpha, model.stochastic_gates)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                if self.n_classes > 1:  # Classification\n",
        "                    preds = torch.argmax(predictions, dim=1).cpu().numpy()\n",
        "                    targets = torch.argmax(y_batch, dim=1).cpu().numpy()\n",
        "                else:  # Regression\n",
        "                    preds = predictions.cpu().numpy()\n",
        "                    targets = y_batch.cpu().numpy()\n",
        "\n",
        "                all_preds.extend(preds)\n",
        "                all_targets.extend(targets)\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "\n",
        "        if self.n_classes > 1:  # Classification\n",
        "            matrix = confusion_matrix(all_targets, all_preds)\n",
        "            accuracy = accuracy_score(all_targets, all_preds)\n",
        "            f1 = f1_score(all_targets, all_preds, average='weighted')\n",
        "            precision = precision_score(all_targets, all_preds, average='weighted')\n",
        "            recall = recall_score(all_targets, all_preds, average='weighted')\n",
        "\n",
        "            return avg_loss, accuracy, matrix, f1, precision, recall\n",
        "\n",
        "    def __objective(self, trial):\n",
        "        \"\"\"Objective function for Optuna optimization.\"\"\"\n",
        "        # Define hyperparameters to optimize\n",
        "        self.model_params['hidden_layers_node'] = trial.suggest_categorical(\n",
        "            \"hidden_layers_node\",\n",
        "            [[70, 20], [50, 10], [40, 20, 10], [100, 20], [50, 20, 10], [10, 10, 10], [10, 5]]\n",
        "        )\n",
        "        self.model_params['gating_net_hidden_layers_node'] = trial.suggest_categorical(\n",
        "            \"gating_net_hidden_layers_node\",\n",
        "            [[4, 4], [2, 2], [8], [20, 10], [2, 2, 2], [8, 2]]\n",
        "        )\n",
        "        self.model_params['activation_pred'] = trial.suggest_categorical(\n",
        "            \"activation_pred\",\n",
        "            ['relu', 'l_relu', 'sigmoid', 'tanh']\n",
        "        )\n",
        "        self.model_params['lam'] = trial.suggest_loguniform('lam', 0.005, 0.01)\n",
        "\n",
        "        lr = trial.suggest_loguniform('learning_rate', 0.00005, 0.01)\n",
        "        num_epochs = trial.suggest_categorical('num_epoch', [200, 500, 1000, 1500, 2000])\n",
        "\n",
        "        # Create model\n",
        "        model = LSPINModel(**self.model_params).to(self.device)\n",
        "\n",
        "        print(self.model_params)\n",
        "\n",
        "        # Define loss and optimizer\n",
        "        criterion = LSPINLoss(\n",
        "            lam=self.model_params['lam'],\n",
        "            gamma1=0,\n",
        "            gamma2=0,\n",
        "            output_node=self.model_params['output_node']\n",
        "        )\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader, val_loader, test_loader = self._create_data_loaders(\n",
        "            batch_size=self.training_params['batch_size']\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        train_losses, val_losses, val_accuracies = self.train_model(\n",
        "            model, optimizer, criterion, train_loader, val_loader,\n",
        "            epochs=num_epochs, compute_sim=False\n",
        "        )\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_loss, test_acc, test_matrix, test_f1, test_precision, test_recall = self.evaluate(model, criterion, test_loader)\n",
        "        print(f'Test Loss: {test_loss}', f'Test Accuracy: {test_acc}')\n",
        "        print(f'weighted: Test F1: {test_loss}', f'Test Precision: {test_acc}', f'Test Recall: {test_acc}')\n",
        "        print(test_matrix)\n",
        "\n",
        "        trial_data = {\n",
        "            'trial': trial.number,\n",
        "            'train_losses': train_losses,\n",
        "            'val_accuracies': val_accuracies,\n",
        "            'val_losses': val_losses,\n",
        "            'test_acc': test_acc,\n",
        "            'test_loss': test_loss,\n",
        "            'params': {\n",
        "                'hidden_layers_node': self.model_params['hidden_layers_node'],\n",
        "                'gating_net_hidden_layers_node': self.model_params['gating_net_hidden_layers_node'],\n",
        "                'activation_pred': self.model_params['activation_pred'],\n",
        "                'lam': self.model_params['lam'],\n",
        "                'learning_rate': lr,\n",
        "                'num_epoch': num_epochs}}\n",
        "\n",
        "        self.trial_logs.append(trial_data)\n",
        "        print(f'[Trial {trial.number}] Test acc: {test_acc}, Best val acc: {max(val_accuracies) if val_accuracies else None}')\n",
        "        print('---')\n",
        "        # Save model if it's the best so far\n",
        "        if self.best_model is None or test_acc > self.best_acc:\n",
        "            self.best_model = model\n",
        "            self.best_acc = test_acc\n",
        "\n",
        "        return test_acc\n",
        "\n",
        "    def optimize(self, n_trials, n_jobs=1):\n",
        "        \"\"\"Optimize hyperparameters using Optuna.\"\"\"\n",
        "        self.best_acc = 0\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(self.__objective, n_trials=n_trials, n_jobs=n_jobs)\n",
        "\n",
        "        # Get best parameters\n",
        "        best_params = study.best_params\n",
        "        print(\"Best parameters:\", best_params)\n",
        "\n",
        "        # Create data loaders\n",
        "        _, _, test_loader = self._create_data_loaders(\n",
        "            batch_size=len(self.x_test)\n",
        "        )\n",
        "\n",
        "        # Evaluate best model\n",
        "        criterion = LSPINLoss(\n",
        "            lam=best_params['lam'],\n",
        "            gamma1=0,\n",
        "            gamma2=0,\n",
        "            output_node=self.model_params['output_node']\n",
        "        )\n",
        "\n",
        "        test_loss, test_acc = self.evaluate(self.best_model, criterion, test_loader)\n",
        "\n",
        "        # Test predictions for metrics\n",
        "        self.best_model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_test_tensor = torch.FloatTensor(self.x_test).to(self.device)\n",
        "            predictions, _ = self.best_model(x_test_tensor, train_gates=False)\n",
        "            if self.n_classes > 1:\n",
        "                y_pred = torch.argmax(predictions, dim=1).cpu().numpy()\n",
        "                y_true = np.argmax(self.y_test, axis=1)\n",
        "            else:\n",
        "                y_pred = predictions.cpu().numpy()\n",
        "                y_true = self.y_test\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "        precision = precision_score(y_true, y_pred, average='weighted')\n",
        "        recall = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        print(\"Trial Finished*************\")\n",
        "        print(f\"Best model's prediction architecture: {best_params['hidden_layers_node']}\")\n",
        "        print(f\"Best model's gating architecture: {best_params['gating_net_hidden_layers_node']}\")\n",
        "        print(f\"Best model's prediction activation function: {best_params['activation_pred']}\")\n",
        "        print(f\"Best model's lambda: {best_params['lam']}\")\n",
        "        print(f\"Best model's learning rate: {best_params['learning_rate']}\")\n",
        "        print(f\"Best model's num of epochs: {best_params['num_epoch']}\")\n",
        "        print(f\"Test accuracy: {accuracy}\")\n",
        "        print(f\"Test F1: {f1}\")\n",
        "        print(f\"Test precision: {precision}\")\n",
        "        print(f\"Test recall: {recall}\")\n",
        "\n",
        "        # Save results\n",
        "        results_path = \"results\"\n",
        "        os.makedirs(results_path, exist_ok=True)\n",
        "        with open(os.path.join(results_path, 'hyperparameters.txt'), \"w\") as file:\n",
        "            file.write(\n",
        "                f\"prediction architecture: {best_params['hidden_layers_node']}\\n\"\n",
        "                f\"gating architecture: {best_params['gating_net_hidden_layers_node']}\\n\"\n",
        "                f\"prediction activation function: {best_params['activation_pred']}\\n\"\n",
        "                f\"lambda: {best_params['lam']}\\n\"\n",
        "                f\"learning rate: {best_params['learning_rate']}\\n\"\n",
        "                f\"number of epochs: {best_params['num_epoch']}\\n\"\n",
        "                f\"Accuracy: {accuracy}\\n\"\n",
        "                f\"F1: {f1}\\n\"\n",
        "                f\"precision: {precision}\\n\"\n",
        "                f\"recall: {recall}\\n\"\n",
        "            )\n",
        "\n",
        "    def get_results(self):\n",
        "        \"\"\"Plot the gate feature selection for each label and confusion matrix.\"\"\"\n",
        "        results_path = \"results\"\n",
        "        os.makedirs(results_path, exist_ok=True)\n",
        "\n",
        "        # Get model predictions\n",
        "        self.best_model.eval()\n",
        "        with torch.no_grad():\n",
        "            x_test_tensor = torch.FloatTensor(self.x_test).to(self.device)\n",
        "            predictions, _ = self.best_model(x_test_tensor, train_gates=False)\n",
        "            if self.n_classes > 1:\n",
        "                y_pred = torch.argmax(predictions, dim=1).cpu().numpy()\n",
        "                y_true = np.argmax(self.y_test, axis=1)\n",
        "            else:\n",
        "                y_pred = predictions.cpu().numpy()\n",
        "                y_true = self.y_test\n",
        "\n",
        "        # Plot gate feature selection matrices\n",
        "        test_labels = np.argmax(self.y_test, axis=1)\n",
        "        gate_matrix = []\n",
        "\n",
        "        for i in range(self.n_classes):\n",
        "            label_indices = np.where(test_labels == i)[0]\n",
        "            if len(label_indices) > 0:\n",
        "                label_data = self.x_test[label_indices]\n",
        "\n",
        "                # Get gate probabilities for this class\n",
        "                gate_probs = self.best_model.get_prob_alpha(torch.FloatTensor(label_data).to(self.device))\n",
        "                gate_matrix.append(gate_probs)\n",
        "\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                sns.clustermap(gate_probs, vmin=0, vmax=1, cbar_pos=None)\n",
        "                plt.xlabel('Features')\n",
        "                plt.ylabel('Samples')\n",
        "                plt.subplots_adjust(top=0.95, bottom=0.1, right=0.9)\n",
        "                plt.suptitle(f\"Label: {self.class_names[i]}\", fontsize=16)\n",
        "                plt.savefig(os.path.join(results_path, f\"gate_matrix_{self.class_names[i]}.png\"))\n",
        "                plt.close()\n",
        "\n",
        "        # Create color bar for reference\n",
        "        plt.figure(figsize=(2, 4))\n",
        "        sns.clustermap(np.array([[0, 0], [0, 0]]), vmin=0, vmax=1, cbar_pos=(.01, .2, .03, .4))\n",
        "        plt.savefig(os.path.join(results_path, \"cbar.png\"))\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        def reverse_labels(tup):\n",
        "            \"\"\"Convert numerical labels to named labels.\"\"\"\n",
        "            return [self.class_names[x] for x in tup]\n",
        "\n",
        "        y_true_labeled, y_pred_labeled = reverse_labels(tuple(y_true)), reverse_labels(tuple(y_pred))\n",
        "        matrix = confusion_matrix(y_true_labeled, y_pred_labeled)\n",
        "        df_cm = pd.DataFrame(matrix, columns=np.unique(y_true_labeled), index=np.unique(y_true_labeled))\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        cmap = sns.cubehelix_palette(light=0.9, as_cmap=True)\n",
        "        cm_normalized = df_cm.div(df_cm.sum(axis=0), axis=1)\n",
        "        sns.heatmap(cm_normalized, cbar=False, annot=True, cmap=cmap, square=True, fmt='.1%', annot_kws={'size': 10})\n",
        "        plt.title('LSPIN Classification')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(results_path, \"lspin_results.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"Save the best model.\"\"\"\n",
        "        results_path = \"results\"\n",
        "        os.makedirs(results_path, exist_ok=True)\n",
        "        torch.save(self.best_model.state_dict(), os.path.join(results_path, 'model.pth'))\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        \"\"\"Load a saved model.\"\"\"\n",
        "        model = LSPINModel(**self.model_params).to(self.device)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "        self.best_model = model\n",
        "        return model"
      ],
      "metadata": {
        "id": "XDU5Uezj_BfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "print = functools.partial(print, flush=True)"
      ],
      "metadata": {
        "id": "EVhBJUs6S9GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X = pd.read_pickle('https://raw.githubusercontent.com/stepikVys/gamma_knife/refs/heads/main/features_dataset_normalized.pkl')\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X.drop(columns='Прогрессия'), X['Прогрессия'])\n",
        "X_test = pd.read_pickle('https://raw.githubusercontent.com/stepikVys/gamma_knife/refs/heads/main/test_dataset_normalized.pkl')"
      ],
      "metadata": {
        "id": "edWDgNnw0zMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_norm = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
        "data_norm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eQve-Nod7QNb",
        "outputId": "77b5f5ba-70b3-4f5c-bf4c-85797b7d4f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Число очагов  Объем очагов  Число фракций  Индекс Карновского  ОВГМ  \\\n",
              "0        0.047619      0.177158            0.0            0.833333     1   \n",
              "1        0.380952      0.010791            0.0            0.833333     0   \n",
              "2        0.095238      0.112410            0.0            0.833333     0   \n",
              "3        0.047619      0.049685            0.6            0.833333     0   \n",
              "4        0.666667      0.216052            0.0            0.333333     0   \n",
              "..            ...           ...            ...                 ...   ...   \n",
              "731      0.002905      0.056477            0.0            0.676833     0   \n",
              "732      0.045841      0.061195            0.0            0.827109     0   \n",
              "733      0.156686      0.228403            0.0            0.666667     0   \n",
              "734      0.085760      0.232430            0.0            0.666667     0   \n",
              "735      0.000000      0.204782            0.0            0.500000     0   \n",
              "\n",
              "     Операция   Возраст  Время метастазирования  Время реагирования  КРР  \\\n",
              "0           0  0.421053                1.164881           -0.005626    0   \n",
              "1           0  0.842105                1.143593            0.099859    0   \n",
              "2           0  0.877193                1.000000            0.057665    0   \n",
              "3           1  0.771930                0.712676           -0.015471    0   \n",
              "4           0  0.508772                0.724363            0.019691    0   \n",
              "..        ...       ...                     ...                 ...  ...   \n",
              "731         0  0.490158                0.211182            0.088418    0   \n",
              "732         0  0.414648                0.057650            0.011853    0   \n",
              "733         0  0.583189                0.229784            0.000521    0   \n",
              "734         0  0.611957                0.150926            0.008499    0   \n",
              "735         0  0.614324                0.092412            0.047708    0   \n",
              "\n",
              "     Меланома  НМРЛ  РМЖ  РП  Таргетная терапия  Химиотерапия  Без лечения  \\\n",
              "0           0     0    1   0                  0             0            0   \n",
              "1           0     0    1   0                  0             1            0   \n",
              "2           0     0    0   1                  1             0            0   \n",
              "3           0     0    0   1                  0             0            0   \n",
              "4           0     0    0   1                  0             0            0   \n",
              "..        ...   ...  ...  ..                ...           ...          ...   \n",
              "731         0     0    1   0                  0             0            0   \n",
              "732         0     1    0   0                  0             1            0   \n",
              "733         0     0    1   0                  1             0            0   \n",
              "734         0     1    0   0                  0             1            0   \n",
              "735         1     0    0   0                  0             0            0   \n",
              "\n",
              "     Мужчина  Прогрессия  \n",
              "0          0           1  \n",
              "1          0           1  \n",
              "2          1           1  \n",
              "3          0           1  \n",
              "4          1           1  \n",
              "..       ...         ...  \n",
              "731        0           0  \n",
              "732        1           0  \n",
              "733        0           0  \n",
              "734        0           0  \n",
              "735        1           0  \n",
              "\n",
              "[736 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f715d5e-745f-461d-b597-592bdd54d89f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Число очагов</th>\n",
              "      <th>Объем очагов</th>\n",
              "      <th>Число фракций</th>\n",
              "      <th>Индекс Карновского</th>\n",
              "      <th>ОВГМ</th>\n",
              "      <th>Операция</th>\n",
              "      <th>Возраст</th>\n",
              "      <th>Время метастазирования</th>\n",
              "      <th>Время реагирования</th>\n",
              "      <th>КРР</th>\n",
              "      <th>Меланома</th>\n",
              "      <th>НМРЛ</th>\n",
              "      <th>РМЖ</th>\n",
              "      <th>РП</th>\n",
              "      <th>Таргетная терапия</th>\n",
              "      <th>Химиотерапия</th>\n",
              "      <th>Без лечения</th>\n",
              "      <th>Мужчина</th>\n",
              "      <th>Прогрессия</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.177158</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>1.164881</td>\n",
              "      <td>-0.005626</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.010791</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>1.143593</td>\n",
              "      <td>0.099859</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.112410</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.877193</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.057665</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.049685</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.771930</td>\n",
              "      <td>0.712676</td>\n",
              "      <td>-0.015471</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.216052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.508772</td>\n",
              "      <td>0.724363</td>\n",
              "      <td>0.019691</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>0.002905</td>\n",
              "      <td>0.056477</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.676833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.490158</td>\n",
              "      <td>0.211182</td>\n",
              "      <td>0.088418</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>0.045841</td>\n",
              "      <td>0.061195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.827109</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.414648</td>\n",
              "      <td>0.057650</td>\n",
              "      <td>0.011853</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>0.156686</td>\n",
              "      <td>0.228403</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.583189</td>\n",
              "      <td>0.229784</td>\n",
              "      <td>0.000521</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>0.085760</td>\n",
              "      <td>0.232430</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.611957</td>\n",
              "      <td>0.150926</td>\n",
              "      <td>0.008499</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.204782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.614324</td>\n",
              "      <td>0.092412</td>\n",
              "      <td>0.047708</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>736 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f715d5e-745f-461d-b597-592bdd54d89f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f715d5e-745f-461d-b597-592bdd54d89f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f715d5e-745f-461d-b597-592bdd54d89f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee23185f-16ca-40f6-a19f-d4b683b7f4ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee23185f-16ca-40f6-a19f-d4b683b7f4ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee23185f-16ca-40f6-a19f-d4b683b7f4ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_norm",
              "summary": "{\n  \"name\": \"data_norm\",\n  \"rows\": 736,\n  \"fields\": [\n    {\n      \"column\": \"\\u0427\\u0438\\u0441\\u043b\\u043e \\u043e\\u0447\\u0430\\u0433\\u043e\\u0432\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2083021908948819,\n        \"min\": 0.0,\n        \"max\": 1.6666666666666667,\n        \"num_unique_values\": 162,\n        \"samples\": [\n          0.0029047857084808977,\n          0.10497109033118207,\n          0.11093315298214045\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041e\\u0431\\u044a\\u0435\\u043c \\u043e\\u0447\\u0430\\u0433\\u043e\\u0432\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15126013689011453,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 634,\n        \"samples\": [\n          0.11915467625899279,\n          0.1555755395683453,\n          0.09757194244604316\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0427\\u0438\\u0441\\u043b\\u043e \\u0444\\u0440\\u0430\\u043a\\u0446\\u0438\\u0439\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14088621290095021,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.18317200700099023,\n          0.6,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0418\\u043d\\u0434\\u0435\\u043a\\u0441 \\u041a\\u0430\\u0440\\u043d\\u043e\\u0432\\u0441\\u043a\\u043e\\u0433\\u043e\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14237432780286086,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          0.5853488430498801,\n          1.0,\n          0.5429902712858593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041e\\u0412\\u0413\\u041c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041e\\u043f\\u0435\\u0440\\u0430\\u0446\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0412\\u043e\\u0437\\u0440\\u0430\\u0441\\u0442\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19425401963182487,\n        \"min\": 0.0,\n        \"max\": 1.0175438596491229,\n        \"num_unique_values\": 236,\n        \"samples\": [\n          0.5337949179539293,\n          0.7480035047525005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0412\\u0440\\u0435\\u043c\\u044f \\u043c\\u0435\\u0442\\u0430\\u0441\\u0442\\u0430\\u0437\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17203163832680185,\n        \"min\": 0.0,\n        \"max\": 1.1648810352024488,\n        \"num_unique_values\": 547,\n        \"samples\": [\n          0.13134826770557953,\n          0.440517601224433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0412\\u0440\\u0435\\u043c\\u044f \\u0440\\u0435\\u0430\\u0433\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3027639126573494,\n        \"min\": -0.015471167369901548,\n        \"max\": 2.9915611814345993,\n        \"num_unique_values\": 387,\n        \"samples\": [\n          0.017776943009917466,\n          0.10829817158931083\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041a\\u0420\\u0420\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041c\\u0435\\u043b\\u0430\\u043d\\u043e\\u043c\\u0430\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041d\\u041c\\u0420\\u041b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0420\\u041c\\u0416\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0420\\u041f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0422\\u0430\\u0440\\u0433\\u0435\\u0442\\u043d\\u0430\\u044f \\u0442\\u0435\\u0440\\u0430\\u043f\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0425\\u0438\\u043c\\u0438\\u043e\\u0442\\u0435\\u0440\\u0430\\u043f\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0411\\u0435\\u0437 \\u043b\\u0435\\u0447\\u0435\\u043d\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041c\\u0443\\u0436\\u0447\\u0438\\u043d\\u0430\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041f\\u0440\\u043e\\u0433\\u0440\\u0435\\u0441\\u0441\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "def get_device():\n",
        "    \"\"\"\n",
        "    Determines which device to use (GPU/CPU).\n",
        "    :return: PyTorch device\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "        return torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        print(\"No GPU available, using CPU\")\n",
        "        return torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "cyBfz29d7nHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_device()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17WINJ757p0x",
        "outputId": "b6b7a438-d472-4676-dcc3-662f3b014813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: Tesla T4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)     # игнорировать UserWarning\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "3aHpagEBCh3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the locally sparse model\n",
        "device = get_device()\n",
        "\n",
        "# Initialize the model\n",
        "clf = LocallySparse(data=data_norm, n_classes=2)\n",
        "\n",
        "# Set up model parameters\n",
        "clf.create_model(feature_selection=True)\n",
        "\n",
        "# Optimize model hyperparameters\n",
        "clf.optimize(n_trials=250, n_jobs=1)\n",
        "\n",
        "# Generate and save result visualizations\n",
        "clf.get_results()\n",
        "\n",
        "# Save the trained model\n",
        "clf.save_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNaYKB3CMMJL",
        "outputId": "c4381017-8bb8-4309-a1c3-92478c39b1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: Tesla T4\n",
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:39:11,478] A new study created in memory with name: no-name-11324703-d7dc-45a6-af11-4b1917067bb7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.006464328564158388}\n",
            "Epoch 100/1500, Train Loss: 0.694168, Val Loss: 0.697063, Val Acc: 0.474576\n",
            "Epoch 200/1500, Train Loss: 0.693256, Val Loss: 0.696274, Val Acc: 0.483051\n",
            "Epoch 300/1500, Train Loss: 0.691484, Val Loss: 0.695439, Val Acc: 0.533898\n",
            "Epoch 400/1500, Train Loss: 0.689521, Val Loss: 0.693858, Val Acc: 0.584746\n",
            "Epoch 500/1500, Train Loss: 0.687513, Val Loss: 0.691453, Val Acc: 0.601695\n",
            "Epoch 600/1500, Train Loss: 0.684123, Val Loss: 0.687905, Val Acc: 0.593220\n",
            "Epoch 700/1500, Train Loss: 0.679518, Val Loss: 0.682293, Val Acc: 0.610169\n",
            "Epoch 800/1500, Train Loss: 0.666967, Val Loss: 0.674148, Val Acc: 0.644068\n",
            "Epoch 900/1500, Train Loss: 0.659641, Val Loss: 0.661572, Val Acc: 0.686441\n",
            "Epoch 1000/1500, Train Loss: 0.629026, Val Loss: 0.642081, Val Acc: 0.720339\n",
            "Epoch 1100/1500, Train Loss: 0.602663, Val Loss: 0.614247, Val Acc: 0.686441\n",
            "Epoch 1200/1500, Train Loss: 0.563974, Val Loss: 0.584751, Val Acc: 0.694915\n",
            "Epoch 1300/1500, Train Loss: 0.545852, Val Loss: 0.562663, Val Acc: 0.720339\n",
            "Epoch 1400/1500, Train Loss: 0.497137, Val Loss: 0.549423, Val Acc: 0.720339\n",
            "Epoch 1500/1500, Train Loss: 0.484278, Val Loss: 0.544313, Val Acc: 0.720339\n",
            "Test Loss: 0.5288600921630859 Test Accuracy: 0.7432432432432432\n",
            "weighted: Test F1: 0.5288600921630859 Test Precision: 0.7432432432432432 Test Recall: 0.7432432432432432\n",
            "[[61 10]\n",
            " [28 49]]\n",
            "[Trial 0] Test acc: 0.7432432432432432, Best val acc: 0.7203389830508474\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:40:19,295] Trial 0 finished with value: 0.7432432432432432 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.006464328564158388, 'learning_rate': 0.0029565552708311587, 'num_epoch': 1500}. Best is trial 0 with value: 0.7432432432432432.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007280693634860393}\n",
            "Epoch 100/500, Train Loss: 0.696754, Val Loss: 0.696195, Val Acc: 0.601695\n",
            "Epoch 200/500, Train Loss: 0.696403, Val Loss: 0.695977, Val Acc: 0.618644\n",
            "Epoch 300/500, Train Loss: 0.696403, Val Loss: 0.695853, Val Acc: 0.644068\n",
            "Epoch 400/500, Train Loss: 0.696248, Val Loss: 0.695617, Val Acc: 0.652542\n",
            "Epoch 500/500, Train Loss: 0.695758, Val Loss: 0.695334, Val Acc: 0.644068\n",
            "Test Loss: 0.6968501806259155 Test Accuracy: 0.47297297297297297\n",
            "weighted: Test F1: 0.6968501806259155 Test Precision: 0.47297297297297297 Test Recall: 0.47297297297297297\n",
            "[[37 34]\n",
            " [44 33]]\n",
            "[Trial 1] Test acc: 0.47297297297297297, Best val acc: 0.652542372881356\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:40:41,189] Trial 1 finished with value: 0.47297297297297297 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007280693634860393, 'learning_rate': 0.005024610347941667, 'num_epoch': 500}. Best is trial 0 with value: 0.7432432432432432.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.006110299758106644}\n",
            "Epoch 100/1500, Train Loss: 0.696277, Val Loss: 0.696168, Val Acc: 0.525424\n",
            "Epoch 200/1500, Train Loss: 0.696232, Val Loss: 0.696182, Val Acc: 0.542373\n",
            "Epoch 300/1500, Train Loss: 0.696323, Val Loss: 0.696219, Val Acc: 0.474576\n",
            "Epoch 400/1500, Train Loss: 0.696244, Val Loss: 0.696136, Val Acc: 0.525424\n",
            "Epoch 500/1500, Train Loss: 0.696309, Val Loss: 0.696222, Val Acc: 0.474576\n",
            "Epoch 600/1500, Train Loss: 0.696257, Val Loss: 0.696096, Val Acc: 0.525424\n",
            "Epoch 700/1500, Train Loss: 0.696259, Val Loss: 0.696263, Val Acc: 0.474576\n",
            "Epoch 800/1500, Train Loss: 0.696239, Val Loss: 0.696204, Val Acc: 0.474576\n",
            "Epoch 900/1500, Train Loss: 0.696317, Val Loss: 0.696158, Val Acc: 0.525424\n",
            "Epoch 1000/1500, Train Loss: 0.696244, Val Loss: 0.696170, Val Acc: 0.533898\n",
            "Epoch 1100/1500, Train Loss: 0.696305, Val Loss: 0.696264, Val Acc: 0.474576\n",
            "Epoch 1200/1500, Train Loss: 0.696231, Val Loss: 0.696194, Val Acc: 0.457627\n",
            "Epoch 1300/1500, Train Loss: 0.696213, Val Loss: 0.696134, Val Acc: 0.525424\n",
            "Epoch 1400/1500, Train Loss: 0.696286, Val Loss: 0.696096, Val Acc: 0.525424\n",
            "Epoch 1500/1500, Train Loss: 0.696229, Val Loss: 0.696124, Val Acc: 0.525424\n",
            "Test Loss: 0.69623863697052 Test Accuracy: 0.4797297297297297\n",
            "weighted: Test F1: 0.69623863697052 Test Precision: 0.4797297297297297 Test Recall: 0.4797297297297297\n",
            "[[71  0]\n",
            " [77  0]]\n",
            "[Trial 2] Test acc: 0.4797297297297297, Best val acc: 0.5423728813559322\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:41:42,256] Trial 2 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.006110299758106644, 'learning_rate': 0.004207047086531431, 'num_epoch': 1500}. Best is trial 0 with value: 0.7432432432432432.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005814159237667409}\n",
            "Epoch 100/2000, Train Loss: 0.694909, Val Loss: 0.695660, Val Acc: 0.550847\n",
            "Epoch 200/2000, Train Loss: 0.692919, Val Loss: 0.694043, Val Acc: 0.584746\n",
            "Epoch 300/2000, Train Loss: 0.689506, Val Loss: 0.690997, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.680064, Val Loss: 0.685198, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.676809, Val Loss: 0.673229, Val Acc: 0.677966\n",
            "Epoch 600/2000, Train Loss: 0.641828, Val Loss: 0.648684, Val Acc: 0.737288\n",
            "Epoch 700/2000, Train Loss: 0.598175, Val Loss: 0.607507, Val Acc: 0.703390\n",
            "Epoch 800/2000, Train Loss: 0.534622, Val Loss: 0.569592, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.493425, Val Loss: 0.545384, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.458486, Val Loss: 0.537431, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.445503, Val Loss: 0.541616, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.438392, Val Loss: 0.543898, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.433748, Val Loss: 0.545578, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.432075, Val Loss: 0.548091, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.424602, Val Loss: 0.545486, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.409824, Val Loss: 0.554953, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.414528, Val Loss: 0.556009, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.403852, Val Loss: 0.557701, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.401133, Val Loss: 0.563742, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.394583, Val Loss: 0.566795, Val Acc: 0.720339\n",
            "Test Loss: 0.5347747206687927 Test Accuracy: 0.7837837837837838\n",
            "weighted: Test F1: 0.5347747206687927 Test Precision: 0.7837837837837838 Test Recall: 0.7837837837837838\n",
            "[[62  9]\n",
            " [23 54]]\n",
            "[Trial 3] Test acc: 0.7837837837837838, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:43:04,113] Trial 3 finished with value: 0.7837837837837838 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005814159237667409, 'learning_rate': 0.004790467601403632, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.005949567439061245}\n",
            "Epoch 100/500, Train Loss: 0.696194, Val Loss: 0.696218, Val Acc: 0.483051\n",
            "Epoch 200/500, Train Loss: 0.695808, Val Loss: 0.696152, Val Acc: 0.508475\n",
            "Epoch 300/500, Train Loss: 0.696083, Val Loss: 0.696126, Val Acc: 0.542373\n",
            "Epoch 400/500, Train Loss: 0.695779, Val Loss: 0.696051, Val Acc: 0.567797\n",
            "Epoch 500/500, Train Loss: 0.695295, Val Loss: 0.695864, Val Acc: 0.567797\n",
            "Test Loss: 0.6953406929969788 Test Accuracy: 0.6148648648648649\n",
            "weighted: Test F1: 0.6953406929969788 Test Precision: 0.6148648648648649 Test Recall: 0.6148648648648649\n",
            "[[44 27]\n",
            " [30 47]]\n",
            "[Trial 4] Test acc: 0.6148648648648649, Best val acc: 0.5677966101694916\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:43:33,086] Trial 4 finished with value: 0.6148648648648649 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.005949567439061245, 'learning_rate': 0.009821033698454402, 'num_epoch': 500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'tanh', 'lam': 0.007410396342167559}\n",
            "Epoch 100/200, Train Loss: 0.691327, Val Loss: 0.694463, Val Acc: 0.576271\n",
            "Epoch 200/200, Train Loss: 0.681600, Val Loss: 0.689665, Val Acc: 0.618644\n",
            "Test Loss: 0.6855199933052063 Test Accuracy: 0.6283783783783784\n",
            "weighted: Test F1: 0.6855199933052063 Test Precision: 0.6283783783783784 Test Recall: 0.6283783783783784\n",
            "[[42 29]\n",
            " [26 51]]\n",
            "[Trial 5] Test acc: 0.6283783783783784, Best val acc: 0.6186440677966102\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:43:42,548] Trial 5 finished with value: 0.6283783783783784 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'tanh', 'lam': 0.007410396342167559, 'learning_rate': 0.00347245626392733, 'num_epoch': 200}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'tanh', 'lam': 0.005866710090695424}\n",
            "Epoch 100/500, Train Loss: 0.696265, Val Loss: 0.696122, Val Acc: 0.474576\n",
            "Epoch 200/500, Train Loss: 0.696252, Val Loss: 0.696084, Val Acc: 0.483051\n",
            "Epoch 300/500, Train Loss: 0.696062, Val Loss: 0.696048, Val Acc: 0.474576\n",
            "Epoch 400/500, Train Loss: 0.696130, Val Loss: 0.696025, Val Acc: 0.508475\n",
            "Epoch 500/500, Train Loss: 0.696080, Val Loss: 0.695952, Val Acc: 0.550847\n",
            "Test Loss: 0.6959876418113708 Test Accuracy: 0.5337837837837838\n",
            "weighted: Test F1: 0.6959876418113708 Test Precision: 0.5337837837837838 Test Recall: 0.5337837837837838\n",
            "[[26 45]\n",
            " [24 53]]\n",
            "[Trial 6] Test acc: 0.5337837837837838, Best val acc: 0.5508474576271186\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:44:04,296] Trial 6 finished with value: 0.5337837837837838 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'tanh', 'lam': 0.005866710090695424, 'learning_rate': 0.0062432271953362425, 'num_epoch': 500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'sigmoid', 'lam': 0.00873487194111265}\n",
            "Epoch 100/1000, Train Loss: 0.697634, Val Loss: 0.698469, Val Acc: 0.474576\n",
            "Epoch 200/1000, Train Loss: 0.697517, Val Loss: 0.697651, Val Acc: 0.474576\n",
            "Epoch 300/1000, Train Loss: 0.697528, Val Loss: 0.697571, Val Acc: 0.474576\n",
            "Epoch 400/1000, Train Loss: 0.697534, Val Loss: 0.697494, Val Acc: 0.525424\n",
            "Epoch 500/1000, Train Loss: 0.697547, Val Loss: 0.697509, Val Acc: 0.525424\n",
            "Epoch 600/1000, Train Loss: 0.697527, Val Loss: 0.697486, Val Acc: 0.525424\n",
            "Epoch 700/1000, Train Loss: 0.697536, Val Loss: 0.697525, Val Acc: 0.474576\n",
            "Epoch 800/1000, Train Loss: 0.697526, Val Loss: 0.697506, Val Acc: 0.525424\n",
            "Epoch 900/1000, Train Loss: 0.697533, Val Loss: 0.697495, Val Acc: 0.525424\n",
            "Epoch 1000/1000, Train Loss: 0.697518, Val Loss: 0.697533, Val Acc: 0.474576\n",
            "Test Loss: 0.6974915266036987 Test Accuracy: 0.5202702702702703\n",
            "weighted: Test F1: 0.6974915266036987 Test Precision: 0.5202702702702703 Test Recall: 0.5202702702702703\n",
            "[[ 0 71]\n",
            " [ 0 77]]\n",
            "[Trial 7] Test acc: 0.5202702702702703, Best val acc: 0.5254237288135594\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:44:50,252] Trial 7 finished with value: 0.5202702702702703 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'sigmoid', 'lam': 0.00873487194111265, 'learning_rate': 0.0007671398501217333, 'num_epoch': 1000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'l_relu', 'lam': 0.00630333932467468}\n",
            "Epoch 100/500, Train Loss: 0.696171, Val Loss: 0.696222, Val Acc: 0.474576\n",
            "Epoch 200/500, Train Loss: 0.696173, Val Loss: 0.696205, Val Acc: 0.474576\n",
            "Epoch 300/500, Train Loss: 0.696174, Val Loss: 0.696197, Val Acc: 0.483051\n",
            "Epoch 400/500, Train Loss: 0.696171, Val Loss: 0.696189, Val Acc: 0.533898\n",
            "Epoch 500/500, Train Loss: 0.696171, Val Loss: 0.696180, Val Acc: 0.559322\n",
            "Test Loss: 0.6961738467216492 Test Accuracy: 0.5675675675675675\n",
            "weighted: Test F1: 0.6961738467216492 Test Precision: 0.5675675675675675 Test Recall: 0.5675675675675675\n",
            "[[11 60]\n",
            " [ 4 73]]\n",
            "[Trial 8] Test acc: 0.5675675675675675, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:45:10,956] Trial 8 finished with value: 0.5675675675675675 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'l_relu', 'lam': 0.00630333932467468, 'learning_rate': 0.00021111381513539744, 'num_epoch': 500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005157346237578317}\n",
            "Epoch 100/1000, Train Loss: 0.695735, Val Loss: 0.695704, Val Acc: 0.559322\n",
            "Epoch 200/1000, Train Loss: 0.695689, Val Loss: 0.695705, Val Acc: 0.559322\n",
            "Epoch 300/1000, Train Loss: 0.695717, Val Loss: 0.695707, Val Acc: 0.533898\n",
            "Epoch 400/1000, Train Loss: 0.695720, Val Loss: 0.695710, Val Acc: 0.533898\n",
            "Epoch 500/1000, Train Loss: 0.695728, Val Loss: 0.695711, Val Acc: 0.491525\n",
            "Epoch 600/1000, Train Loss: 0.695722, Val Loss: 0.695709, Val Acc: 0.533898\n",
            "Epoch 700/1000, Train Loss: 0.695715, Val Loss: 0.695707, Val Acc: 0.533898\n",
            "Epoch 800/1000, Train Loss: 0.695731, Val Loss: 0.695706, Val Acc: 0.550847\n",
            "Epoch 900/1000, Train Loss: 0.695753, Val Loss: 0.695706, Val Acc: 0.525424\n",
            "Epoch 1000/1000, Train Loss: 0.695729, Val Loss: 0.695706, Val Acc: 0.516949\n",
            "Test Loss: 0.6957341432571411 Test Accuracy: 0.4527027027027027\n",
            "weighted: Test F1: 0.6957341432571411 Test Precision: 0.4527027027027027 Test Recall: 0.4527027027027027\n",
            "[[42 29]\n",
            " [52 25]]\n",
            "[Trial 9] Test acc: 0.4527027027027027, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:45:54,252] Trial 9 finished with value: 0.4527027027027027 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005157346237578317, 'learning_rate': 9.868452162597194e-05, 'num_epoch': 1000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'relu', 'lam': 0.005153845848497083}\n",
            "Epoch 100/2000, Train Loss: 0.695065, Val Loss: 0.695594, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.694952, Val Loss: 0.695435, Val Acc: 0.500000\n",
            "Epoch 300/2000, Train Loss: 0.694881, Val Loss: 0.695323, Val Acc: 0.533898\n",
            "Epoch 400/2000, Train Loss: 0.694813, Val Loss: 0.695274, Val Acc: 0.516949\n",
            "Epoch 500/2000, Train Loss: 0.694994, Val Loss: 0.695235, Val Acc: 0.491525\n",
            "Epoch 600/2000, Train Loss: 0.694894, Val Loss: 0.695168, Val Acc: 0.516949\n",
            "Epoch 700/2000, Train Loss: 0.694670, Val Loss: 0.695127, Val Acc: 0.516949\n",
            "Epoch 800/2000, Train Loss: 0.694853, Val Loss: 0.695059, Val Acc: 0.525424\n",
            "Epoch 900/2000, Train Loss: 0.694282, Val Loss: 0.695105, Val Acc: 0.500000\n",
            "Epoch 1000/2000, Train Loss: 0.693671, Val Loss: 0.695018, Val Acc: 0.508475\n",
            "Epoch 1100/2000, Train Loss: 0.694541, Val Loss: 0.694933, Val Acc: 0.550847\n",
            "Epoch 1200/2000, Train Loss: 0.693750, Val Loss: 0.694839, Val Acc: 0.550847\n",
            "Epoch 1300/2000, Train Loss: 0.692268, Val Loss: 0.694695, Val Acc: 0.542373\n",
            "Epoch 1400/2000, Train Loss: 0.693168, Val Loss: 0.694511, Val Acc: 0.533898\n",
            "Epoch 1500/2000, Train Loss: 0.691819, Val Loss: 0.694319, Val Acc: 0.533898\n",
            "Epoch 1600/2000, Train Loss: 0.691534, Val Loss: 0.694065, Val Acc: 0.533898\n",
            "Epoch 1700/2000, Train Loss: 0.692196, Val Loss: 0.693738, Val Acc: 0.542373\n",
            "Epoch 1800/2000, Train Loss: 0.691377, Val Loss: 0.693365, Val Acc: 0.542373\n",
            "Epoch 1900/2000, Train Loss: 0.689984, Val Loss: 0.692950, Val Acc: 0.542373\n",
            "Epoch 2000/2000, Train Loss: 0.690603, Val Loss: 0.692429, Val Acc: 0.559322\n",
            "Test Loss: 0.6892949342727661 Test Accuracy: 0.6081081081081081\n",
            "weighted: Test F1: 0.6892949342727661 Test Precision: 0.6081081081081081 Test Recall: 0.6081081081081081\n",
            "[[41 30]\n",
            " [28 49]]\n",
            "[Trial 10] Test acc: 0.6081081081081081, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:47:32,002] Trial 10 finished with value: 0.6081081081081081 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'relu', 'lam': 0.005153845848497083, 'learning_rate': 0.0012449228504534404, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006728384590658574}\n",
            "Epoch 100/2000, Train Loss: 0.696634, Val Loss: 0.696426, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.696844, Val Loss: 0.696358, Val Acc: 0.516949\n",
            "Epoch 300/2000, Train Loss: 0.696950, Val Loss: 0.696168, Val Acc: 0.516949\n",
            "Epoch 400/2000, Train Loss: 0.696373, Val Loss: 0.695929, Val Acc: 0.542373\n",
            "Epoch 500/2000, Train Loss: 0.696166, Val Loss: 0.695679, Val Acc: 0.550847\n",
            "Epoch 600/2000, Train Loss: 0.696136, Val Loss: 0.695368, Val Acc: 0.635593\n",
            "Epoch 700/2000, Train Loss: 0.695781, Val Loss: 0.695074, Val Acc: 0.635593\n",
            "Epoch 800/2000, Train Loss: 0.695502, Val Loss: 0.694759, Val Acc: 0.669492\n",
            "Epoch 900/2000, Train Loss: 0.694742, Val Loss: 0.694420, Val Acc: 0.661017\n",
            "Epoch 1000/2000, Train Loss: 0.694854, Val Loss: 0.693999, Val Acc: 0.669492\n",
            "Epoch 1100/2000, Train Loss: 0.694175, Val Loss: 0.693477, Val Acc: 0.661017\n",
            "Epoch 1200/2000, Train Loss: 0.693431, Val Loss: 0.692857, Val Acc: 0.652542\n",
            "Epoch 1300/2000, Train Loss: 0.692456, Val Loss: 0.692093, Val Acc: 0.644068\n",
            "Epoch 1400/2000, Train Loss: 0.690234, Val Loss: 0.691119, Val Acc: 0.644068\n",
            "Epoch 1500/2000, Train Loss: 0.691525, Val Loss: 0.689884, Val Acc: 0.644068\n",
            "Epoch 1600/2000, Train Loss: 0.687860, Val Loss: 0.688250, Val Acc: 0.644068\n",
            "Epoch 1700/2000, Train Loss: 0.686252, Val Loss: 0.685932, Val Acc: 0.669492\n",
            "Epoch 1800/2000, Train Loss: 0.684074, Val Loss: 0.682869, Val Acc: 0.669492\n",
            "Epoch 1900/2000, Train Loss: 0.679693, Val Loss: 0.678880, Val Acc: 0.669492\n",
            "Epoch 2000/2000, Train Loss: 0.676304, Val Loss: 0.673867, Val Acc: 0.661017\n",
            "Test Loss: 0.677067220211029 Test Accuracy: 0.6351351351351351\n",
            "weighted: Test F1: 0.677067220211029 Test Precision: 0.6351351351351351 Test Recall: 0.6351351351351351\n",
            "[[46 25]\n",
            " [29 48]]\n",
            "[Trial 11] Test acc: 0.6351351351351351, Best val acc: 0.6694915254237288\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:48:55,488] Trial 11 finished with value: 0.6351351351351351 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006728384590658574, 'learning_rate': 0.0018841642951830239, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'l_relu', 'lam': 0.009886031740587307}\n",
            "Epoch 100/1500, Train Loss: 0.698240, Val Loss: 0.698463, Val Acc: 0.457627\n",
            "Epoch 200/1500, Train Loss: 0.697407, Val Loss: 0.698404, Val Acc: 0.457627\n",
            "Epoch 300/1500, Train Loss: 0.697241, Val Loss: 0.698364, Val Acc: 0.457627\n",
            "Epoch 400/1500, Train Loss: 0.698220, Val Loss: 0.698295, Val Acc: 0.466102\n",
            "Epoch 500/1500, Train Loss: 0.697745, Val Loss: 0.698231, Val Acc: 0.457627\n",
            "Epoch 600/1500, Train Loss: 0.697246, Val Loss: 0.698154, Val Acc: 0.457627\n",
            "Epoch 700/1500, Train Loss: 0.697293, Val Loss: 0.698108, Val Acc: 0.466102\n",
            "Epoch 800/1500, Train Loss: 0.697858, Val Loss: 0.698078, Val Acc: 0.474576\n",
            "Epoch 900/1500, Train Loss: 0.696741, Val Loss: 0.698030, Val Acc: 0.466102\n",
            "Epoch 1000/1500, Train Loss: 0.697059, Val Loss: 0.697967, Val Acc: 0.457627\n",
            "Epoch 1100/1500, Train Loss: 0.697380, Val Loss: 0.697911, Val Acc: 0.466102\n",
            "Epoch 1200/1500, Train Loss: 0.695946, Val Loss: 0.697850, Val Acc: 0.474576\n",
            "Epoch 1300/1500, Train Loss: 0.696894, Val Loss: 0.697794, Val Acc: 0.491525\n",
            "Epoch 1400/1500, Train Loss: 0.696878, Val Loss: 0.697725, Val Acc: 0.500000\n",
            "Epoch 1500/1500, Train Loss: 0.696441, Val Loss: 0.697657, Val Acc: 0.500000\n",
            "Test Loss: 0.6956800222396851 Test Accuracy: 0.5675675675675675\n",
            "weighted: Test F1: 0.6956800222396851 Test Precision: 0.5675675675675675 Test Recall: 0.5675675675675675\n",
            "[[46 25]\n",
            " [39 38]]\n",
            "[Trial 12] Test acc: 0.5675675675675675, Best val acc: 0.5\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:49:53,668] Trial 12 finished with value: 0.5675675675675675 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'l_relu', 'lam': 0.009886031740587307, 'learning_rate': 0.00037455768344830373, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.007929510625434065}\n",
            "Epoch 100/1500, Train Loss: 0.696931, Val Loss: 0.696149, Val Acc: 0.500000\n",
            "Epoch 200/1500, Train Loss: 0.696616, Val Loss: 0.695666, Val Acc: 0.542373\n",
            "Epoch 300/1500, Train Loss: 0.696148, Val Loss: 0.695076, Val Acc: 0.593220\n",
            "Epoch 400/1500, Train Loss: 0.695255, Val Loss: 0.694441, Val Acc: 0.618644\n",
            "Epoch 500/1500, Train Loss: 0.694358, Val Loss: 0.693727, Val Acc: 0.627119\n",
            "Epoch 600/1500, Train Loss: 0.691877, Val Loss: 0.692921, Val Acc: 0.635593\n",
            "Epoch 700/1500, Train Loss: 0.692463, Val Loss: 0.692006, Val Acc: 0.644068\n",
            "Epoch 800/1500, Train Loss: 0.691524, Val Loss: 0.690792, Val Acc: 0.652542\n",
            "Epoch 900/1500, Train Loss: 0.693158, Val Loss: 0.689285, Val Acc: 0.661017\n",
            "Epoch 1000/1500, Train Loss: 0.684776, Val Loss: 0.687208, Val Acc: 0.661017\n",
            "Epoch 1100/1500, Train Loss: 0.685527, Val Loss: 0.684487, Val Acc: 0.661017\n",
            "Epoch 1200/1500, Train Loss: 0.679550, Val Loss: 0.681078, Val Acc: 0.661017\n",
            "Epoch 1300/1500, Train Loss: 0.678778, Val Loss: 0.676583, Val Acc: 0.669492\n",
            "Epoch 1400/1500, Train Loss: 0.668740, Val Loss: 0.670782, Val Acc: 0.669492\n",
            "Epoch 1500/1500, Train Loss: 0.664227, Val Loss: 0.663485, Val Acc: 0.669492\n",
            "Test Loss: 0.6648638844490051 Test Accuracy: 0.6081081081081081\n",
            "weighted: Test F1: 0.6648638844490051 Test Precision: 0.6081081081081081 Test Recall: 0.6081081081081081\n",
            "[[42 29]\n",
            " [29 48]]\n",
            "[Trial 13] Test acc: 0.6081081081081081, Best val acc: 0.6694915254237288\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:50:55,912] Trial 13 finished with value: 0.6081081081081081 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.007929510625434065, 'learning_rate': 0.002058441477415464, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.005592156941711579}\n",
            "Epoch 100/2000, Train Loss: 0.695645, Val Loss: 0.697642, Val Acc: 0.432203\n",
            "Epoch 200/2000, Train Loss: 0.696092, Val Loss: 0.697301, Val Acc: 0.398305\n",
            "Epoch 300/2000, Train Loss: 0.695390, Val Loss: 0.697039, Val Acc: 0.449153\n",
            "Epoch 400/2000, Train Loss: 0.694412, Val Loss: 0.696791, Val Acc: 0.466102\n",
            "Epoch 500/2000, Train Loss: 0.694541, Val Loss: 0.696569, Val Acc: 0.466102\n",
            "Epoch 600/2000, Train Loss: 0.694512, Val Loss: 0.696356, Val Acc: 0.449153\n",
            "Epoch 700/2000, Train Loss: 0.694289, Val Loss: 0.696159, Val Acc: 0.466102\n",
            "Epoch 800/2000, Train Loss: 0.694107, Val Loss: 0.695911, Val Acc: 0.500000\n",
            "Epoch 900/2000, Train Loss: 0.692762, Val Loss: 0.695662, Val Acc: 0.508475\n",
            "Epoch 1000/2000, Train Loss: 0.692351, Val Loss: 0.695377, Val Acc: 0.533898\n",
            "Epoch 1100/2000, Train Loss: 0.692328, Val Loss: 0.695065, Val Acc: 0.542373\n",
            "Epoch 1200/2000, Train Loss: 0.691356, Val Loss: 0.694662, Val Acc: 0.550847\n",
            "Epoch 1300/2000, Train Loss: 0.690953, Val Loss: 0.694250, Val Acc: 0.567797\n",
            "Epoch 1400/2000, Train Loss: 0.690721, Val Loss: 0.693800, Val Acc: 0.584746\n",
            "Epoch 1500/2000, Train Loss: 0.689168, Val Loss: 0.693274, Val Acc: 0.593220\n",
            "Epoch 1600/2000, Train Loss: 0.688583, Val Loss: 0.692688, Val Acc: 0.610169\n",
            "Epoch 1700/2000, Train Loss: 0.689246, Val Loss: 0.692006, Val Acc: 0.635593\n",
            "Epoch 1800/2000, Train Loss: 0.687063, Val Loss: 0.691209, Val Acc: 0.635593\n",
            "Epoch 1900/2000, Train Loss: 0.685966, Val Loss: 0.690312, Val Acc: 0.635593\n",
            "Epoch 2000/2000, Train Loss: 0.684870, Val Loss: 0.689319, Val Acc: 0.635593\n",
            "Test Loss: 0.6858766674995422 Test Accuracy: 0.6013513513513513\n",
            "weighted: Test F1: 0.6858766674995422 Test Precision: 0.6013513513513513 Test Recall: 0.6013513513513513\n",
            "[[44 27]\n",
            " [32 45]]\n",
            "[Trial 14] Test acc: 0.6013513513513513, Best val acc: 0.635593220338983\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:52:18,230] Trial 14 finished with value: 0.6013513513513513 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.005592156941711579, 'learning_rate': 0.0009187825656244133, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.00688814765967597}\n",
            "Epoch 100/200, Train Loss: 0.694688, Val Loss: 0.694626, Val Acc: 0.516949\n",
            "Epoch 200/200, Train Loss: 0.695148, Val Loss: 0.693933, Val Acc: 0.525424\n",
            "Test Loss: 0.6955986618995667 Test Accuracy: 0.527027027027027\n",
            "weighted: Test F1: 0.6955986618995667 Test Precision: 0.527027027027027 Test Recall: 0.527027027027027\n",
            "[[31 40]\n",
            " [30 47]]\n",
            "[Trial 15] Test acc: 0.527027027027027, Best val acc: 0.5254237288135594\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:52:26,115] Trial 15 finished with value: 0.527027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.00688814765967597, 'learning_rate': 0.0027440172469182633, 'num_epoch': 200}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'sigmoid', 'lam': 0.006532172416095929}\n",
            "Epoch 100/1500, Train Loss: 0.696649, Val Loss: 0.696450, Val Acc: 0.474576\n",
            "Epoch 200/1500, Train Loss: 0.697000, Val Loss: 0.696338, Val Acc: 0.525424\n",
            "Epoch 300/1500, Train Loss: 0.696495, Val Loss: 0.696607, Val Acc: 0.474576\n",
            "Epoch 400/1500, Train Loss: 0.696553, Val Loss: 0.696534, Val Acc: 0.474576\n",
            "Epoch 500/1500, Train Loss: 0.696499, Val Loss: 0.696470, Val Acc: 0.474576\n",
            "Epoch 600/1500, Train Loss: 0.696713, Val Loss: 0.696409, Val Acc: 0.474576\n",
            "Epoch 700/1500, Train Loss: 0.696812, Val Loss: 0.696469, Val Acc: 0.474576\n",
            "Epoch 800/1500, Train Loss: 0.696860, Val Loss: 0.696538, Val Acc: 0.474576\n",
            "Epoch 900/1500, Train Loss: 0.696583, Val Loss: 0.696328, Val Acc: 0.525424\n",
            "Epoch 1000/1500, Train Loss: 0.696519, Val Loss: 0.696365, Val Acc: 0.525424\n",
            "Epoch 1100/1500, Train Loss: 0.696635, Val Loss: 0.696581, Val Acc: 0.474576\n",
            "Epoch 1200/1500, Train Loss: 0.696675, Val Loss: 0.696437, Val Acc: 0.474576\n",
            "Epoch 1300/1500, Train Loss: 0.696776, Val Loss: 0.696567, Val Acc: 0.474576\n",
            "Epoch 1400/1500, Train Loss: 0.696530, Val Loss: 0.696393, Val Acc: 0.474576\n",
            "Epoch 1500/1500, Train Loss: 0.696662, Val Loss: 0.696338, Val Acc: 0.525424\n",
            "Test Loss: 0.6963725090026855 Test Accuracy: 0.4797297297297297\n",
            "weighted: Test F1: 0.6963725090026855 Test Precision: 0.4797297297297297 Test Recall: 0.4797297297297297\n",
            "[[71  0]\n",
            " [77  0]]\n",
            "[Trial 16] Test acc: 0.4797297297297297, Best val acc: 0.5254237288135594\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:53:27,403] Trial 16 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'sigmoid', 'lam': 0.006532172416095929, 'learning_rate': 0.009511809466041259, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.00545555848309818}\n",
            "Epoch 100/2000, Train Loss: 0.697109, Val Loss: 0.696427, Val Acc: 0.466102\n",
            "Epoch 200/2000, Train Loss: 0.696772, Val Loss: 0.696401, Val Acc: 0.466102\n",
            "Epoch 300/2000, Train Loss: 0.696104, Val Loss: 0.696375, Val Acc: 0.466102\n",
            "Epoch 400/2000, Train Loss: 0.696596, Val Loss: 0.696351, Val Acc: 0.466102\n",
            "Epoch 500/2000, Train Loss: 0.696537, Val Loss: 0.696325, Val Acc: 0.466102\n",
            "Epoch 600/2000, Train Loss: 0.696844, Val Loss: 0.696302, Val Acc: 0.466102\n",
            "Epoch 700/2000, Train Loss: 0.696520, Val Loss: 0.696279, Val Acc: 0.440678\n",
            "Epoch 800/2000, Train Loss: 0.697366, Val Loss: 0.696256, Val Acc: 0.432203\n",
            "Epoch 900/2000, Train Loss: 0.696634, Val Loss: 0.696232, Val Acc: 0.432203\n",
            "Epoch 1000/2000, Train Loss: 0.696621, Val Loss: 0.696211, Val Acc: 0.432203\n",
            "Epoch 1100/2000, Train Loss: 0.696707, Val Loss: 0.696190, Val Acc: 0.432203\n",
            "Epoch 1200/2000, Train Loss: 0.696885, Val Loss: 0.696170, Val Acc: 0.440678\n",
            "Epoch 1300/2000, Train Loss: 0.696426, Val Loss: 0.696148, Val Acc: 0.457627\n",
            "Epoch 1400/2000, Train Loss: 0.696433, Val Loss: 0.696129, Val Acc: 0.457627\n",
            "Epoch 1500/2000, Train Loss: 0.696618, Val Loss: 0.696110, Val Acc: 0.483051\n",
            "Epoch 1600/2000, Train Loss: 0.696388, Val Loss: 0.696091, Val Acc: 0.474576\n",
            "Epoch 1700/2000, Train Loss: 0.696199, Val Loss: 0.696075, Val Acc: 0.474576\n",
            "Epoch 1800/2000, Train Loss: 0.696901, Val Loss: 0.696058, Val Acc: 0.483051\n",
            "Epoch 1900/2000, Train Loss: 0.696291, Val Loss: 0.696042, Val Acc: 0.483051\n",
            "Epoch 2000/2000, Train Loss: 0.696087, Val Loss: 0.696025, Val Acc: 0.483051\n",
            "Test Loss: 0.6967179179191589 Test Accuracy: 0.4864864864864865\n",
            "weighted: Test F1: 0.6967179179191589 Test Precision: 0.4864864864864865 Test Recall: 0.4864864864864865\n",
            "[[21 50]\n",
            " [26 51]]\n",
            "[Trial 17] Test acc: 0.4864864864864865, Best val acc: 0.4830508474576271\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:54:53,071] Trial 17 finished with value: 0.4864864864864865 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.00545555848309818, 'learning_rate': 5.234482553144775e-05, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.008068458928911847}\n",
            "Epoch 100/1500, Train Loss: 0.696558, Val Loss: 0.696189, Val Acc: 0.525424\n",
            "Epoch 200/1500, Train Loss: 0.695916, Val Loss: 0.695963, Val Acc: 0.525424\n",
            "Epoch 300/1500, Train Loss: 0.696140, Val Loss: 0.695671, Val Acc: 0.533898\n",
            "Epoch 400/1500, Train Loss: 0.695528, Val Loss: 0.695255, Val Acc: 0.533898\n",
            "Epoch 500/1500, Train Loss: 0.694808, Val Loss: 0.694865, Val Acc: 0.516949\n",
            "Epoch 600/1500, Train Loss: 0.694375, Val Loss: 0.694326, Val Acc: 0.550847\n",
            "Epoch 700/1500, Train Loss: 0.692231, Val Loss: 0.693714, Val Acc: 0.542373\n",
            "Epoch 800/1500, Train Loss: 0.691285, Val Loss: 0.692948, Val Acc: 0.610169\n",
            "Epoch 900/1500, Train Loss: 0.692208, Val Loss: 0.692032, Val Acc: 0.618644\n",
            "Epoch 1000/1500, Train Loss: 0.689866, Val Loss: 0.691075, Val Acc: 0.661017\n",
            "Epoch 1100/1500, Train Loss: 0.687241, Val Loss: 0.689979, Val Acc: 0.644068\n",
            "Epoch 1200/1500, Train Loss: 0.685639, Val Loss: 0.688730, Val Acc: 0.669492\n",
            "Epoch 1300/1500, Train Loss: 0.686298, Val Loss: 0.687322, Val Acc: 0.677966\n",
            "Epoch 1400/1500, Train Loss: 0.680461, Val Loss: 0.685552, Val Acc: 0.677966\n",
            "Epoch 1500/1500, Train Loss: 0.680769, Val Loss: 0.683413, Val Acc: 0.686441\n",
            "Test Loss: 0.6842774152755737 Test Accuracy: 0.581081081081081\n",
            "weighted: Test F1: 0.6842774152755737 Test Precision: 0.581081081081081 Test Recall: 0.581081081081081\n",
            "[[38 33]\n",
            " [29 48]]\n",
            "[Trial 18] Test acc: 0.581081081081081, Best val acc: 0.6864406779661016\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:55:53,845] Trial 18 finished with value: 0.581081081081081 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.008068458928911847, 'learning_rate': 0.001290613764003835, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.005526157437263439}\n",
            "Epoch 100/2000, Train Loss: 0.695646, Val Loss: 0.696094, Val Acc: 0.466102\n",
            "Epoch 200/2000, Train Loss: 0.695730, Val Loss: 0.696057, Val Acc: 0.466102\n",
            "Epoch 300/2000, Train Loss: 0.695706, Val Loss: 0.696043, Val Acc: 0.432203\n",
            "Epoch 400/2000, Train Loss: 0.695679, Val Loss: 0.696020, Val Acc: 0.457627\n",
            "Epoch 500/2000, Train Loss: 0.695750, Val Loss: 0.695993, Val Acc: 0.483051\n",
            "Epoch 600/2000, Train Loss: 0.695745, Val Loss: 0.695981, Val Acc: 0.525424\n",
            "Epoch 700/2000, Train Loss: 0.695644, Val Loss: 0.695970, Val Acc: 0.550847\n",
            "Epoch 800/2000, Train Loss: 0.695390, Val Loss: 0.695958, Val Acc: 0.550847\n",
            "Epoch 900/2000, Train Loss: 0.695599, Val Loss: 0.695953, Val Acc: 0.542373\n",
            "Epoch 1000/2000, Train Loss: 0.695571, Val Loss: 0.695954, Val Acc: 0.550847\n",
            "Epoch 1100/2000, Train Loss: 0.695898, Val Loss: 0.695946, Val Acc: 0.542373\n",
            "Epoch 1200/2000, Train Loss: 0.695835, Val Loss: 0.695935, Val Acc: 0.525424\n",
            "Epoch 1300/2000, Train Loss: 0.695664, Val Loss: 0.695939, Val Acc: 0.542373\n",
            "Epoch 1400/2000, Train Loss: 0.695622, Val Loss: 0.695932, Val Acc: 0.542373\n",
            "Epoch 1500/2000, Train Loss: 0.695648, Val Loss: 0.695921, Val Acc: 0.525424\n",
            "Epoch 1600/2000, Train Loss: 0.695559, Val Loss: 0.695925, Val Acc: 0.533898\n",
            "Epoch 1700/2000, Train Loss: 0.695633, Val Loss: 0.695928, Val Acc: 0.542373\n",
            "Epoch 1800/2000, Train Loss: 0.695496, Val Loss: 0.695921, Val Acc: 0.542373\n",
            "Epoch 1900/2000, Train Loss: 0.695571, Val Loss: 0.695920, Val Acc: 0.542373\n",
            "Epoch 2000/2000, Train Loss: 0.695813, Val Loss: 0.695910, Val Acc: 0.525424\n",
            "Test Loss: 0.6957594156265259 Test Accuracy: 0.5472972972972973\n",
            "weighted: Test F1: 0.6957594156265259 Test Precision: 0.5472972972972973 Test Recall: 0.5472972972972973\n",
            "[[50 21]\n",
            " [46 31]]\n",
            "[Trial 19] Test acc: 0.5472972972972973, Best val acc: 0.5508474576271186\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:57:20,214] Trial 19 finished with value: 0.5472972972972973 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.005526157437263439, 'learning_rate': 0.0003104709828520428, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'l_relu', 'lam': 0.006416859283576748}\n",
            "Epoch 100/200, Train Loss: 0.695712, Val Loss: 0.696014, Val Acc: 0.610169\n",
            "Epoch 200/200, Train Loss: 0.695638, Val Loss: 0.695810, Val Acc: 0.601695\n",
            "Test Loss: 0.6958308815956116 Test Accuracy: 0.527027027027027\n",
            "weighted: Test F1: 0.6958308815956116 Test Precision: 0.527027027027027 Test Recall: 0.527027027027027\n",
            "[[32 39]\n",
            " [31 46]]\n",
            "[Trial 20] Test acc: 0.527027027027027, Best val acc: 0.6101694915254238\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:57:28,232] Trial 20 finished with value: 0.527027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'l_relu', 'lam': 0.006416859283576748, 'learning_rate': 0.0005583963658563343, 'num_epoch': 200}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006737213995179229}\n",
            "Epoch 100/2000, Train Loss: 0.695282, Val Loss: 0.696582, Val Acc: 0.449153\n",
            "Epoch 200/2000, Train Loss: 0.694595, Val Loss: 0.695842, Val Acc: 0.500000\n",
            "Epoch 300/2000, Train Loss: 0.693383, Val Loss: 0.694966, Val Acc: 0.516949\n",
            "Epoch 400/2000, Train Loss: 0.692352, Val Loss: 0.693952, Val Acc: 0.559322\n",
            "Epoch 500/2000, Train Loss: 0.688577, Val Loss: 0.692595, Val Acc: 0.576271\n",
            "Epoch 600/2000, Train Loss: 0.687643, Val Loss: 0.690864, Val Acc: 0.593220\n",
            "Epoch 700/2000, Train Loss: 0.682248, Val Loss: 0.688674, Val Acc: 0.584746\n",
            "Epoch 800/2000, Train Loss: 0.681144, Val Loss: 0.685682, Val Acc: 0.601695\n",
            "Epoch 900/2000, Train Loss: 0.675208, Val Loss: 0.681512, Val Acc: 0.601695\n",
            "Epoch 1000/2000, Train Loss: 0.669493, Val Loss: 0.675889, Val Acc: 0.644068\n",
            "Epoch 1100/2000, Train Loss: 0.661828, Val Loss: 0.668388, Val Acc: 0.677966\n",
            "Epoch 1200/2000, Train Loss: 0.649292, Val Loss: 0.658472, Val Acc: 0.677966\n",
            "Epoch 1300/2000, Train Loss: 0.640363, Val Loss: 0.644730, Val Acc: 0.686441\n",
            "Epoch 1400/2000, Train Loss: 0.615099, Val Loss: 0.628271, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.600988, Val Loss: 0.609243, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.579224, Val Loss: 0.592871, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.553714, Val Loss: 0.577198, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.524712, Val Loss: 0.564575, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.502591, Val Loss: 0.555119, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.484309, Val Loss: 0.548487, Val Acc: 0.728814\n",
            "Test Loss: 0.5358974933624268 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.5358974933624268 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[58 13]\n",
            " [28 49]]\n",
            "[Trial 21] Test acc: 0.722972972972973, Best val acc: 0.7288135593220338\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 16:58:49,938] Trial 21 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006737213995179229, 'learning_rate': 0.0018409390943829804, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007113905507547061}\n",
            "Epoch 100/2000, Train Loss: 0.694533, Val Loss: 0.695392, Val Acc: 0.610169\n",
            "Epoch 200/2000, Train Loss: 0.695200, Val Loss: 0.695096, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.694180, Val Loss: 0.694618, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.693307, Val Loss: 0.693989, Val Acc: 0.627119\n",
            "Epoch 500/2000, Train Loss: 0.692759, Val Loss: 0.693285, Val Acc: 0.627119\n",
            "Epoch 600/2000, Train Loss: 0.690114, Val Loss: 0.692177, Val Acc: 0.635593\n",
            "Epoch 700/2000, Train Loss: 0.687515, Val Loss: 0.690815, Val Acc: 0.635593\n",
            "Epoch 800/2000, Train Loss: 0.687198, Val Loss: 0.688944, Val Acc: 0.644068\n",
            "Epoch 900/2000, Train Loss: 0.680654, Val Loss: 0.686304, Val Acc: 0.644068\n",
            "Epoch 1000/2000, Train Loss: 0.673467, Val Loss: 0.682852, Val Acc: 0.635593\n",
            "Epoch 1100/2000, Train Loss: 0.671055, Val Loss: 0.677544, Val Acc: 0.618644\n",
            "Epoch 1200/2000, Train Loss: 0.659712, Val Loss: 0.669722, Val Acc: 0.661017\n",
            "Epoch 1300/2000, Train Loss: 0.643671, Val Loss: 0.658433, Val Acc: 0.686441\n",
            "Epoch 1400/2000, Train Loss: 0.630585, Val Loss: 0.643093, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.607907, Val Loss: 0.622883, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.573424, Val Loss: 0.602509, Val Acc: 0.745763\n",
            "Epoch 1700/2000, Train Loss: 0.545583, Val Loss: 0.582291, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.515656, Val Loss: 0.563900, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.504713, Val Loss: 0.550765, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.494087, Val Loss: 0.544010, Val Acc: 0.720339\n",
            "Test Loss: 0.5246002674102783 Test Accuracy: 0.7432432432432432\n",
            "weighted: Test F1: 0.5246002674102783 Test Precision: 0.7432432432432432 Test Recall: 0.7432432432432432\n",
            "[[60 11]\n",
            " [27 50]]\n",
            "[Trial 22] Test acc: 0.7432432432432432, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:00:11,070] Trial 22 finished with value: 0.7432432432432432 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007113905507547061, 'learning_rate': 0.0022473580144648625, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007951932186467154}\n",
            "Epoch 100/2000, Train Loss: 0.695539, Val Loss: 0.695716, Val Acc: 0.576271\n",
            "Epoch 200/2000, Train Loss: 0.692621, Val Loss: 0.692958, Val Acc: 0.644068\n",
            "Epoch 300/2000, Train Loss: 0.684368, Val Loss: 0.686705, Val Acc: 0.669492\n",
            "Epoch 400/2000, Train Loss: 0.664880, Val Loss: 0.670896, Val Acc: 0.694915\n",
            "Epoch 500/2000, Train Loss: 0.618082, Val Loss: 0.632192, Val Acc: 0.694915\n",
            "Epoch 600/2000, Train Loss: 0.554507, Val Loss: 0.576314, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.483605, Val Loss: 0.546260, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.447639, Val Loss: 0.546689, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.427066, Val Loss: 0.551335, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.413380, Val Loss: 0.562104, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.421167, Val Loss: 0.565656, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.385949, Val Loss: 0.582997, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.373949, Val Loss: 0.599115, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.371161, Val Loss: 0.626075, Val Acc: 0.686441\n",
            "Epoch 1500/2000, Train Loss: 0.355421, Val Loss: 0.625498, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.329114, Val Loss: 0.642057, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.321592, Val Loss: 0.647891, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.298277, Val Loss: 0.662130, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.305051, Val Loss: 0.664448, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.288449, Val Loss: 0.686570, Val Acc: 0.737288\n",
            "Test Loss: 0.6063194870948792 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.6063194870948792 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[54 17]\n",
            " [24 53]]\n",
            "[Trial 23] Test acc: 0.722972972972973, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:01:31,960] Trial 23 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007951932186467154, 'learning_rate': 0.006305573259944887, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007142756385533048}\n",
            "Epoch 100/2000, Train Loss: 0.695456, Val Loss: 0.695282, Val Acc: 0.601695\n",
            "Epoch 200/2000, Train Loss: 0.694362, Val Loss: 0.694688, Val Acc: 0.567797\n",
            "Epoch 300/2000, Train Loss: 0.694576, Val Loss: 0.693946, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.691135, Val Loss: 0.692876, Val Acc: 0.542373\n",
            "Epoch 500/2000, Train Loss: 0.690799, Val Loss: 0.691182, Val Acc: 0.576271\n",
            "Epoch 600/2000, Train Loss: 0.686976, Val Loss: 0.688697, Val Acc: 0.627119\n",
            "Epoch 700/2000, Train Loss: 0.679733, Val Loss: 0.684831, Val Acc: 0.627119\n",
            "Epoch 800/2000, Train Loss: 0.673617, Val Loss: 0.678940, Val Acc: 0.661017\n",
            "Epoch 900/2000, Train Loss: 0.658624, Val Loss: 0.670137, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.652587, Val Loss: 0.656656, Val Acc: 0.694915\n",
            "Epoch 1100/2000, Train Loss: 0.633493, Val Loss: 0.635700, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.594488, Val Loss: 0.608408, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.571797, Val Loss: 0.583418, Val Acc: 0.694915\n",
            "Epoch 1400/2000, Train Loss: 0.519672, Val Loss: 0.564167, Val Acc: 0.686441\n",
            "Epoch 1500/2000, Train Loss: 0.503315, Val Loss: 0.550898, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.471378, Val Loss: 0.544857, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.464745, Val Loss: 0.542188, Val Acc: 0.745763\n",
            "Epoch 1800/2000, Train Loss: 0.455756, Val Loss: 0.541725, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.443619, Val Loss: 0.543237, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.430215, Val Loss: 0.545566, Val Acc: 0.737288\n",
            "Test Loss: 0.5199414491653442 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.5199414491653442 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[61 10]\n",
            " [26 51]]\n",
            "[Trial 24] Test acc: 0.7567567567567568, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:02:53,396] Trial 24 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007142756385533048, 'learning_rate': 0.002970897474094482, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'relu', 'lam': 0.007532967768265289}\n",
            "Epoch 100/1000, Train Loss: 0.695445, Val Loss: 0.696024, Val Acc: 0.483051\n",
            "Epoch 200/1000, Train Loss: 0.693866, Val Loss: 0.694411, Val Acc: 0.483051\n",
            "Epoch 300/1000, Train Loss: 0.690532, Val Loss: 0.692464, Val Acc: 0.500000\n",
            "Epoch 400/1000, Train Loss: 0.685624, Val Loss: 0.688732, Val Acc: 0.601695\n",
            "Epoch 500/1000, Train Loss: 0.679144, Val Loss: 0.682371, Val Acc: 0.618644\n",
            "Epoch 600/1000, Train Loss: 0.662703, Val Loss: 0.671913, Val Acc: 0.635593\n",
            "Epoch 700/1000, Train Loss: 0.644545, Val Loss: 0.653243, Val Acc: 0.669492\n",
            "Epoch 800/1000, Train Loss: 0.607514, Val Loss: 0.621722, Val Acc: 0.694915\n",
            "Epoch 900/1000, Train Loss: 0.565226, Val Loss: 0.585669, Val Acc: 0.711864\n",
            "Epoch 1000/1000, Train Loss: 0.513165, Val Loss: 0.560639, Val Acc: 0.711864\n",
            "Test Loss: 0.5464631915092468 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.5464631915092468 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[57 14]\n",
            " [27 50]]\n",
            "[Trial 25] Test acc: 0.722972972972973, Best val acc: 0.711864406779661\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:03:36,663] Trial 25 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'relu', 'lam': 0.007532967768265289, 'learning_rate': 0.0038138698995618284, 'num_epoch': 1000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'tanh', 'lam': 0.005727977351201849}\n",
            "Epoch 100/1500, Train Loss: 0.693177, Val Loss: 0.695727, Val Acc: 0.491525\n",
            "Epoch 200/1500, Train Loss: 0.689725, Val Loss: 0.693070, Val Acc: 0.500000\n",
            "Epoch 300/1500, Train Loss: 0.689835, Val Loss: 0.690384, Val Acc: 0.601695\n",
            "Epoch 400/1500, Train Loss: 0.689203, Val Loss: 0.687629, Val Acc: 0.618644\n",
            "Epoch 500/1500, Train Loss: 0.683019, Val Loss: 0.684394, Val Acc: 0.644068\n",
            "Epoch 600/1500, Train Loss: 0.680141, Val Loss: 0.680764, Val Acc: 0.669492\n",
            "Epoch 700/1500, Train Loss: 0.675517, Val Loss: 0.676326, Val Acc: 0.677966\n",
            "Epoch 800/1500, Train Loss: 0.666788, Val Loss: 0.671190, Val Acc: 0.677966\n",
            "Epoch 900/1500, Train Loss: 0.665533, Val Loss: 0.664799, Val Acc: 0.677966\n",
            "Epoch 1000/1500, Train Loss: 0.658991, Val Loss: 0.657165, Val Acc: 0.677966\n",
            "Epoch 1100/1500, Train Loss: 0.643304, Val Loss: 0.647864, Val Acc: 0.686441\n",
            "Epoch 1200/1500, Train Loss: 0.645970, Val Loss: 0.636795, Val Acc: 0.686441\n",
            "Epoch 1300/1500, Train Loss: 0.627784, Val Loss: 0.623593, Val Acc: 0.711864\n",
            "Epoch 1400/1500, Train Loss: 0.598135, Val Loss: 0.609430, Val Acc: 0.720339\n",
            "Epoch 1500/1500, Train Loss: 0.591040, Val Loss: 0.596330, Val Acc: 0.720339\n",
            "Test Loss: 0.5924502015113831 Test Accuracy: 0.7162162162162162\n",
            "weighted: Test F1: 0.5924502015113831 Test Precision: 0.7162162162162162 Test Recall: 0.7162162162162162\n",
            "[[53 18]\n",
            " [24 53]]\n",
            "[Trial 26] Test acc: 0.7162162162162162, Best val acc: 0.7203389830508474\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:04:33,217] Trial 26 finished with value: 0.7162162162162162 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'tanh', 'lam': 0.005727977351201849, 'learning_rate': 0.0013599428636255062, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.006149172217522751}\n",
            "Epoch 100/2000, Train Loss: 0.696245, Val Loss: 0.696280, Val Acc: 0.432203\n",
            "Epoch 200/2000, Train Loss: 0.696301, Val Loss: 0.696302, Val Acc: 0.449153\n",
            "Epoch 300/2000, Train Loss: 0.696268, Val Loss: 0.696263, Val Acc: 0.440678\n",
            "Epoch 400/2000, Train Loss: 0.696268, Val Loss: 0.696205, Val Acc: 0.567797\n",
            "Epoch 500/2000, Train Loss: 0.696225, Val Loss: 0.696243, Val Acc: 0.432203\n",
            "Epoch 600/2000, Train Loss: 0.696247, Val Loss: 0.696227, Val Acc: 0.483051\n",
            "Epoch 700/2000, Train Loss: 0.696309, Val Loss: 0.696275, Val Acc: 0.449153\n",
            "Epoch 800/2000, Train Loss: 0.696259, Val Loss: 0.696107, Val Acc: 0.525424\n",
            "Epoch 900/2000, Train Loss: 0.696259, Val Loss: 0.696152, Val Acc: 0.525424\n",
            "Epoch 1000/2000, Train Loss: 0.696279, Val Loss: 0.696218, Val Acc: 0.483051\n",
            "Epoch 1100/2000, Train Loss: 0.696251, Val Loss: 0.696303, Val Acc: 0.474576\n",
            "Epoch 1200/2000, Train Loss: 0.696230, Val Loss: 0.696164, Val Acc: 0.576271\n",
            "Epoch 1300/2000, Train Loss: 0.696270, Val Loss: 0.696187, Val Acc: 0.559322\n",
            "Epoch 1400/2000, Train Loss: 0.696270, Val Loss: 0.696213, Val Acc: 0.449153\n",
            "Epoch 1500/2000, Train Loss: 0.696287, Val Loss: 0.696081, Val Acc: 0.525424\n",
            "Epoch 1600/2000, Train Loss: 0.696209, Val Loss: 0.696198, Val Acc: 0.491525\n",
            "Epoch 1700/2000, Train Loss: 0.696282, Val Loss: 0.696149, Val Acc: 0.601695\n",
            "Epoch 1800/2000, Train Loss: 0.696149, Val Loss: 0.696158, Val Acc: 0.593220\n",
            "Epoch 1900/2000, Train Loss: 0.696272, Val Loss: 0.696179, Val Acc: 0.516949\n",
            "Epoch 2000/2000, Train Loss: 0.696154, Val Loss: 0.696143, Val Acc: 0.576271\n",
            "Test Loss: 0.6961736679077148 Test Accuracy: 0.5337837837837838\n",
            "weighted: Test F1: 0.6961736679077148 Test Precision: 0.5337837837837838 Test Recall: 0.5337837837837838\n",
            "[[61 10]\n",
            " [59 18]]\n",
            "[Trial 27] Test acc: 0.5337837837837838, Best val acc: 0.6016949152542372\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:05:54,282] Trial 27 finished with value: 0.5337837837837838 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.006149172217522751, 'learning_rate': 0.0031284529000857922, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.008826623112449505}\n",
            "Epoch 100/2000, Train Loss: 0.697601, Val Loss: 0.697549, Val Acc: 0.516949\n",
            "Epoch 200/2000, Train Loss: 0.697607, Val Loss: 0.697593, Val Acc: 0.483051\n",
            "Epoch 300/2000, Train Loss: 0.697639, Val Loss: 0.697549, Val Acc: 0.508475\n",
            "Epoch 400/2000, Train Loss: 0.697561, Val Loss: 0.697570, Val Acc: 0.508475\n",
            "Epoch 500/2000, Train Loss: 0.697582, Val Loss: 0.697530, Val Acc: 0.508475\n",
            "Epoch 600/2000, Train Loss: 0.697564, Val Loss: 0.697639, Val Acc: 0.474576\n",
            "Epoch 700/2000, Train Loss: 0.697545, Val Loss: 0.697517, Val Acc: 0.508475\n",
            "Epoch 800/2000, Train Loss: 0.697465, Val Loss: 0.697526, Val Acc: 0.491525\n",
            "Epoch 900/2000, Train Loss: 0.697473, Val Loss: 0.697480, Val Acc: 0.516949\n",
            "Epoch 1000/2000, Train Loss: 0.697375, Val Loss: 0.697499, Val Acc: 0.500000\n",
            "Epoch 1100/2000, Train Loss: 0.697419, Val Loss: 0.697534, Val Acc: 0.542373\n",
            "Epoch 1200/2000, Train Loss: 0.697447, Val Loss: 0.697511, Val Acc: 0.542373\n",
            "Epoch 1300/2000, Train Loss: 0.697290, Val Loss: 0.697443, Val Acc: 0.483051\n",
            "Epoch 1400/2000, Train Loss: 0.697116, Val Loss: 0.697363, Val Acc: 0.516949\n",
            "Epoch 1500/2000, Train Loss: 0.697192, Val Loss: 0.697370, Val Acc: 0.516949\n",
            "Epoch 1600/2000, Train Loss: 0.696932, Val Loss: 0.697300, Val Acc: 0.516949\n",
            "Epoch 1700/2000, Train Loss: 0.696800, Val Loss: 0.697185, Val Acc: 0.525424\n",
            "Epoch 1800/2000, Train Loss: 0.696853, Val Loss: 0.697012, Val Acc: 0.516949\n",
            "Epoch 1900/2000, Train Loss: 0.696034, Val Loss: 0.696846, Val Acc: 0.516949\n",
            "Epoch 2000/2000, Train Loss: 0.695872, Val Loss: 0.696606, Val Acc: 0.559322\n",
            "Test Loss: 0.6955783367156982 Test Accuracy: 0.6081081081081081\n",
            "weighted: Test F1: 0.6955783367156982 Test Precision: 0.6081081081081081 Test Recall: 0.6081081081081081\n",
            "[[49 22]\n",
            " [36 41]]\n",
            "[Trial 28] Test acc: 0.6081081081081081, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:07:19,954] Trial 28 finished with value: 0.6081081081081081 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.008826623112449505, 'learning_rate': 0.006877670555401052, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.007119668866298869}\n",
            "Epoch 100/1500, Train Loss: 0.696754, Val Loss: 0.696596, Val Acc: 0.593220\n",
            "Epoch 200/1500, Train Loss: 0.696675, Val Loss: 0.696590, Val Acc: 0.584746\n",
            "Epoch 300/1500, Train Loss: 0.696583, Val Loss: 0.696548, Val Acc: 0.584746\n",
            "Epoch 400/1500, Train Loss: 0.696641, Val Loss: 0.696536, Val Acc: 0.567797\n",
            "Epoch 500/1500, Train Loss: 0.696597, Val Loss: 0.696409, Val Acc: 0.542373\n",
            "Epoch 600/1500, Train Loss: 0.696461, Val Loss: 0.696456, Val Acc: 0.576271\n",
            "Epoch 700/1500, Train Loss: 0.696418, Val Loss: 0.696411, Val Acc: 0.576271\n",
            "Epoch 800/1500, Train Loss: 0.696335, Val Loss: 0.696352, Val Acc: 0.610169\n",
            "Epoch 900/1500, Train Loss: 0.696337, Val Loss: 0.696316, Val Acc: 0.618644\n",
            "Epoch 1000/1500, Train Loss: 0.696131, Val Loss: 0.696205, Val Acc: 0.618644\n",
            "Epoch 1100/1500, Train Loss: 0.696241, Val Loss: 0.696153, Val Acc: 0.652542\n",
            "Epoch 1200/1500, Train Loss: 0.695849, Val Loss: 0.696024, Val Acc: 0.644068\n",
            "Epoch 1300/1500, Train Loss: 0.696000, Val Loss: 0.695884, Val Acc: 0.644068\n",
            "Epoch 1400/1500, Train Loss: 0.695756, Val Loss: 0.695649, Val Acc: 0.644068\n",
            "Epoch 1500/1500, Train Loss: 0.694914, Val Loss: 0.695389, Val Acc: 0.652542\n",
            "Test Loss: 0.6957355737686157 Test Accuracy: 0.581081081081081\n",
            "weighted: Test F1: 0.6957355737686157 Test Precision: 0.581081081081081 Test Recall: 0.581081081081081\n",
            "[[49 22]\n",
            " [40 37]]\n",
            "[Trial 29] Test acc: 0.581081081081081, Best val acc: 0.652542372881356\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:08:24,332] Trial 29 finished with value: 0.581081081081081 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.007119668866298869, 'learning_rate': 0.004877685048067093, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005352195655307629}\n",
            "Epoch 100/1000, Train Loss: 0.693689, Val Loss: 0.693527, Val Acc: 0.584746\n",
            "Epoch 200/1000, Train Loss: 0.691543, Val Loss: 0.692002, Val Acc: 0.550847\n",
            "Epoch 300/1000, Train Loss: 0.686428, Val Loss: 0.689383, Val Acc: 0.542373\n",
            "Epoch 400/1000, Train Loss: 0.678250, Val Loss: 0.683663, Val Acc: 0.584746\n",
            "Epoch 500/1000, Train Loss: 0.665292, Val Loss: 0.672538, Val Acc: 0.669492\n",
            "Epoch 600/1000, Train Loss: 0.639046, Val Loss: 0.649638, Val Acc: 0.694915\n",
            "Epoch 700/1000, Train Loss: 0.591753, Val Loss: 0.608749, Val Acc: 0.694915\n",
            "Epoch 800/1000, Train Loss: 0.530637, Val Loss: 0.567332, Val Acc: 0.737288\n",
            "Epoch 900/1000, Train Loss: 0.501402, Val Loss: 0.546394, Val Acc: 0.720339\n",
            "Epoch 1000/1000, Train Loss: 0.451477, Val Loss: 0.542449, Val Acc: 0.728814\n",
            "Test Loss: 0.5242218971252441 Test Accuracy: 0.7432432432432432\n",
            "weighted: Test F1: 0.5242218971252441 Test Precision: 0.7432432432432432 Test Recall: 0.7432432432432432\n",
            "[[61 10]\n",
            " [28 49]]\n",
            "[Trial 30] Test acc: 0.7432432432432432, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:09:05,321] Trial 30 finished with value: 0.7432432432432432 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005352195655307629, 'learning_rate': 0.005175800444806833, 'num_epoch': 1000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007198255123734068}\n",
            "Epoch 100/2000, Train Loss: 0.696811, Val Loss: 0.696659, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.696221, Val Loss: 0.696392, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.695930, Val Loss: 0.696112, Val Acc: 0.584746\n",
            "Epoch 400/2000, Train Loss: 0.695456, Val Loss: 0.695751, Val Acc: 0.576271\n",
            "Epoch 500/2000, Train Loss: 0.694164, Val Loss: 0.695261, Val Acc: 0.618644\n",
            "Epoch 600/2000, Train Loss: 0.694328, Val Loss: 0.694582, Val Acc: 0.618644\n",
            "Epoch 700/2000, Train Loss: 0.693075, Val Loss: 0.693726, Val Acc: 0.618644\n",
            "Epoch 800/2000, Train Loss: 0.691176, Val Loss: 0.692489, Val Acc: 0.627119\n",
            "Epoch 900/2000, Train Loss: 0.689636, Val Loss: 0.690970, Val Acc: 0.652542\n",
            "Epoch 1000/2000, Train Loss: 0.685161, Val Loss: 0.688621, Val Acc: 0.652542\n",
            "Epoch 1100/2000, Train Loss: 0.685867, Val Loss: 0.685307, Val Acc: 0.661017\n",
            "Epoch 1200/2000, Train Loss: 0.676269, Val Loss: 0.680623, Val Acc: 0.661017\n",
            "Epoch 1300/2000, Train Loss: 0.669727, Val Loss: 0.674007, Val Acc: 0.677966\n",
            "Epoch 1400/2000, Train Loss: 0.665366, Val Loss: 0.664598, Val Acc: 0.703390\n",
            "Epoch 1500/2000, Train Loss: 0.644603, Val Loss: 0.651889, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.621884, Val Loss: 0.634482, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.599128, Val Loss: 0.612092, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.565906, Val Loss: 0.590884, Val Acc: 0.745763\n",
            "Epoch 1900/2000, Train Loss: 0.536432, Val Loss: 0.573076, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.526942, Val Loss: 0.560256, Val Acc: 0.720339\n",
            "Test Loss: 0.5380957722663879 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.5380957722663879 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[56 15]\n",
            " [26 51]]\n",
            "[Trial 31] Test acc: 0.722972972972973, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:10:26,212] Trial 31 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007198255123734068, 'learning_rate': 0.0025346670373303467, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007694954483272911}\n",
            "Epoch 100/2000, Train Loss: 0.697103, Val Loss: 0.697164, Val Acc: 0.415254\n",
            "Epoch 200/2000, Train Loss: 0.696894, Val Loss: 0.697142, Val Acc: 0.474576\n",
            "Epoch 300/2000, Train Loss: 0.697001, Val Loss: 0.697195, Val Acc: 0.389831\n",
            "Epoch 400/2000, Train Loss: 0.696908, Val Loss: 0.697173, Val Acc: 0.415254\n",
            "Epoch 500/2000, Train Loss: 0.696915, Val Loss: 0.697184, Val Acc: 0.415254\n",
            "Epoch 600/2000, Train Loss: 0.696894, Val Loss: 0.697195, Val Acc: 0.423729\n",
            "Epoch 700/2000, Train Loss: 0.697037, Val Loss: 0.697147, Val Acc: 0.457627\n",
            "Epoch 800/2000, Train Loss: 0.696746, Val Loss: 0.697187, Val Acc: 0.432203\n",
            "Epoch 900/2000, Train Loss: 0.696810, Val Loss: 0.697170, Val Acc: 0.423729\n",
            "Epoch 1000/2000, Train Loss: 0.696619, Val Loss: 0.697148, Val Acc: 0.449153\n",
            "Epoch 1100/2000, Train Loss: 0.696496, Val Loss: 0.697160, Val Acc: 0.423729\n",
            "Epoch 1200/2000, Train Loss: 0.696638, Val Loss: 0.697173, Val Acc: 0.466102\n",
            "Epoch 1300/2000, Train Loss: 0.696493, Val Loss: 0.697171, Val Acc: 0.466102\n",
            "Epoch 1400/2000, Train Loss: 0.696460, Val Loss: 0.697130, Val Acc: 0.432203\n",
            "Epoch 1500/2000, Train Loss: 0.696437, Val Loss: 0.697100, Val Acc: 0.449153\n",
            "Epoch 1600/2000, Train Loss: 0.696163, Val Loss: 0.697090, Val Acc: 0.457627\n",
            "Epoch 1700/2000, Train Loss: 0.695942, Val Loss: 0.697018, Val Acc: 0.483051\n",
            "Epoch 1800/2000, Train Loss: 0.696012, Val Loss: 0.696946, Val Acc: 0.500000\n",
            "Epoch 1900/2000, Train Loss: 0.695668, Val Loss: 0.696903, Val Acc: 0.516949\n",
            "Epoch 2000/2000, Train Loss: 0.695647, Val Loss: 0.696807, Val Acc: 0.525424\n",
            "Test Loss: 0.6955145597457886 Test Accuracy: 0.6216216216216216\n",
            "weighted: Test F1: 0.6955145597457886 Test Precision: 0.6216216216216216 Test Recall: 0.6216216216216216\n",
            "[[44 27]\n",
            " [29 48]]\n",
            "[Trial 32] Test acc: 0.6216216216216216, Best val acc: 0.5254237288135594\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:11:47,411] Trial 32 finished with value: 0.6216216216216216 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007694954483272911, 'learning_rate': 0.0025851614343627978, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006100009286765558}\n",
            "Epoch 100/2000, Train Loss: 0.694803, Val Loss: 0.696646, Val Acc: 0.508475\n",
            "Epoch 200/2000, Train Loss: 0.693812, Val Loss: 0.695996, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.690852, Val Loss: 0.694983, Val Acc: 0.567797\n",
            "Epoch 400/2000, Train Loss: 0.690813, Val Loss: 0.693416, Val Acc: 0.584746\n",
            "Epoch 500/2000, Train Loss: 0.684164, Val Loss: 0.690371, Val Acc: 0.576271\n",
            "Epoch 600/2000, Train Loss: 0.674468, Val Loss: 0.684300, Val Acc: 0.584746\n",
            "Epoch 700/2000, Train Loss: 0.660102, Val Loss: 0.670741, Val Acc: 0.601695\n",
            "Epoch 800/2000, Train Loss: 0.637995, Val Loss: 0.645659, Val Acc: 0.652542\n",
            "Epoch 900/2000, Train Loss: 0.594825, Val Loss: 0.607568, Val Acc: 0.762712\n",
            "Epoch 1000/2000, Train Loss: 0.553955, Val Loss: 0.568695, Val Acc: 0.771186\n",
            "Epoch 1100/2000, Train Loss: 0.510695, Val Loss: 0.541703, Val Acc: 0.745763\n",
            "Epoch 1200/2000, Train Loss: 0.470708, Val Loss: 0.529881, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.452259, Val Loss: 0.532098, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.427914, Val Loss: 0.540600, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.410378, Val Loss: 0.543042, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.431503, Val Loss: 0.547511, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.406623, Val Loss: 0.552019, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.415075, Val Loss: 0.553504, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.405874, Val Loss: 0.561397, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.386445, Val Loss: 0.569792, Val Acc: 0.737288\n",
            "Test Loss: 0.5413085222244263 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5413085222244263 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[56 15]\n",
            " [22 55]]\n",
            "[Trial 33] Test acc: 0.75, Best val acc: 0.7711864406779662\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:13:09,317] Trial 33 finished with value: 0.75 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006100009286765558, 'learning_rate': 0.00405547194031753, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.005988746671082697}\n",
            "Epoch 100/500, Train Loss: 0.691710, Val Loss: 0.692477, Val Acc: 0.559322\n",
            "Epoch 200/500, Train Loss: 0.678225, Val Loss: 0.681612, Val Acc: 0.567797\n",
            "Epoch 300/500, Train Loss: 0.648650, Val Loss: 0.654496, Val Acc: 0.686441\n",
            "Epoch 400/500, Train Loss: 0.577153, Val Loss: 0.591838, Val Acc: 0.745763\n",
            "Epoch 500/500, Train Loss: 0.495403, Val Loss: 0.548209, Val Acc: 0.728814\n",
            "Test Loss: 0.5341693758964539 Test Accuracy: 0.7162162162162162\n",
            "weighted: Test F1: 0.5341693758964539 Test Precision: 0.7162162162162162 Test Recall: 0.7162162162162162\n",
            "[[54 17]\n",
            " [25 52]]\n",
            "[Trial 34] Test acc: 0.7162162162162162, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:13:30,047] Trial 34 finished with value: 0.7162162162162162 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.005988746671082697, 'learning_rate': 0.008320841334593933, 'num_epoch': 500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.006260289404999844}\n",
            "Epoch 100/200, Train Loss: 0.694869, Val Loss: 0.693844, Val Acc: 0.618644\n",
            "Epoch 200/200, Train Loss: 0.691268, Val Loss: 0.691290, Val Acc: 0.610169\n",
            "Test Loss: 0.6926655769348145 Test Accuracy: 0.581081081081081\n",
            "weighted: Test F1: 0.6926655769348145 Test Precision: 0.581081081081081 Test Recall: 0.581081081081081\n",
            "[[38 33]\n",
            " [29 48]]\n",
            "[Trial 35] Test acc: 0.581081081081081, Best val acc: 0.6186440677966102\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:13:38,256] Trial 35 finished with value: 0.581081081081081 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.006260289404999844, 'learning_rate': 0.003992383331063228, 'num_epoch': 200}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.005801389909907241}\n",
            "Epoch 100/2000, Train Loss: 0.696200, Val Loss: 0.696046, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.696197, Val Loss: 0.696046, Val Acc: 0.533898\n",
            "Epoch 300/2000, Train Loss: 0.696130, Val Loss: 0.696044, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.696204, Val Loss: 0.695986, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.696194, Val Loss: 0.696048, Val Acc: 0.491525\n",
            "Epoch 600/2000, Train Loss: 0.696168, Val Loss: 0.696028, Val Acc: 0.525424\n",
            "Epoch 700/2000, Train Loss: 0.696225, Val Loss: 0.696091, Val Acc: 0.474576\n",
            "Epoch 800/2000, Train Loss: 0.696150, Val Loss: 0.696084, Val Acc: 0.474576\n",
            "Epoch 900/2000, Train Loss: 0.696191, Val Loss: 0.696096, Val Acc: 0.474576\n",
            "Epoch 1000/2000, Train Loss: 0.696159, Val Loss: 0.696033, Val Acc: 0.525424\n",
            "Epoch 1100/2000, Train Loss: 0.696204, Val Loss: 0.695963, Val Acc: 0.525424\n",
            "Epoch 1200/2000, Train Loss: 0.696210, Val Loss: 0.696116, Val Acc: 0.474576\n",
            "Epoch 1300/2000, Train Loss: 0.696142, Val Loss: 0.696071, Val Acc: 0.474576\n",
            "Epoch 1400/2000, Train Loss: 0.696162, Val Loss: 0.696044, Val Acc: 0.406780\n",
            "Epoch 1500/2000, Train Loss: 0.696243, Val Loss: 0.696037, Val Acc: 0.483051\n",
            "Epoch 1600/2000, Train Loss: 0.696152, Val Loss: 0.696051, Val Acc: 0.474576\n",
            "Epoch 1700/2000, Train Loss: 0.696161, Val Loss: 0.695979, Val Acc: 0.525424\n",
            "Epoch 1800/2000, Train Loss: 0.696226, Val Loss: 0.695925, Val Acc: 0.525424\n",
            "Epoch 1900/2000, Train Loss: 0.696200, Val Loss: 0.696033, Val Acc: 0.576271\n",
            "Epoch 2000/2000, Train Loss: 0.696167, Val Loss: 0.695990, Val Acc: 0.525424\n",
            "Test Loss: 0.6960686445236206 Test Accuracy: 0.4797297297297297\n",
            "weighted: Test F1: 0.6960686445236206 Test Precision: 0.4797297297297297 Test Recall: 0.4797297297297297\n",
            "[[71  0]\n",
            " [77  0]]\n",
            "[Trial 36] Test acc: 0.4797297297297297, Best val acc: 0.576271186440678\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:15:04,806] Trial 36 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.005801389909907241, 'learning_rate': 0.004933537684385303, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'tanh', 'lam': 0.006637903155062285}\n",
            "Epoch 100/500, Train Loss: 0.697069, Val Loss: 0.697009, Val Acc: 0.423729\n",
            "Epoch 200/500, Train Loss: 0.696834, Val Loss: 0.696855, Val Acc: 0.449153\n",
            "Epoch 300/500, Train Loss: 0.696740, Val Loss: 0.696702, Val Acc: 0.449153\n",
            "Epoch 400/500, Train Loss: 0.696647, Val Loss: 0.696597, Val Acc: 0.457627\n",
            "Epoch 500/500, Train Loss: 0.696690, Val Loss: 0.696455, Val Acc: 0.500000\n",
            "Test Loss: 0.6963998675346375 Test Accuracy: 0.5202702702702703\n",
            "weighted: Test F1: 0.6963998675346375 Test Precision: 0.5202702702702703 Test Recall: 0.5202702702702703\n",
            "[[40 31]\n",
            " [40 37]]\n",
            "[Trial 37] Test acc: 0.5202702702702703, Best val acc: 0.5\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:15:25,608] Trial 37 finished with value: 0.5202702702702703 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'tanh', 'lam': 0.006637903155062285, 'learning_rate': 0.0036668586707788485, 'num_epoch': 500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.006111449549725539}\n",
            "Epoch 100/1500, Train Loss: 0.696183, Val Loss: 0.696201, Val Acc: 0.406780\n",
            "Epoch 200/1500, Train Loss: 0.696185, Val Loss: 0.696159, Val Acc: 0.542373\n",
            "Epoch 300/1500, Train Loss: 0.696140, Val Loss: 0.696155, Val Acc: 0.550847\n",
            "Epoch 400/1500, Train Loss: 0.696124, Val Loss: 0.696173, Val Acc: 0.466102\n",
            "Epoch 500/1500, Train Loss: 0.696151, Val Loss: 0.696160, Val Acc: 0.483051\n",
            "Epoch 600/1500, Train Loss: 0.696038, Val Loss: 0.696123, Val Acc: 0.533898\n",
            "Epoch 700/1500, Train Loss: 0.696121, Val Loss: 0.696107, Val Acc: 0.559322\n",
            "Epoch 800/1500, Train Loss: 0.696079, Val Loss: 0.696146, Val Acc: 0.500000\n",
            "Epoch 900/1500, Train Loss: 0.696008, Val Loss: 0.696134, Val Acc: 0.525424\n",
            "Epoch 1000/1500, Train Loss: 0.696069, Val Loss: 0.696146, Val Acc: 0.483051\n",
            "Epoch 1100/1500, Train Loss: 0.696000, Val Loss: 0.696145, Val Acc: 0.483051\n",
            "Epoch 1200/1500, Train Loss: 0.696023, Val Loss: 0.696138, Val Acc: 0.491525\n",
            "Epoch 1300/1500, Train Loss: 0.696056, Val Loss: 0.696144, Val Acc: 0.542373\n",
            "Epoch 1400/1500, Train Loss: 0.696089, Val Loss: 0.696115, Val Acc: 0.525424\n",
            "Epoch 1500/1500, Train Loss: 0.696056, Val Loss: 0.696067, Val Acc: 0.559322\n",
            "Test Loss: 0.6960433125495911 Test Accuracy: 0.5405405405405406\n",
            "weighted: Test F1: 0.6960433125495911 Test Precision: 0.5405405405405406 Test Recall: 0.5405405405405406\n",
            "[[57 14]\n",
            " [54 23]]\n",
            "[Trial 38] Test acc: 0.5405405405405406, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:16:30,358] Trial 38 finished with value: 0.5405405405405406 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'l_relu', 'lam': 0.006111449549725539, 'learning_rate': 0.0015911433862497053, 'num_epoch': 1500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006344825791546517}\n",
            "Epoch 100/2000, Train Loss: 0.694142, Val Loss: 0.695799, Val Acc: 0.500000\n",
            "Epoch 200/2000, Train Loss: 0.689986, Val Loss: 0.693225, Val Acc: 0.567797\n",
            "Epoch 300/2000, Train Loss: 0.679512, Val Loss: 0.686780, Val Acc: 0.635593\n",
            "Epoch 400/2000, Train Loss: 0.658248, Val Loss: 0.666475, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.598929, Val Loss: 0.612479, Val Acc: 0.720339\n",
            "Epoch 600/2000, Train Loss: 0.522089, Val Loss: 0.565012, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.463070, Val Loss: 0.552539, Val Acc: 0.703390\n",
            "Epoch 800/2000, Train Loss: 0.443532, Val Loss: 0.551798, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.435818, Val Loss: 0.559430, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.417240, Val Loss: 0.563112, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.416397, Val Loss: 0.578130, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.398238, Val Loss: 0.592964, Val Acc: 0.686441\n",
            "Epoch 1300/2000, Train Loss: 0.384996, Val Loss: 0.596972, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.359739, Val Loss: 0.605875, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.346223, Val Loss: 0.618357, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.335238, Val Loss: 0.635308, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.306912, Val Loss: 0.655550, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.306601, Val Loss: 0.681285, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.282806, Val Loss: 0.695150, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.266112, Val Loss: 0.717366, Val Acc: 0.737288\n",
            "Test Loss: 0.6006376147270203 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.6006376147270203 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[53 18]\n",
            " [21 56]]\n",
            "[Trial 39] Test acc: 0.7364864864864865, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:17:52,250] Trial 39 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006344825791546517, 'learning_rate': 0.0069522215058383414, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.005736034427718515}\n",
            "Epoch 100/2000, Train Loss: 0.696210, Val Loss: 0.696868, Val Acc: 0.474576\n",
            "Epoch 200/2000, Train Loss: 0.696168, Val Loss: 0.696092, Val Acc: 0.372881\n",
            "Epoch 300/2000, Train Loss: 0.696126, Val Loss: 0.696117, Val Acc: 0.440678\n",
            "Epoch 400/2000, Train Loss: 0.696062, Val Loss: 0.696052, Val Acc: 0.508475\n",
            "Epoch 500/2000, Train Loss: 0.696074, Val Loss: 0.696104, Val Acc: 0.415254\n",
            "Epoch 600/2000, Train Loss: 0.696061, Val Loss: 0.696105, Val Acc: 0.440678\n",
            "Epoch 700/2000, Train Loss: 0.696027, Val Loss: 0.696050, Val Acc: 0.491525\n",
            "Epoch 800/2000, Train Loss: 0.696033, Val Loss: 0.696104, Val Acc: 0.449153\n",
            "Epoch 900/2000, Train Loss: 0.696010, Val Loss: 0.696081, Val Acc: 0.449153\n",
            "Epoch 1000/2000, Train Loss: 0.696047, Val Loss: 0.696028, Val Acc: 0.533898\n",
            "Epoch 1100/2000, Train Loss: 0.696056, Val Loss: 0.696034, Val Acc: 0.500000\n",
            "Epoch 1200/2000, Train Loss: 0.696037, Val Loss: 0.696022, Val Acc: 0.533898\n",
            "Epoch 1300/2000, Train Loss: 0.696022, Val Loss: 0.696050, Val Acc: 0.415254\n",
            "Epoch 1400/2000, Train Loss: 0.696011, Val Loss: 0.696061, Val Acc: 0.449153\n",
            "Epoch 1500/2000, Train Loss: 0.696024, Val Loss: 0.696054, Val Acc: 0.440678\n",
            "Epoch 1600/2000, Train Loss: 0.696024, Val Loss: 0.696058, Val Acc: 0.440678\n",
            "Epoch 1700/2000, Train Loss: 0.696021, Val Loss: 0.696035, Val Acc: 0.491525\n",
            "Epoch 1800/2000, Train Loss: 0.696019, Val Loss: 0.695985, Val Acc: 0.559322\n",
            "Epoch 1900/2000, Train Loss: 0.695999, Val Loss: 0.696133, Val Acc: 0.491525\n",
            "Epoch 2000/2000, Train Loss: 0.696006, Val Loss: 0.695998, Val Acc: 0.508475\n",
            "Test Loss: 0.696104109287262 Test Accuracy: 0.4864864864864865\n",
            "weighted: Test F1: 0.696104109287262 Test Precision: 0.4864864864864865 Test Recall: 0.4864864864864865\n",
            "[[51 20]\n",
            " [56 21]]\n",
            "[Trial 40] Test acc: 0.4864864864864865, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:19:13,767] Trial 40 finished with value: 0.4864864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.005736034427718515, 'learning_rate': 0.0006402440130226293, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006938112596332388}\n",
            "Epoch 100/2000, Train Loss: 0.694829, Val Loss: 0.695164, Val Acc: 0.559322\n",
            "Epoch 200/2000, Train Loss: 0.693453, Val Loss: 0.693892, Val Acc: 0.533898\n",
            "Epoch 300/2000, Train Loss: 0.691336, Val Loss: 0.692108, Val Acc: 0.567797\n",
            "Epoch 400/2000, Train Loss: 0.688241, Val Loss: 0.689990, Val Acc: 0.584746\n",
            "Epoch 500/2000, Train Loss: 0.685940, Val Loss: 0.687263, Val Acc: 0.593220\n",
            "Epoch 600/2000, Train Loss: 0.681443, Val Loss: 0.683346, Val Acc: 0.601695\n",
            "Epoch 700/2000, Train Loss: 0.674438, Val Loss: 0.677523, Val Acc: 0.610169\n",
            "Epoch 800/2000, Train Loss: 0.663713, Val Loss: 0.669192, Val Acc: 0.627119\n",
            "Epoch 900/2000, Train Loss: 0.654435, Val Loss: 0.657580, Val Acc: 0.669492\n",
            "Epoch 1000/2000, Train Loss: 0.634746, Val Loss: 0.641175, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.620629, Val Loss: 0.618718, Val Acc: 0.771186\n",
            "Epoch 1200/2000, Train Loss: 0.586717, Val Loss: 0.594924, Val Acc: 0.771186\n",
            "Epoch 1300/2000, Train Loss: 0.558392, Val Loss: 0.574280, Val Acc: 0.745763\n",
            "Epoch 1400/2000, Train Loss: 0.528865, Val Loss: 0.556282, Val Acc: 0.745763\n",
            "Epoch 1500/2000, Train Loss: 0.507369, Val Loss: 0.543580, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.479141, Val Loss: 0.535969, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.462561, Val Loss: 0.533144, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.462282, Val Loss: 0.534135, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.455318, Val Loss: 0.534633, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.446999, Val Loss: 0.535456, Val Acc: 0.720339\n",
            "Test Loss: 0.5281111001968384 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5281111001968384 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[62  9]\n",
            " [28 49]]\n",
            "[Trial 41] Test acc: 0.75, Best val acc: 0.7711864406779662\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:20:35,238] Trial 41 finished with value: 0.75 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006938112596332388, 'learning_rate': 0.0023757737893388606, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006779321210828323}\n",
            "Epoch 100/2000, Train Loss: 0.694997, Val Loss: 0.693423, Val Acc: 0.593220\n",
            "Epoch 200/2000, Train Loss: 0.693243, Val Loss: 0.692001, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.690462, Val Loss: 0.689925, Val Acc: 0.567797\n",
            "Epoch 400/2000, Train Loss: 0.687935, Val Loss: 0.686841, Val Acc: 0.593220\n",
            "Epoch 500/2000, Train Loss: 0.683792, Val Loss: 0.682226, Val Acc: 0.644068\n",
            "Epoch 600/2000, Train Loss: 0.675551, Val Loss: 0.675592, Val Acc: 0.644068\n",
            "Epoch 700/2000, Train Loss: 0.661372, Val Loss: 0.665826, Val Acc: 0.669492\n",
            "Epoch 800/2000, Train Loss: 0.644602, Val Loss: 0.651134, Val Acc: 0.686441\n",
            "Epoch 900/2000, Train Loss: 0.624613, Val Loss: 0.629415, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.591166, Val Loss: 0.601457, Val Acc: 0.762712\n",
            "Epoch 1100/2000, Train Loss: 0.560716, Val Loss: 0.576096, Val Acc: 0.754237\n",
            "Epoch 1200/2000, Train Loss: 0.529417, Val Loss: 0.556682, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.499886, Val Loss: 0.543113, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.475668, Val Loss: 0.537994, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.465740, Val Loss: 0.537386, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.446863, Val Loss: 0.537485, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.427014, Val Loss: 0.538368, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.434174, Val Loss: 0.536148, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.440916, Val Loss: 0.542110, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.429443, Val Loss: 0.545168, Val Acc: 0.728814\n",
            "Test Loss: 0.529526948928833 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.529526948928833 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[61 10]\n",
            " [24 53]]\n",
            "[Trial 42] Test acc: 0.7702702702702703, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:21:56,474] Trial 42 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006779321210828323, 'learning_rate': 0.0029447556507853443, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.00693097917498089}\n",
            "Epoch 100/2000, Train Loss: 0.697088, Val Loss: 0.695366, Val Acc: 0.576271\n",
            "Epoch 200/2000, Train Loss: 0.696324, Val Loss: 0.695284, Val Acc: 0.584746\n",
            "Epoch 300/2000, Train Loss: 0.696207, Val Loss: 0.695184, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.695726, Val Loss: 0.695068, Val Acc: 0.584746\n",
            "Epoch 500/2000, Train Loss: 0.695161, Val Loss: 0.694919, Val Acc: 0.635593\n",
            "Epoch 600/2000, Train Loss: 0.695143, Val Loss: 0.694783, Val Acc: 0.661017\n",
            "Epoch 700/2000, Train Loss: 0.695143, Val Loss: 0.694648, Val Acc: 0.635593\n",
            "Epoch 800/2000, Train Loss: 0.694716, Val Loss: 0.694523, Val Acc: 0.644068\n",
            "Epoch 900/2000, Train Loss: 0.694689, Val Loss: 0.694357, Val Acc: 0.627119\n",
            "Epoch 1000/2000, Train Loss: 0.694024, Val Loss: 0.694170, Val Acc: 0.627119\n",
            "Epoch 1100/2000, Train Loss: 0.693400, Val Loss: 0.693937, Val Acc: 0.601695\n",
            "Epoch 1200/2000, Train Loss: 0.691900, Val Loss: 0.693661, Val Acc: 0.593220\n",
            "Epoch 1300/2000, Train Loss: 0.692778, Val Loss: 0.693350, Val Acc: 0.593220\n",
            "Epoch 1400/2000, Train Loss: 0.693127, Val Loss: 0.693000, Val Acc: 0.601695\n",
            "Epoch 1500/2000, Train Loss: 0.692631, Val Loss: 0.692585, Val Acc: 0.601695\n",
            "Epoch 1600/2000, Train Loss: 0.691765, Val Loss: 0.692145, Val Acc: 0.610169\n",
            "Epoch 1700/2000, Train Loss: 0.689930, Val Loss: 0.691591, Val Acc: 0.610169\n",
            "Epoch 1800/2000, Train Loss: 0.687692, Val Loss: 0.690968, Val Acc: 0.610169\n",
            "Epoch 1900/2000, Train Loss: 0.689089, Val Loss: 0.690237, Val Acc: 0.610169\n",
            "Epoch 2000/2000, Train Loss: 0.687387, Val Loss: 0.689398, Val Acc: 0.610169\n",
            "Test Loss: 0.6887273788452148 Test Accuracy: 0.5675675675675675\n",
            "weighted: Test F1: 0.6887273788452148 Test Precision: 0.5675675675675675 Test Recall: 0.5675675675675675\n",
            "[[40 31]\n",
            " [33 44]]\n",
            "[Trial 43] Test acc: 0.5675675675675675, Best val acc: 0.6610169491525424\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:23:17,460] Trial 43 finished with value: 0.5675675675675675 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.00693097917498089, 'learning_rate': 0.0009194834829071877, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007364090654488972}\n",
            "Epoch 100/2000, Train Loss: 0.695641, Val Loss: 0.696883, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.695008, Val Loss: 0.696519, Val Acc: 0.491525\n",
            "Epoch 300/2000, Train Loss: 0.693023, Val Loss: 0.696020, Val Acc: 0.508475\n",
            "Epoch 400/2000, Train Loss: 0.691269, Val Loss: 0.695287, Val Acc: 0.550847\n",
            "Epoch 500/2000, Train Loss: 0.690711, Val Loss: 0.693865, Val Acc: 0.584746\n",
            "Epoch 600/2000, Train Loss: 0.686520, Val Loss: 0.691246, Val Acc: 0.576271\n",
            "Epoch 700/2000, Train Loss: 0.677848, Val Loss: 0.686720, Val Acc: 0.584746\n",
            "Epoch 800/2000, Train Loss: 0.674265, Val Loss: 0.678753, Val Acc: 0.618644\n",
            "Epoch 900/2000, Train Loss: 0.653055, Val Loss: 0.664567, Val Acc: 0.652542\n",
            "Epoch 1000/2000, Train Loss: 0.633418, Val Loss: 0.642245, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.602397, Val Loss: 0.610591, Val Acc: 0.745763\n",
            "Epoch 1200/2000, Train Loss: 0.563478, Val Loss: 0.582839, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.515776, Val Loss: 0.560371, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.484636, Val Loss: 0.548533, Val Acc: 0.703390\n",
            "Epoch 1500/2000, Train Loss: 0.456493, Val Loss: 0.545452, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.448610, Val Loss: 0.544338, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.434553, Val Loss: 0.546493, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.426888, Val Loss: 0.549899, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.428118, Val Loss: 0.552527, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.411196, Val Loss: 0.558629, Val Acc: 0.711864\n",
            "Test Loss: 0.5232239365577698 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5232239365577698 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[63  8]\n",
            " [29 48]]\n",
            "[Trial 44] Test acc: 0.75, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:24:38,951] Trial 44 finished with value: 0.75 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007364090654488972, 'learning_rate': 0.0032702205288452153, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006878203663049806}\n",
            "Epoch 100/2000, Train Loss: 0.695964, Val Loss: 0.696113, Val Acc: 0.500000\n",
            "Epoch 200/2000, Train Loss: 0.694183, Val Loss: 0.695292, Val Acc: 0.508475\n",
            "Epoch 300/2000, Train Loss: 0.690542, Val Loss: 0.692997, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.686081, Val Loss: 0.687811, Val Acc: 0.677966\n",
            "Epoch 500/2000, Train Loss: 0.666892, Val Loss: 0.675354, Val Acc: 0.669492\n",
            "Epoch 600/2000, Train Loss: 0.642982, Val Loss: 0.646082, Val Acc: 0.686441\n",
            "Epoch 700/2000, Train Loss: 0.580363, Val Loss: 0.594957, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.516945, Val Loss: 0.556019, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.478522, Val Loss: 0.545662, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.452050, Val Loss: 0.545981, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.436235, Val Loss: 0.551814, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.425111, Val Loss: 0.560710, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.416453, Val Loss: 0.566319, Val Acc: 0.703390\n",
            "Epoch 1400/2000, Train Loss: 0.402622, Val Loss: 0.574808, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.390901, Val Loss: 0.584051, Val Acc: 0.703390\n",
            "Epoch 1600/2000, Train Loss: 0.387714, Val Loss: 0.585146, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.363626, Val Loss: 0.595465, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.367412, Val Loss: 0.598034, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.353664, Val Loss: 0.604501, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.336809, Val Loss: 0.616788, Val Acc: 0.745763\n",
            "Test Loss: 0.5601974129676819 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5601974129676819 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[60 11]\n",
            " [24 53]]\n",
            "[Trial 45] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:25:59,520] Trial 45 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006878203663049806, 'learning_rate': 0.005545725940910191, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006607085212597947}\n",
            "Epoch 100/2000, Train Loss: 0.696454, Val Loss: 0.696351, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.696311, Val Loss: 0.696326, Val Acc: 0.525424\n",
            "Epoch 300/2000, Train Loss: 0.696422, Val Loss: 0.696266, Val Acc: 0.550847\n",
            "Epoch 400/2000, Train Loss: 0.696354, Val Loss: 0.696219, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.696305, Val Loss: 0.696215, Val Acc: 0.576271\n",
            "Epoch 600/2000, Train Loss: 0.696249, Val Loss: 0.696158, Val Acc: 0.533898\n",
            "Epoch 700/2000, Train Loss: 0.696162, Val Loss: 0.696178, Val Acc: 0.610169\n",
            "Epoch 800/2000, Train Loss: 0.696202, Val Loss: 0.696008, Val Acc: 0.542373\n",
            "Epoch 900/2000, Train Loss: 0.696177, Val Loss: 0.695957, Val Acc: 0.533898\n",
            "Epoch 1000/2000, Train Loss: 0.696081, Val Loss: 0.695951, Val Acc: 0.533898\n",
            "Epoch 1100/2000, Train Loss: 0.696124, Val Loss: 0.695884, Val Acc: 0.542373\n",
            "Epoch 1200/2000, Train Loss: 0.696150, Val Loss: 0.695700, Val Acc: 0.516949\n",
            "Epoch 1300/2000, Train Loss: 0.695800, Val Loss: 0.695547, Val Acc: 0.533898\n",
            "Epoch 1400/2000, Train Loss: 0.695810, Val Loss: 0.695433, Val Acc: 0.525424\n",
            "Epoch 1500/2000, Train Loss: 0.695472, Val Loss: 0.695276, Val Acc: 0.593220\n",
            "Epoch 1600/2000, Train Loss: 0.694755, Val Loss: 0.694844, Val Acc: 0.525424\n",
            "Epoch 1700/2000, Train Loss: 0.694625, Val Loss: 0.694398, Val Acc: 0.542373\n",
            "Epoch 1800/2000, Train Loss: 0.693735, Val Loss: 0.693651, Val Acc: 0.542373\n",
            "Epoch 1900/2000, Train Loss: 0.693870, Val Loss: 0.692582, Val Acc: 0.559322\n",
            "Epoch 2000/2000, Train Loss: 0.690791, Val Loss: 0.690681, Val Acc: 0.593220\n",
            "Test Loss: 0.693665087223053 Test Accuracy: 0.5608108108108109\n",
            "weighted: Test F1: 0.693665087223053 Test Precision: 0.5608108108108109 Test Recall: 0.5608108108108109\n",
            "[[47 24]\n",
            " [41 36]]\n",
            "[Trial 46] Test acc: 0.5608108108108109, Best val acc: 0.6101694915254238\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:27:25,614] Trial 46 finished with value: 0.5608108108108109 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006607085212597947, 'learning_rate': 0.005380447593398052, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.008247278277211865}\n",
            "Epoch 100/2000, Train Loss: 0.697498, Val Loss: 0.697401, Val Acc: 0.474576\n",
            "Epoch 200/2000, Train Loss: 0.697216, Val Loss: 0.697190, Val Acc: 0.533898\n",
            "Epoch 300/2000, Train Loss: 0.697201, Val Loss: 0.697273, Val Acc: 0.474576\n",
            "Epoch 400/2000, Train Loss: 0.697158, Val Loss: 0.697237, Val Acc: 0.533898\n",
            "Epoch 500/2000, Train Loss: 0.697168, Val Loss: 0.697197, Val Acc: 0.550847\n",
            "Epoch 600/2000, Train Loss: 0.696973, Val Loss: 0.697127, Val Acc: 0.559322\n",
            "Epoch 700/2000, Train Loss: 0.697055, Val Loss: 0.697089, Val Acc: 0.550847\n",
            "Epoch 800/2000, Train Loss: 0.696783, Val Loss: 0.697113, Val Acc: 0.508475\n",
            "Epoch 900/2000, Train Loss: 0.696549, Val Loss: 0.696900, Val Acc: 0.584746\n",
            "Epoch 1000/2000, Train Loss: 0.696413, Val Loss: 0.696699, Val Acc: 0.576271\n",
            "Epoch 1100/2000, Train Loss: 0.695999, Val Loss: 0.696545, Val Acc: 0.584746\n",
            "Epoch 1200/2000, Train Loss: 0.695251, Val Loss: 0.696020, Val Acc: 0.610169\n",
            "Epoch 1300/2000, Train Loss: 0.694683, Val Loss: 0.694971, Val Acc: 0.635593\n",
            "Epoch 1400/2000, Train Loss: 0.689263, Val Loss: 0.692464, Val Acc: 0.661017\n",
            "Epoch 1500/2000, Train Loss: 0.677758, Val Loss: 0.683651, Val Acc: 0.669492\n",
            "Epoch 1600/2000, Train Loss: 0.623456, Val Loss: 0.640758, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.510877, Val Loss: 0.564962, Val Acc: 0.694915\n",
            "Epoch 1800/2000, Train Loss: 0.457395, Val Loss: 0.549580, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.450444, Val Loss: 0.547224, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.434627, Val Loss: 0.545064, Val Acc: 0.745763\n",
            "Test Loss: 0.548433780670166 Test Accuracy: 0.7094594594594594\n",
            "weighted: Test F1: 0.548433780670166 Test Precision: 0.7094594594594594 Test Recall: 0.7094594594594594\n",
            "[[60 11]\n",
            " [32 45]]\n",
            "[Trial 47] Test acc: 0.7094594594594594, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:28:51,578] Trial 47 finished with value: 0.7094594594594594 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.008247278277211865, 'learning_rate': 0.008210593252137403, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.005007078162803566}\n",
            "Epoch 100/2000, Train Loss: 0.689280, Val Loss: 0.691940, Val Acc: 0.576271\n",
            "Epoch 200/2000, Train Loss: 0.679801, Val Loss: 0.684848, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.659483, Val Loss: 0.670971, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.642295, Val Loss: 0.645157, Val Acc: 0.728814\n",
            "Epoch 500/2000, Train Loss: 0.582031, Val Loss: 0.605795, Val Acc: 0.728814\n",
            "Epoch 600/2000, Train Loss: 0.542271, Val Loss: 0.573600, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.503284, Val Loss: 0.555875, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.481126, Val Loss: 0.550042, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.457764, Val Loss: 0.549591, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.448838, Val Loss: 0.551082, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.450275, Val Loss: 0.554824, Val Acc: 0.745763\n",
            "Epoch 1200/2000, Train Loss: 0.437076, Val Loss: 0.555509, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.425904, Val Loss: 0.556704, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.444067, Val Loss: 0.560243, Val Acc: 0.745763\n",
            "Epoch 1500/2000, Train Loss: 0.440694, Val Loss: 0.564932, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.437016, Val Loss: 0.567622, Val Acc: 0.745763\n",
            "Epoch 1700/2000, Train Loss: 0.439289, Val Loss: 0.568944, Val Acc: 0.745763\n",
            "Epoch 1800/2000, Train Loss: 0.432152, Val Loss: 0.571095, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.429377, Val Loss: 0.572707, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.427054, Val Loss: 0.572571, Val Acc: 0.745763\n",
            "Test Loss: 0.5530573725700378 Test Accuracy: 0.7162162162162162\n",
            "weighted: Test F1: 0.5530573725700378 Test Precision: 0.7162162162162162 Test Recall: 0.7162162162162162\n",
            "[[61 10]\n",
            " [32 45]]\n",
            "[Trial 48] Test acc: 0.7162162162162162, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:30:12,455] Trial 48 finished with value: 0.7162162162162162 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.005007078162803566, 'learning_rate': 0.004067317195977547, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'l_relu', 'lam': 0.006012058890931586}\n",
            "Epoch 100/1000, Train Loss: 0.695113, Val Loss: 0.694848, Val Acc: 0.627119\n",
            "Epoch 200/1000, Train Loss: 0.694620, Val Loss: 0.694606, Val Acc: 0.618644\n",
            "Epoch 300/1000, Train Loss: 0.694747, Val Loss: 0.694237, Val Acc: 0.601695\n",
            "Epoch 400/1000, Train Loss: 0.694036, Val Loss: 0.693706, Val Acc: 0.627119\n",
            "Epoch 500/1000, Train Loss: 0.692610, Val Loss: 0.693064, Val Acc: 0.618644\n",
            "Epoch 600/1000, Train Loss: 0.691668, Val Loss: 0.692177, Val Acc: 0.627119\n",
            "Epoch 700/1000, Train Loss: 0.691398, Val Loss: 0.690850, Val Acc: 0.618644\n",
            "Epoch 800/1000, Train Loss: 0.690174, Val Loss: 0.689095, Val Acc: 0.618644\n",
            "Epoch 900/1000, Train Loss: 0.686094, Val Loss: 0.686453, Val Acc: 0.652542\n",
            "Epoch 1000/1000, Train Loss: 0.680519, Val Loss: 0.682382, Val Acc: 0.635593\n",
            "Test Loss: 0.682297945022583 Test Accuracy: 0.5945945945945946\n",
            "weighted: Test F1: 0.682297945022583 Test Precision: 0.5945945945945946 Test Recall: 0.5945945945945946\n",
            "[[42 29]\n",
            " [31 46]]\n",
            "[Trial 49] Test acc: 0.5945945945945946, Best val acc: 0.652542372881356\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:30:55,806] Trial 49 finished with value: 0.5945945945945946 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'l_relu', 'lam': 0.006012058890931586, 'learning_rate': 0.0030045279281093215, 'num_epoch': 1000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.007664485545506262}\n",
            "Epoch 100/500, Train Loss: 0.698087, Val Loss: 0.697605, Val Acc: 0.500000\n",
            "Epoch 200/500, Train Loss: 0.697924, Val Loss: 0.697619, Val Acc: 0.483051\n",
            "Epoch 300/500, Train Loss: 0.697458, Val Loss: 0.697633, Val Acc: 0.466102\n",
            "Epoch 400/500, Train Loss: 0.698034, Val Loss: 0.697642, Val Acc: 0.483051\n",
            "Epoch 500/500, Train Loss: 0.697580, Val Loss: 0.697650, Val Acc: 0.500000\n",
            "Test Loss: 0.6979780793190002 Test Accuracy: 0.44594594594594594\n",
            "weighted: Test F1: 0.6979780793190002 Test Precision: 0.44594594594594594 Test Recall: 0.44594594594594594\n",
            "[[31 40]\n",
            " [42 35]]\n",
            "[Trial 50] Test acc: 0.44594594594594594, Best val acc: 0.5\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:31:14,590] Trial 50 finished with value: 0.44594594594594594 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.007664485545506262, 'learning_rate': 0.00017169571268625032, 'num_epoch': 500}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006829629567221758}\n",
            "Epoch 100/2000, Train Loss: 0.692917, Val Loss: 0.693405, Val Acc: 0.610169\n",
            "Epoch 200/2000, Train Loss: 0.690858, Val Loss: 0.691895, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.689211, Val Loss: 0.690218, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.684810, Val Loss: 0.687806, Val Acc: 0.610169\n",
            "Epoch 500/2000, Train Loss: 0.683279, Val Loss: 0.684745, Val Acc: 0.618644\n",
            "Epoch 600/2000, Train Loss: 0.679073, Val Loss: 0.680536, Val Acc: 0.618644\n",
            "Epoch 700/2000, Train Loss: 0.669846, Val Loss: 0.674318, Val Acc: 0.635593\n",
            "Epoch 800/2000, Train Loss: 0.662112, Val Loss: 0.665358, Val Acc: 0.661017\n",
            "Epoch 900/2000, Train Loss: 0.646466, Val Loss: 0.652100, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.629133, Val Loss: 0.633715, Val Acc: 0.694915\n",
            "Epoch 1100/2000, Train Loss: 0.591182, Val Loss: 0.611338, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.579670, Val Loss: 0.591617, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.554705, Val Loss: 0.574104, Val Acc: 0.754237\n",
            "Epoch 1400/2000, Train Loss: 0.528009, Val Loss: 0.559649, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.508032, Val Loss: 0.548550, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.492263, Val Loss: 0.543402, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.465545, Val Loss: 0.541340, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.453772, Val Loss: 0.542421, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.451434, Val Loss: 0.545097, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.446472, Val Loss: 0.544700, Val Acc: 0.720339\n",
            "Test Loss: 0.5253246426582336 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.5253246426582336 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[61 10]\n",
            " [29 48]]\n",
            "[Trial 51] Test acc: 0.7364864864864865, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:32:36,065] Trial 51 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006829629567221758, 'learning_rate': 0.0021009679796915267, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007000864044870822}\n",
            "Epoch 100/2000, Train Loss: 0.695008, Val Loss: 0.696650, Val Acc: 0.466102\n",
            "Epoch 200/2000, Train Loss: 0.692906, Val Loss: 0.695391, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.690938, Val Loss: 0.692789, Val Acc: 0.559322\n",
            "Epoch 400/2000, Train Loss: 0.682712, Val Loss: 0.687455, Val Acc: 0.610169\n",
            "Epoch 500/2000, Train Loss: 0.670332, Val Loss: 0.677525, Val Acc: 0.627119\n",
            "Epoch 600/2000, Train Loss: 0.649275, Val Loss: 0.658785, Val Acc: 0.635593\n",
            "Epoch 700/2000, Train Loss: 0.613132, Val Loss: 0.623764, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.559684, Val Loss: 0.581652, Val Acc: 0.745763\n",
            "Epoch 900/2000, Train Loss: 0.521095, Val Loss: 0.551965, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.473237, Val Loss: 0.545252, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.466373, Val Loss: 0.542356, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.438690, Val Loss: 0.547167, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.424871, Val Loss: 0.554067, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.418498, Val Loss: 0.558314, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.410009, Val Loss: 0.560735, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.409469, Val Loss: 0.566394, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.407179, Val Loss: 0.579176, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.388401, Val Loss: 0.579012, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.378697, Val Loss: 0.578527, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.367815, Val Loss: 0.588562, Val Acc: 0.737288\n",
            "Test Loss: 0.5413856506347656 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5413856506347656 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[61 10]\n",
            " [25 52]]\n",
            "[Trial 52] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:33:56,934] Trial 52 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007000864044870822, 'learning_rate': 0.004656336281643229, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006480396706868677}\n",
            "Epoch 100/2000, Train Loss: 0.694208, Val Loss: 0.693862, Val Acc: 0.677966\n",
            "Epoch 200/2000, Train Loss: 0.687788, Val Loss: 0.688977, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.675497, Val Loss: 0.680039, Val Acc: 0.661017\n",
            "Epoch 400/2000, Train Loss: 0.658540, Val Loss: 0.660254, Val Acc: 0.694915\n",
            "Epoch 500/2000, Train Loss: 0.610991, Val Loss: 0.614809, Val Acc: 0.745763\n",
            "Epoch 600/2000, Train Loss: 0.526535, Val Loss: 0.562616, Val Acc: 0.754237\n",
            "Epoch 700/2000, Train Loss: 0.468733, Val Loss: 0.543960, Val Acc: 0.737288\n",
            "Epoch 800/2000, Train Loss: 0.443241, Val Loss: 0.544263, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.433390, Val Loss: 0.543153, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.419675, Val Loss: 0.548682, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.412742, Val Loss: 0.555050, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.410178, Val Loss: 0.562261, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.384605, Val Loss: 0.566415, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.385654, Val Loss: 0.579014, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.366178, Val Loss: 0.581655, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.358497, Val Loss: 0.598990, Val Acc: 0.694915\n",
            "Epoch 1700/2000, Train Loss: 0.341808, Val Loss: 0.599705, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.319626, Val Loss: 0.615055, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.318591, Val Loss: 0.630547, Val Acc: 0.703390\n",
            "Epoch 2000/2000, Train Loss: 0.308504, Val Loss: 0.641387, Val Acc: 0.720339\n",
            "Test Loss: 0.5721449255943298 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5721449255943298 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[59 12]\n",
            " [22 55]]\n",
            "[Trial 53] Test acc: 0.7702702702702703, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:35:18,621] Trial 53 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006480396706868677, 'learning_rate': 0.0060156967948037, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'l_relu', 'lam': 0.00648667385152503}\n",
            "Epoch 100/2000, Train Loss: 0.693956, Val Loss: 0.694418, Val Acc: 0.618644\n",
            "Epoch 200/2000, Train Loss: 0.687238, Val Loss: 0.689241, Val Acc: 0.677966\n",
            "Epoch 300/2000, Train Loss: 0.663848, Val Loss: 0.669785, Val Acc: 0.703390\n",
            "Epoch 400/2000, Train Loss: 0.591506, Val Loss: 0.600259, Val Acc: 0.720339\n",
            "Epoch 500/2000, Train Loss: 0.487053, Val Loss: 0.550049, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.452773, Val Loss: 0.547634, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.433632, Val Loss: 0.560896, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.415529, Val Loss: 0.560915, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.398497, Val Loss: 0.572730, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.388499, Val Loss: 0.584652, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.364047, Val Loss: 0.594970, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.363361, Val Loss: 0.611137, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.335627, Val Loss: 0.640933, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.324096, Val Loss: 0.673547, Val Acc: 0.686441\n",
            "Epoch 1500/2000, Train Loss: 0.291903, Val Loss: 0.683625, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.284124, Val Loss: 0.752579, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.253295, Val Loss: 0.729456, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.240868, Val Loss: 0.751144, Val Acc: 0.754237\n",
            "Epoch 1900/2000, Train Loss: 0.220316, Val Loss: 0.791716, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.217274, Val Loss: 0.817134, Val Acc: 0.720339\n",
            "Test Loss: 0.737615168094635 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.737615168094635 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[59 12]\n",
            " [24 53]]\n",
            "[Trial 54] Test acc: 0.7567567567567568, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:36:40,003] Trial 54 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'l_relu', 'lam': 0.00648667385152503, 'learning_rate': 0.009383339425491674, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.0074014423749062365}\n",
            "Epoch 100/200, Train Loss: 0.696899, Val Loss: 0.696829, Val Acc: 0.525424\n",
            "Epoch 200/200, Train Loss: 0.696830, Val Loss: 0.696867, Val Acc: 0.483051\n",
            "Test Loss: 0.6968185305595398 Test Accuracy: 0.5878378378378378\n",
            "weighted: Test F1: 0.6968185305595398 Test Precision: 0.5878378378378378 Test Recall: 0.5878378378378378\n",
            "[[53 18]\n",
            " [43 34]]\n",
            "[Trial 55] Test acc: 0.5878378378378378, Best val acc: 0.5254237288135594\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:36:47,939] Trial 55 finished with value: 0.5878378378378378 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.0074014423749062365, 'learning_rate': 0.0057673820485465745, 'num_epoch': 200}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007007924912343815}\n",
            "Epoch 100/2000, Train Loss: 0.692222, Val Loss: 0.694370, Val Acc: 0.550847\n",
            "Epoch 200/2000, Train Loss: 0.687431, Val Loss: 0.689517, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.677904, Val Loss: 0.676917, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.638858, Val Loss: 0.641291, Val Acc: 0.703390\n",
            "Epoch 500/2000, Train Loss: 0.571332, Val Loss: 0.577071, Val Acc: 0.728814\n",
            "Epoch 600/2000, Train Loss: 0.479694, Val Loss: 0.539975, Val Acc: 0.745763\n",
            "Epoch 700/2000, Train Loss: 0.445283, Val Loss: 0.540106, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.425983, Val Loss: 0.542888, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.421098, Val Loss: 0.551412, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.406289, Val Loss: 0.555938, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.397050, Val Loss: 0.559573, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.371690, Val Loss: 0.583586, Val Acc: 0.703390\n",
            "Epoch 1300/2000, Train Loss: 0.360134, Val Loss: 0.591633, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.330599, Val Loss: 0.608934, Val Acc: 0.745763\n",
            "Epoch 1500/2000, Train Loss: 0.312317, Val Loss: 0.627582, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.308785, Val Loss: 0.661082, Val Acc: 0.694915\n",
            "Epoch 1700/2000, Train Loss: 0.300705, Val Loss: 0.663112, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.290665, Val Loss: 0.694007, Val Acc: 0.703390\n",
            "Epoch 1900/2000, Train Loss: 0.256015, Val Loss: 0.709702, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.251931, Val Loss: 0.721384, Val Acc: 0.711864\n",
            "Test Loss: 0.697674036026001 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.697674036026001 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[55 16]\n",
            " [23 54]]\n",
            "[Trial 56] Test acc: 0.7364864864864865, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:38:08,659] Trial 56 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.007007924912343815, 'learning_rate': 0.0073327774621709235, 'num_epoch': 2000}. Best is trial 3 with value: 0.7837837837837838.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006775747148017478}\n",
            "Epoch 100/2000, Train Loss: 0.694332, Val Loss: 0.694686, Val Acc: 0.635593\n",
            "Epoch 200/2000, Train Loss: 0.690421, Val Loss: 0.692139, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.686001, Val Loss: 0.688139, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.673249, Val Loss: 0.679725, Val Acc: 0.601695\n",
            "Epoch 500/2000, Train Loss: 0.652413, Val Loss: 0.662687, Val Acc: 0.601695\n",
            "Epoch 600/2000, Train Loss: 0.623577, Val Loss: 0.631105, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.575491, Val Loss: 0.591921, Val Acc: 0.754237\n",
            "Epoch 800/2000, Train Loss: 0.519439, Val Loss: 0.556702, Val Acc: 0.754237\n",
            "Epoch 900/2000, Train Loss: 0.473261, Val Loss: 0.540393, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.450294, Val Loss: 0.539250, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.452528, Val Loss: 0.543535, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.429234, Val Loss: 0.548832, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.418921, Val Loss: 0.558701, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.414184, Val Loss: 0.568159, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.398828, Val Loss: 0.576795, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.402159, Val Loss: 0.580592, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.383371, Val Loss: 0.585650, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.374048, Val Loss: 0.597462, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.370237, Val Loss: 0.597993, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.352527, Val Loss: 0.599286, Val Acc: 0.728814\n",
            "Test Loss: 0.530725359916687 Test Accuracy: 0.7905405405405406\n",
            "weighted: Test F1: 0.530725359916687 Test Precision: 0.7905405405405406 Test Recall: 0.7905405405405406\n",
            "[[62  9]\n",
            " [22 55]]\n",
            "[Trial 57] Test acc: 0.7905405405405406, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:39:30,011] Trial 57 finished with value: 0.7905405405405406 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006775747148017478, 'learning_rate': 0.00455422759107859, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006730044091987177}\n",
            "Epoch 100/2000, Train Loss: 0.696131, Val Loss: 0.696463, Val Acc: 0.508475\n",
            "Epoch 200/2000, Train Loss: 0.695142, Val Loss: 0.695394, Val Acc: 0.559322\n",
            "Epoch 300/2000, Train Loss: 0.693621, Val Loss: 0.693602, Val Acc: 0.627119\n",
            "Epoch 400/2000, Train Loss: 0.690238, Val Loss: 0.690773, Val Acc: 0.610169\n",
            "Epoch 500/2000, Train Loss: 0.682844, Val Loss: 0.685962, Val Acc: 0.652542\n",
            "Epoch 600/2000, Train Loss: 0.676044, Val Loss: 0.676459, Val Acc: 0.652542\n",
            "Epoch 700/2000, Train Loss: 0.648157, Val Loss: 0.657487, Val Acc: 0.686441\n",
            "Epoch 800/2000, Train Loss: 0.600578, Val Loss: 0.620257, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.540974, Val Loss: 0.577376, Val Acc: 0.745763\n",
            "Epoch 1000/2000, Train Loss: 0.494218, Val Loss: 0.548909, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.479601, Val Loss: 0.541161, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.451532, Val Loss: 0.539198, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.441758, Val Loss: 0.545343, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.433112, Val Loss: 0.547459, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.418522, Val Loss: 0.551598, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.433478, Val Loss: 0.551699, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.418196, Val Loss: 0.548664, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.399597, Val Loss: 0.557645, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.402471, Val Loss: 0.562927, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.385753, Val Loss: 0.565484, Val Acc: 0.711864\n",
            "Test Loss: 0.53996342420578 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.53996342420578 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[62  9]\n",
            " [25 52]]\n",
            "[Trial 58] Test acc: 0.7702702702702703, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:40:50,943] Trial 58 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006730044091987177, 'learning_rate': 0.004658601164939244, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006749688454989155}\n",
            "Epoch 100/2000, Train Loss: 0.696480, Val Loss: 0.696420, Val Acc: 0.500000\n",
            "Epoch 200/2000, Train Loss: 0.696442, Val Loss: 0.696337, Val Acc: 0.559322\n",
            "Epoch 300/2000, Train Loss: 0.696239, Val Loss: 0.696245, Val Acc: 0.559322\n",
            "Epoch 400/2000, Train Loss: 0.696242, Val Loss: 0.696181, Val Acc: 0.567797\n",
            "Epoch 500/2000, Train Loss: 0.696023, Val Loss: 0.696099, Val Acc: 0.533898\n",
            "Epoch 600/2000, Train Loss: 0.695688, Val Loss: 0.695904, Val Acc: 0.533898\n",
            "Epoch 700/2000, Train Loss: 0.695447, Val Loss: 0.695829, Val Acc: 0.610169\n",
            "Epoch 800/2000, Train Loss: 0.695161, Val Loss: 0.695444, Val Acc: 0.593220\n",
            "Epoch 900/2000, Train Loss: 0.694225, Val Loss: 0.694883, Val Acc: 0.618644\n",
            "Epoch 1000/2000, Train Loss: 0.692393, Val Loss: 0.693894, Val Acc: 0.618644\n",
            "Epoch 1100/2000, Train Loss: 0.690856, Val Loss: 0.691796, Val Acc: 0.635593\n",
            "Epoch 1200/2000, Train Loss: 0.682817, Val Loss: 0.687203, Val Acc: 0.635593\n",
            "Epoch 1300/2000, Train Loss: 0.667490, Val Loss: 0.675046, Val Acc: 0.661017\n",
            "Epoch 1400/2000, Train Loss: 0.635000, Val Loss: 0.640118, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.545973, Val Loss: 0.566366, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.472822, Val Loss: 0.541330, Val Acc: 0.694915\n",
            "Epoch 1700/2000, Train Loss: 0.445867, Val Loss: 0.546186, Val Acc: 0.703390\n",
            "Epoch 1800/2000, Train Loss: 0.447883, Val Loss: 0.548761, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.423047, Val Loss: 0.561447, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.429576, Val Loss: 0.561778, Val Acc: 0.745763\n",
            "Test Loss: 0.5354400873184204 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5354400873184204 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[62  9]\n",
            " [26 51]]\n",
            "[Trial 59] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:42:18,188] Trial 59 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006749688454989155, 'learning_rate': 0.006073467512110055, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006473089374352618}\n",
            "Epoch 100/2000, Train Loss: 0.693115, Val Loss: 0.693589, Val Acc: 0.644068\n",
            "Epoch 200/2000, Train Loss: 0.685796, Val Loss: 0.687356, Val Acc: 0.610169\n",
            "Epoch 300/2000, Train Loss: 0.669954, Val Loss: 0.670192, Val Acc: 0.669492\n",
            "Epoch 400/2000, Train Loss: 0.612990, Val Loss: 0.624432, Val Acc: 0.703390\n",
            "Epoch 500/2000, Train Loss: 0.530530, Val Loss: 0.557717, Val Acc: 0.737288\n",
            "Epoch 600/2000, Train Loss: 0.457427, Val Loss: 0.543768, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.437113, Val Loss: 0.541924, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.430935, Val Loss: 0.546629, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.411884, Val Loss: 0.554201, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.399206, Val Loss: 0.561108, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.405173, Val Loss: 0.562838, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.401154, Val Loss: 0.582507, Val Acc: 0.703390\n",
            "Epoch 1300/2000, Train Loss: 0.372114, Val Loss: 0.591402, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.357532, Val Loss: 0.623017, Val Acc: 0.694915\n",
            "Epoch 1500/2000, Train Loss: 0.332307, Val Loss: 0.628879, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.334811, Val Loss: 0.684808, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.314777, Val Loss: 0.653943, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.302971, Val Loss: 0.677930, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.274310, Val Loss: 0.687370, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.273326, Val Loss: 0.705711, Val Acc: 0.737288\n",
            "Test Loss: 0.605098307132721 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.605098307132721 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[52 19]\n",
            " [22 55]]\n",
            "[Trial 60] Test acc: 0.722972972972973, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:43:39,007] Trial 60 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006473089374352618, 'learning_rate': 0.008084680892801375, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0062503495943812}\n",
            "Epoch 100/2000, Train Loss: 0.693550, Val Loss: 0.692616, Val Acc: 0.584746\n",
            "Epoch 200/2000, Train Loss: 0.689714, Val Loss: 0.689443, Val Acc: 0.567797\n",
            "Epoch 300/2000, Train Loss: 0.684931, Val Loss: 0.684351, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.672430, Val Loss: 0.675116, Val Acc: 0.635593\n",
            "Epoch 500/2000, Train Loss: 0.657698, Val Loss: 0.658769, Val Acc: 0.635593\n",
            "Epoch 600/2000, Train Loss: 0.619357, Val Loss: 0.630651, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.574310, Val Loss: 0.591049, Val Acc: 0.754237\n",
            "Epoch 800/2000, Train Loss: 0.518184, Val Loss: 0.558663, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.464758, Val Loss: 0.541873, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.448677, Val Loss: 0.537898, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.444359, Val Loss: 0.540065, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.434102, Val Loss: 0.539658, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.435570, Val Loss: 0.544749, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.413795, Val Loss: 0.542002, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.424285, Val Loss: 0.543896, Val Acc: 0.703390\n",
            "Epoch 1600/2000, Train Loss: 0.394701, Val Loss: 0.552141, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.384206, Val Loss: 0.547742, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.371494, Val Loss: 0.552265, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.367158, Val Loss: 0.549457, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.356507, Val Loss: 0.573955, Val Acc: 0.694915\n",
            "Test Loss: 0.5745436549186707 Test Accuracy: 0.7162162162162162\n",
            "weighted: Test F1: 0.5745436549186707 Test Precision: 0.7162162162162162 Test Recall: 0.7162162162162162\n",
            "[[50 21]\n",
            " [21 56]]\n",
            "[Trial 61] Test acc: 0.7162162162162162, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:45:00,358] Trial 61 finished with value: 0.7162162162162162 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0062503495943812, 'learning_rate': 0.004701564884333699, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006642823296628016}\n",
            "Epoch 100/2000, Train Loss: 0.695049, Val Loss: 0.694915, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.692834, Val Loss: 0.692766, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.690125, Val Loss: 0.689385, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.682859, Val Loss: 0.683132, Val Acc: 0.644068\n",
            "Epoch 500/2000, Train Loss: 0.672512, Val Loss: 0.672366, Val Acc: 0.661017\n",
            "Epoch 600/2000, Train Loss: 0.649663, Val Loss: 0.651303, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.612894, Val Loss: 0.615379, Val Acc: 0.703390\n",
            "Epoch 800/2000, Train Loss: 0.564766, Val Loss: 0.574857, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.519386, Val Loss: 0.550931, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.474311, Val Loss: 0.542422, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.456092, Val Loss: 0.541827, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.454120, Val Loss: 0.548393, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.434852, Val Loss: 0.548903, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.437258, Val Loss: 0.550114, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.424199, Val Loss: 0.550280, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.437350, Val Loss: 0.557149, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.413524, Val Loss: 0.556542, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.395827, Val Loss: 0.558586, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.407237, Val Loss: 0.564168, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.396050, Val Loss: 0.559501, Val Acc: 0.728814\n",
            "Test Loss: 0.53899747133255 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.53899747133255 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[60 11]\n",
            " [23 54]]\n",
            "[Trial 62] Test acc: 0.7702702702702703, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:46:21,522] Trial 62 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006642823296628016, 'learning_rate': 0.004642357605308103, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006648240085759377}\n",
            "Epoch 100/2000, Train Loss: 0.694967, Val Loss: 0.695960, Val Acc: 0.576271\n",
            "Epoch 200/2000, Train Loss: 0.692964, Val Loss: 0.694173, Val Acc: 0.618644\n",
            "Epoch 300/2000, Train Loss: 0.690403, Val Loss: 0.691190, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.681617, Val Loss: 0.683472, Val Acc: 0.694915\n",
            "Epoch 500/2000, Train Loss: 0.655811, Val Loss: 0.661459, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.604228, Val Loss: 0.612389, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.529281, Val Loss: 0.561230, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.478953, Val Loss: 0.544638, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.453733, Val Loss: 0.543864, Val Acc: 0.711864\n",
            "Epoch 1000/2000, Train Loss: 0.441284, Val Loss: 0.551620, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.435584, Val Loss: 0.555544, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.425889, Val Loss: 0.560568, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.415993, Val Loss: 0.563306, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.413377, Val Loss: 0.567287, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.400832, Val Loss: 0.575261, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.385884, Val Loss: 0.576434, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.377487, Val Loss: 0.590863, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.372223, Val Loss: 0.592685, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.341910, Val Loss: 0.599993, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.349607, Val Loss: 0.599571, Val Acc: 0.720339\n",
            "Test Loss: 0.5775893330574036 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5775893330574036 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[60 11]\n",
            " [26 51]]\n",
            "[Trial 63] Test acc: 0.75, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:47:42,786] Trial 63 finished with value: 0.75 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006648240085759377, 'learning_rate': 0.006100322779642873, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006738053099979144}\n",
            "Epoch 100/2000, Train Loss: 0.694479, Val Loss: 0.695263, Val Acc: 0.584746\n",
            "Epoch 200/2000, Train Loss: 0.686984, Val Loss: 0.690493, Val Acc: 0.584746\n",
            "Epoch 300/2000, Train Loss: 0.667212, Val Loss: 0.668444, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.579481, Val Loss: 0.588507, Val Acc: 0.754237\n",
            "Epoch 500/2000, Train Loss: 0.472514, Val Loss: 0.539981, Val Acc: 0.737288\n",
            "Epoch 600/2000, Train Loss: 0.441281, Val Loss: 0.546077, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.439423, Val Loss: 0.548952, Val Acc: 0.737288\n",
            "Epoch 800/2000, Train Loss: 0.422669, Val Loss: 0.546675, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.404780, Val Loss: 0.555475, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.410280, Val Loss: 0.554101, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.391314, Val Loss: 0.556826, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.375806, Val Loss: 0.572643, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.351123, Val Loss: 0.587918, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.325051, Val Loss: 0.595570, Val Acc: 0.745763\n",
            "Epoch 1500/2000, Train Loss: 0.324837, Val Loss: 0.637293, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.297312, Val Loss: 0.651770, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.285321, Val Loss: 0.693213, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.251668, Val Loss: 0.738082, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.244045, Val Loss: 0.767035, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.222826, Val Loss: 0.776028, Val Acc: 0.703390\n",
            "Test Loss: 0.6857132315635681 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.6857132315635681 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[58 13]\n",
            " [23 54]]\n",
            "[Trial 64] Test acc: 0.7567567567567568, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:49:04,280] Trial 64 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006738053099979144, 'learning_rate': 0.009989781095540308, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007301594067951824}\n",
            "Epoch 100/1000, Train Loss: 0.696624, Val Loss: 0.696564, Val Acc: 0.610169\n",
            "Epoch 200/1000, Train Loss: 0.696573, Val Loss: 0.696527, Val Acc: 0.610169\n",
            "Epoch 300/1000, Train Loss: 0.696410, Val Loss: 0.696509, Val Acc: 0.618644\n",
            "Epoch 400/1000, Train Loss: 0.696374, Val Loss: 0.696483, Val Acc: 0.635593\n",
            "Epoch 500/1000, Train Loss: 0.696405, Val Loss: 0.696442, Val Acc: 0.627119\n",
            "Epoch 600/1000, Train Loss: 0.696502, Val Loss: 0.696392, Val Acc: 0.627119\n",
            "Epoch 700/1000, Train Loss: 0.696458, Val Loss: 0.696301, Val Acc: 0.627119\n",
            "Epoch 800/1000, Train Loss: 0.696449, Val Loss: 0.696225, Val Acc: 0.627119\n",
            "Epoch 900/1000, Train Loss: 0.696147, Val Loss: 0.696178, Val Acc: 0.652542\n",
            "Epoch 1000/1000, Train Loss: 0.696094, Val Loss: 0.696059, Val Acc: 0.652542\n",
            "Test Loss: 0.696444571018219 Test Accuracy: 0.5608108108108109\n",
            "weighted: Test F1: 0.696444571018219 Test Precision: 0.5608108108108109 Test Recall: 0.5608108108108109\n",
            "[[43 28]\n",
            " [37 40]]\n",
            "[Trial 65] Test acc: 0.5608108108108109, Best val acc: 0.652542372881356\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:49:48,003] Trial 65 finished with value: 0.5608108108108109 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007301594067951824, 'learning_rate': 0.00334156229391941, 'num_epoch': 1000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'relu', 'lam': 0.0065179982882267095}\n",
            "Epoch 100/2000, Train Loss: 0.695778, Val Loss: 0.695773, Val Acc: 0.593220\n",
            "Epoch 200/2000, Train Loss: 0.695204, Val Loss: 0.695191, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.694667, Val Loss: 0.694657, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.693156, Val Loss: 0.693759, Val Acc: 0.593220\n",
            "Epoch 500/2000, Train Loss: 0.691389, Val Loss: 0.692304, Val Acc: 0.584746\n",
            "Epoch 600/2000, Train Loss: 0.689792, Val Loss: 0.689911, Val Acc: 0.584746\n",
            "Epoch 700/2000, Train Loss: 0.682293, Val Loss: 0.685666, Val Acc: 0.593220\n",
            "Epoch 800/2000, Train Loss: 0.675579, Val Loss: 0.678011, Val Acc: 0.635593\n",
            "Epoch 900/2000, Train Loss: 0.666738, Val Loss: 0.664922, Val Acc: 0.661017\n",
            "Epoch 1000/2000, Train Loss: 0.640881, Val Loss: 0.642710, Val Acc: 0.669492\n",
            "Epoch 1100/2000, Train Loss: 0.609600, Val Loss: 0.606556, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.555668, Val Loss: 0.569451, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.505557, Val Loss: 0.545514, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.472830, Val Loss: 0.537384, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.455468, Val Loss: 0.539205, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.438404, Val Loss: 0.541522, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.430744, Val Loss: 0.540628, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.425053, Val Loss: 0.545404, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.429178, Val Loss: 0.550315, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.438542, Val Loss: 0.553819, Val Acc: 0.737288\n",
            "Test Loss: 0.5281747579574585 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5281747579574585 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[63  8]\n",
            " [29 48]]\n",
            "[Trial 66] Test acc: 0.75, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:51:14,650] Trial 66 finished with value: 0.75 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'relu', 'lam': 0.0065179982882267095, 'learning_rate': 0.0046227436753116195, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006364208985421691}\n",
            "Epoch 100/200, Train Loss: 0.696393, Val Loss: 0.696438, Val Acc: 0.474576\n",
            "Epoch 200/200, Train Loss: 0.696361, Val Loss: 0.696351, Val Acc: 0.483051\n",
            "Test Loss: 0.6963270902633667 Test Accuracy: 0.5608108108108109\n",
            "weighted: Test F1: 0.6963270902633667 Test Precision: 0.5608108108108109 Test Recall: 0.5608108108108109\n",
            "[[39 32]\n",
            " [33 44]]\n",
            "[Trial 67] Test acc: 0.5608108108108109, Best val acc: 0.4830508474576271\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:51:22,576] Trial 67 finished with value: 0.5608108108108109 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006364208985421691, 'learning_rate': 0.007116171428031047, 'num_epoch': 200}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006829196924786982}\n",
            "Epoch 100/2000, Train Loss: 0.695349, Val Loss: 0.695191, Val Acc: 0.533898\n",
            "Epoch 200/2000, Train Loss: 0.694292, Val Loss: 0.694503, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.694117, Val Loss: 0.693754, Val Acc: 0.550847\n",
            "Epoch 400/2000, Train Loss: 0.693553, Val Loss: 0.692913, Val Acc: 0.567797\n",
            "Epoch 500/2000, Train Loss: 0.694012, Val Loss: 0.692125, Val Acc: 0.567797\n",
            "Epoch 600/2000, Train Loss: 0.692002, Val Loss: 0.691306, Val Acc: 0.550847\n",
            "Epoch 700/2000, Train Loss: 0.690701, Val Loss: 0.690318, Val Acc: 0.542373\n",
            "Epoch 800/2000, Train Loss: 0.690167, Val Loss: 0.689145, Val Acc: 0.550847\n",
            "Epoch 900/2000, Train Loss: 0.688951, Val Loss: 0.687648, Val Acc: 0.559322\n",
            "Epoch 1000/2000, Train Loss: 0.685446, Val Loss: 0.685865, Val Acc: 0.567797\n",
            "Epoch 1100/2000, Train Loss: 0.681726, Val Loss: 0.683501, Val Acc: 0.576271\n",
            "Epoch 1200/2000, Train Loss: 0.678671, Val Loss: 0.680593, Val Acc: 0.584746\n",
            "Epoch 1300/2000, Train Loss: 0.671205, Val Loss: 0.676852, Val Acc: 0.593220\n",
            "Epoch 1400/2000, Train Loss: 0.669814, Val Loss: 0.671983, Val Acc: 0.593220\n",
            "Epoch 1500/2000, Train Loss: 0.662842, Val Loss: 0.665712, Val Acc: 0.644068\n",
            "Epoch 1600/2000, Train Loss: 0.651676, Val Loss: 0.658020, Val Acc: 0.644068\n",
            "Epoch 1700/2000, Train Loss: 0.641687, Val Loss: 0.648213, Val Acc: 0.661017\n",
            "Epoch 1800/2000, Train Loss: 0.631277, Val Loss: 0.636173, Val Acc: 0.686441\n",
            "Epoch 1900/2000, Train Loss: 0.615488, Val Loss: 0.621368, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.598757, Val Loss: 0.604863, Val Acc: 0.745763\n",
            "Test Loss: 0.6051604151725769 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.6051604151725769 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[51 20]\n",
            " [21 56]]\n",
            "[Trial 68] Test acc: 0.722972972972973, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:52:44,263] Trial 68 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006829196924786982, 'learning_rate': 0.0017131808885545556, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006199906823593035}\n",
            "Epoch 100/2000, Train Loss: 0.694509, Val Loss: 0.695693, Val Acc: 0.593220\n",
            "Epoch 200/2000, Train Loss: 0.692883, Val Loss: 0.694122, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.686869, Val Loss: 0.691329, Val Acc: 0.627119\n",
            "Epoch 400/2000, Train Loss: 0.679135, Val Loss: 0.685993, Val Acc: 0.635593\n",
            "Epoch 500/2000, Train Loss: 0.666617, Val Loss: 0.675090, Val Acc: 0.652542\n",
            "Epoch 600/2000, Train Loss: 0.643907, Val Loss: 0.654614, Val Acc: 0.661017\n",
            "Epoch 700/2000, Train Loss: 0.603011, Val Loss: 0.615511, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.542301, Val Loss: 0.573455, Val Acc: 0.686441\n",
            "Epoch 900/2000, Train Loss: 0.489781, Val Loss: 0.552426, Val Acc: 0.703390\n",
            "Epoch 1000/2000, Train Loss: 0.452984, Val Loss: 0.544280, Val Acc: 0.694915\n",
            "Epoch 1100/2000, Train Loss: 0.437760, Val Loss: 0.544742, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.436154, Val Loss: 0.550694, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.423334, Val Loss: 0.551846, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.418693, Val Loss: 0.550893, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.392478, Val Loss: 0.555930, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.395027, Val Loss: 0.561111, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.397968, Val Loss: 0.561778, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.380905, Val Loss: 0.563866, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.374347, Val Loss: 0.573198, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.350896, Val Loss: 0.580600, Val Acc: 0.737288\n",
            "Test Loss: 0.5443664789199829 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5443664789199829 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[58 13]\n",
            " [22 55]]\n",
            "[Trial 69] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:54:05,825] Trial 69 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006199906823593035, 'learning_rate': 0.005668898909582567, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'relu', 'lam': 0.005856957019791374}\n",
            "Epoch 100/500, Train Loss: 0.696381, Val Loss: 0.694737, Val Acc: 0.567797\n",
            "Epoch 200/500, Train Loss: 0.694950, Val Loss: 0.693949, Val Acc: 0.576271\n",
            "Epoch 300/500, Train Loss: 0.694053, Val Loss: 0.692787, Val Acc: 0.635593\n",
            "Epoch 400/500, Train Loss: 0.693213, Val Loss: 0.691416, Val Acc: 0.610169\n",
            "Epoch 500/500, Train Loss: 0.690794, Val Loss: 0.689866, Val Acc: 0.618644\n",
            "Test Loss: 0.6927018165588379 Test Accuracy: 0.5945945945945946\n",
            "weighted: Test F1: 0.6927018165588379 Test Precision: 0.5945945945945946 Test Recall: 0.5945945945945946\n",
            "[[46 25]\n",
            " [35 42]]\n",
            "[Trial 70] Test acc: 0.5945945945945946, Best val acc: 0.635593220338983\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:54:25,888] Trial 70 finished with value: 0.5945945945945946 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'relu', 'lam': 0.005856957019791374, 'learning_rate': 0.0028496500025577427, 'num_epoch': 500}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.007066671959263745}\n",
            "Epoch 100/2000, Train Loss: 0.694436, Val Loss: 0.695727, Val Acc: 0.516949\n",
            "Epoch 200/2000, Train Loss: 0.693454, Val Loss: 0.693905, Val Acc: 0.567797\n",
            "Epoch 300/2000, Train Loss: 0.688765, Val Loss: 0.690709, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.678122, Val Loss: 0.684413, Val Acc: 0.584746\n",
            "Epoch 500/2000, Train Loss: 0.663614, Val Loss: 0.671868, Val Acc: 0.618644\n",
            "Epoch 600/2000, Train Loss: 0.634176, Val Loss: 0.642159, Val Acc: 0.677966\n",
            "Epoch 700/2000, Train Loss: 0.568050, Val Loss: 0.598072, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.526907, Val Loss: 0.564258, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.481791, Val Loss: 0.548095, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.464290, Val Loss: 0.540561, Val Acc: 0.745763\n",
            "Epoch 1100/2000, Train Loss: 0.459694, Val Loss: 0.542092, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.440743, Val Loss: 0.544789, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.424548, Val Loss: 0.549561, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.433108, Val Loss: 0.549498, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.418238, Val Loss: 0.559525, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.400486, Val Loss: 0.560526, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.399612, Val Loss: 0.561840, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.404327, Val Loss: 0.567754, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.386886, Val Loss: 0.571229, Val Acc: 0.703390\n",
            "Epoch 2000/2000, Train Loss: 0.373080, Val Loss: 0.569054, Val Acc: 0.703390\n",
            "Test Loss: 0.5458407998085022 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.5458407998085022 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[58 13]\n",
            " [23 54]]\n",
            "[Trial 71] Test acc: 0.7567567567567568, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:55:47,263] Trial 71 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.007066671959263745, 'learning_rate': 0.004555896956767383, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'sigmoid', 'lam': 0.006968941784587185}\n",
            "Epoch 100/2000, Train Loss: 0.696697, Val Loss: 0.696563, Val Acc: 0.610169\n",
            "Epoch 200/2000, Train Loss: 0.696779, Val Loss: 0.696540, Val Acc: 0.618644\n",
            "Epoch 300/2000, Train Loss: 0.696824, Val Loss: 0.696527, Val Acc: 0.618644\n",
            "Epoch 400/2000, Train Loss: 0.696853, Val Loss: 0.696430, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.696647, Val Loss: 0.696572, Val Acc: 0.432203\n",
            "Epoch 600/2000, Train Loss: 0.696733, Val Loss: 0.696496, Val Acc: 0.593220\n",
            "Epoch 700/2000, Train Loss: 0.696713, Val Loss: 0.696574, Val Acc: 0.466102\n",
            "Epoch 800/2000, Train Loss: 0.696582, Val Loss: 0.696364, Val Acc: 0.525424\n",
            "Epoch 900/2000, Train Loss: 0.696579, Val Loss: 0.696558, Val Acc: 0.483051\n",
            "Epoch 1000/2000, Train Loss: 0.696698, Val Loss: 0.696607, Val Acc: 0.466102\n",
            "Epoch 1100/2000, Train Loss: 0.696600, Val Loss: 0.696435, Val Acc: 0.610169\n",
            "Epoch 1200/2000, Train Loss: 0.696638, Val Loss: 0.696506, Val Acc: 0.474576\n",
            "Epoch 1300/2000, Train Loss: 0.696512, Val Loss: 0.696471, Val Acc: 0.449153\n",
            "Epoch 1400/2000, Train Loss: 0.696537, Val Loss: 0.696484, Val Acc: 0.457627\n",
            "Epoch 1500/2000, Train Loss: 0.696599, Val Loss: 0.696295, Val Acc: 0.584746\n",
            "Epoch 1600/2000, Train Loss: 0.696455, Val Loss: 0.696232, Val Acc: 0.550847\n",
            "Epoch 1700/2000, Train Loss: 0.696575, Val Loss: 0.696264, Val Acc: 0.567797\n",
            "Epoch 1800/2000, Train Loss: 0.696423, Val Loss: 0.696240, Val Acc: 0.576271\n",
            "Epoch 1900/2000, Train Loss: 0.696546, Val Loss: 0.696366, Val Acc: 0.500000\n",
            "Epoch 2000/2000, Train Loss: 0.696265, Val Loss: 0.696295, Val Acc: 0.601695\n",
            "Test Loss: 0.6964036226272583 Test Accuracy: 0.5540540540540541\n",
            "weighted: Test F1: 0.6964036226272583 Test Precision: 0.5540540540540541 Test Recall: 0.5540540540540541\n",
            "[[54 17]\n",
            " [49 28]]\n",
            "[Trial 72] Test acc: 0.5540540540540541, Best val acc: 0.6186440677966102\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:57:08,031] Trial 72 finished with value: 0.5540540540540541 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'sigmoid', 'lam': 0.006968941784587185, 'learning_rate': 0.0035209717921299163, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.007266327645343539}\n",
            "Epoch 100/2000, Train Loss: 0.689528, Val Loss: 0.693950, Val Acc: 0.533898\n",
            "Epoch 200/2000, Train Loss: 0.683894, Val Loss: 0.687790, Val Acc: 0.550847\n",
            "Epoch 300/2000, Train Loss: 0.667446, Val Loss: 0.674878, Val Acc: 0.627119\n",
            "Epoch 400/2000, Train Loss: 0.650474, Val Loss: 0.648816, Val Acc: 0.694915\n",
            "Epoch 500/2000, Train Loss: 0.602400, Val Loss: 0.608436, Val Acc: 0.711864\n",
            "Epoch 600/2000, Train Loss: 0.550456, Val Loss: 0.574261, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.517817, Val Loss: 0.556225, Val Acc: 0.703390\n",
            "Epoch 800/2000, Train Loss: 0.467191, Val Loss: 0.548642, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.474095, Val Loss: 0.548488, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.447687, Val Loss: 0.549751, Val Acc: 0.745763\n",
            "Epoch 1100/2000, Train Loss: 0.449685, Val Loss: 0.553396, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.443594, Val Loss: 0.558479, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.432751, Val Loss: 0.559853, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.431569, Val Loss: 0.560951, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.443394, Val Loss: 0.565543, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.442140, Val Loss: 0.565741, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.441255, Val Loss: 0.566856, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.437290, Val Loss: 0.570891, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.418005, Val Loss: 0.575568, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.439954, Val Loss: 0.574587, Val Acc: 0.728814\n",
            "Test Loss: 0.561774730682373 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.561774730682373 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[58 13]\n",
            " [26 51]]\n",
            "[Trial 73] Test acc: 0.7364864864864865, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:58:27,926] Trial 73 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.007266327645343539, 'learning_rate': 0.004274462044688825, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0065997133219829664}\n",
            "Epoch 100/2000, Train Loss: 0.693565, Val Loss: 0.695330, Val Acc: 0.550847\n",
            "Epoch 200/2000, Train Loss: 0.690337, Val Loss: 0.690803, Val Acc: 0.584746\n",
            "Epoch 300/2000, Train Loss: 0.683898, Val Loss: 0.682220, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.661455, Val Loss: 0.666063, Val Acc: 0.635593\n",
            "Epoch 500/2000, Train Loss: 0.627056, Val Loss: 0.634195, Val Acc: 0.728814\n",
            "Epoch 600/2000, Train Loss: 0.571093, Val Loss: 0.588345, Val Acc: 0.737288\n",
            "Epoch 700/2000, Train Loss: 0.495431, Val Loss: 0.552363, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.466387, Val Loss: 0.545061, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.458563, Val Loss: 0.549534, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.446692, Val Loss: 0.556797, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.428891, Val Loss: 0.561402, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.423768, Val Loss: 0.568028, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.403497, Val Loss: 0.581705, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.412533, Val Loss: 0.580099, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.389259, Val Loss: 0.587349, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.390874, Val Loss: 0.592198, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.373890, Val Loss: 0.598081, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.360755, Val Loss: 0.602004, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.369718, Val Loss: 0.611338, Val Acc: 0.754237\n",
            "Epoch 2000/2000, Train Loss: 0.346063, Val Loss: 0.625123, Val Acc: 0.737288\n",
            "Test Loss: 0.5563914775848389 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.5563914775848389 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[61 10]\n",
            " [23 54]]\n",
            "[Trial 74] Test acc: 0.777027027027027, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 17:59:48,909] Trial 74 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0065997133219829664, 'learning_rate': 0.0053920615898473525, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006612826073810049}\n",
            "Epoch 100/2000, Train Loss: 0.695049, Val Loss: 0.695864, Val Acc: 0.500000\n",
            "Epoch 200/2000, Train Loss: 0.692712, Val Loss: 0.694583, Val Acc: 0.533898\n",
            "Epoch 300/2000, Train Loss: 0.687676, Val Loss: 0.690778, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.672198, Val Loss: 0.678513, Val Acc: 0.669492\n",
            "Epoch 500/2000, Train Loss: 0.638374, Val Loss: 0.643456, Val Acc: 0.711864\n",
            "Epoch 600/2000, Train Loss: 0.576356, Val Loss: 0.582649, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.495378, Val Loss: 0.545654, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.459272, Val Loss: 0.537711, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.442866, Val Loss: 0.539906, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.445212, Val Loss: 0.542131, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.398662, Val Loss: 0.553641, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.423083, Val Loss: 0.554577, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.398951, Val Loss: 0.560601, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.386513, Val Loss: 0.564697, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.399154, Val Loss: 0.565063, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.373222, Val Loss: 0.559213, Val Acc: 0.745763\n",
            "Epoch 1700/2000, Train Loss: 0.369377, Val Loss: 0.562877, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.361146, Val Loss: 0.574794, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.350094, Val Loss: 0.590941, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.357315, Val Loss: 0.612527, Val Acc: 0.728814\n",
            "Test Loss: 0.5896437764167786 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.5896437764167786 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[62  9]\n",
            " [24 53]]\n",
            "[Trial 75] Test acc: 0.777027027027027, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:01:10,182] Trial 75 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006612826073810049, 'learning_rate': 0.006560432007345034, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006610993851433795}\n",
            "Epoch 100/2000, Train Loss: 0.695188, Val Loss: 0.695671, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.691105, Val Loss: 0.693035, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.683928, Val Loss: 0.687432, Val Acc: 0.618644\n",
            "Epoch 400/2000, Train Loss: 0.667218, Val Loss: 0.674343, Val Acc: 0.644068\n",
            "Epoch 500/2000, Train Loss: 0.629439, Val Loss: 0.640968, Val Acc: 0.677966\n",
            "Epoch 600/2000, Train Loss: 0.575742, Val Loss: 0.581403, Val Acc: 0.737288\n",
            "Epoch 700/2000, Train Loss: 0.485821, Val Loss: 0.548003, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.461677, Val Loss: 0.543012, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.456996, Val Loss: 0.550591, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.444384, Val Loss: 0.551225, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.426248, Val Loss: 0.555938, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.422146, Val Loss: 0.562345, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.428113, Val Loss: 0.564929, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.402395, Val Loss: 0.571827, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.405937, Val Loss: 0.580573, Val Acc: 0.703390\n",
            "Epoch 1600/2000, Train Loss: 0.395257, Val Loss: 0.579430, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.378596, Val Loss: 0.588901, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.361216, Val Loss: 0.589085, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.352816, Val Loss: 0.602563, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.329362, Val Loss: 0.626704, Val Acc: 0.711864\n",
            "Test Loss: 0.581102728843689 Test Accuracy: 0.7297297297297297\n",
            "weighted: Test F1: 0.581102728843689 Test Precision: 0.7297297297297297 Test Recall: 0.7297297297297297\n",
            "[[54 17]\n",
            " [23 54]]\n",
            "[Trial 76] Test acc: 0.7297297297297297, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:02:30,984] Trial 76 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006610993851433795, 'learning_rate': 0.006642648372492501, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006419992178524731}\n",
            "Epoch 100/2000, Train Loss: 0.695822, Val Loss: 0.696318, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.695226, Val Loss: 0.696214, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.694573, Val Loss: 0.695860, Val Acc: 0.542373\n",
            "Epoch 400/2000, Train Loss: 0.692601, Val Loss: 0.695113, Val Acc: 0.550847\n",
            "Epoch 500/2000, Train Loss: 0.687237, Val Loss: 0.693021, Val Acc: 0.567797\n",
            "Epoch 600/2000, Train Loss: 0.679447, Val Loss: 0.687815, Val Acc: 0.567797\n",
            "Epoch 700/2000, Train Loss: 0.661244, Val Loss: 0.673001, Val Acc: 0.601695\n",
            "Epoch 800/2000, Train Loss: 0.626982, Val Loss: 0.633913, Val Acc: 0.652542\n",
            "Epoch 900/2000, Train Loss: 0.546605, Val Loss: 0.570498, Val Acc: 0.762712\n",
            "Epoch 1000/2000, Train Loss: 0.484318, Val Loss: 0.540850, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.449262, Val Loss: 0.542782, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.434894, Val Loss: 0.552273, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.430541, Val Loss: 0.557123, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.430323, Val Loss: 0.567266, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.418622, Val Loss: 0.568783, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.411665, Val Loss: 0.586413, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.402597, Val Loss: 0.583622, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.395918, Val Loss: 0.594752, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.387555, Val Loss: 0.612628, Val Acc: 0.703390\n",
            "Epoch 2000/2000, Train Loss: 0.388740, Val Loss: 0.624295, Val Acc: 0.694915\n",
            "Test Loss: 0.5842980146408081 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.5842980146408081 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[57 14]\n",
            " [22 55]]\n",
            "[Trial 77] Test acc: 0.7567567567567568, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:03:51,934] Trial 77 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006419992178524731, 'learning_rate': 0.008334178346253383, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.009513583622433982}\n",
            "Epoch 100/1500, Train Loss: 0.697574, Val Loss: 0.699337, Val Acc: 0.457627\n",
            "Epoch 200/1500, Train Loss: 0.695918, Val Loss: 0.697952, Val Acc: 0.516949\n",
            "Epoch 300/1500, Train Loss: 0.694399, Val Loss: 0.696423, Val Acc: 0.576271\n",
            "Epoch 400/1500, Train Loss: 0.692658, Val Loss: 0.694378, Val Acc: 0.644068\n",
            "Epoch 500/1500, Train Loss: 0.688171, Val Loss: 0.691588, Val Acc: 0.652542\n",
            "Epoch 600/1500, Train Loss: 0.677491, Val Loss: 0.687039, Val Acc: 0.669492\n",
            "Epoch 700/1500, Train Loss: 0.673608, Val Loss: 0.679806, Val Acc: 0.686441\n",
            "Epoch 800/1500, Train Loss: 0.660326, Val Loss: 0.668206, Val Acc: 0.686441\n",
            "Epoch 900/1500, Train Loss: 0.635118, Val Loss: 0.647771, Val Acc: 0.694915\n",
            "Epoch 1000/1500, Train Loss: 0.600284, Val Loss: 0.615053, Val Acc: 0.711864\n",
            "Epoch 1100/1500, Train Loss: 0.547551, Val Loss: 0.582101, Val Acc: 0.694915\n",
            "Epoch 1200/1500, Train Loss: 0.509742, Val Loss: 0.559608, Val Acc: 0.703390\n",
            "Epoch 1300/1500, Train Loss: 0.483693, Val Loss: 0.547888, Val Acc: 0.737288\n",
            "Epoch 1400/1500, Train Loss: 0.453541, Val Loss: 0.546600, Val Acc: 0.720339\n",
            "Epoch 1500/1500, Train Loss: 0.457616, Val Loss: 0.547805, Val Acc: 0.703390\n",
            "Test Loss: 0.5229091644287109 Test Accuracy: 0.7297297297297297\n",
            "weighted: Test F1: 0.5229091644287109 Test Precision: 0.7297297297297297 Test Recall: 0.7297297297297297\n",
            "[[62  9]\n",
            " [31 46]]\n",
            "[Trial 78] Test acc: 0.7297297297297297, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:04:52,499] Trial 78 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.009513583622433982, 'learning_rate': 0.0037834960564240095, 'num_epoch': 1500}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005634098834545182}\n",
            "Epoch 100/2000, Train Loss: 0.695849, Val Loss: 0.695970, Val Acc: 0.500000\n",
            "Epoch 200/2000, Train Loss: 0.695805, Val Loss: 0.695940, Val Acc: 0.491525\n",
            "Epoch 300/2000, Train Loss: 0.695816, Val Loss: 0.695967, Val Acc: 0.466102\n",
            "Epoch 400/2000, Train Loss: 0.695784, Val Loss: 0.695900, Val Acc: 0.584746\n",
            "Epoch 500/2000, Train Loss: 0.695634, Val Loss: 0.695816, Val Acc: 0.542373\n",
            "Epoch 600/2000, Train Loss: 0.695711, Val Loss: 0.695796, Val Acc: 0.576271\n",
            "Epoch 700/2000, Train Loss: 0.695545, Val Loss: 0.695730, Val Acc: 0.567797\n",
            "Epoch 800/2000, Train Loss: 0.695430, Val Loss: 0.695698, Val Acc: 0.601695\n",
            "Epoch 900/2000, Train Loss: 0.695416, Val Loss: 0.695609, Val Acc: 0.584746\n",
            "Epoch 1000/2000, Train Loss: 0.695401, Val Loss: 0.695577, Val Acc: 0.627119\n",
            "Epoch 1100/2000, Train Loss: 0.695331, Val Loss: 0.695502, Val Acc: 0.669492\n",
            "Epoch 1200/2000, Train Loss: 0.695137, Val Loss: 0.695401, Val Acc: 0.694915\n",
            "Epoch 1300/2000, Train Loss: 0.695098, Val Loss: 0.695341, Val Acc: 0.703390\n",
            "Epoch 1400/2000, Train Loss: 0.694920, Val Loss: 0.695187, Val Acc: 0.694915\n",
            "Epoch 1500/2000, Train Loss: 0.694611, Val Loss: 0.694983, Val Acc: 0.677966\n",
            "Epoch 1600/2000, Train Loss: 0.694437, Val Loss: 0.694769, Val Acc: 0.677966\n",
            "Epoch 1700/2000, Train Loss: 0.694395, Val Loss: 0.694526, Val Acc: 0.686441\n",
            "Epoch 1800/2000, Train Loss: 0.693531, Val Loss: 0.694161, Val Acc: 0.686441\n",
            "Epoch 1900/2000, Train Loss: 0.693308, Val Loss: 0.693777, Val Acc: 0.686441\n",
            "Epoch 2000/2000, Train Loss: 0.692329, Val Loss: 0.693268, Val Acc: 0.677966\n",
            "Test Loss: 0.69334876537323 Test Accuracy: 0.6216216216216216\n",
            "weighted: Test F1: 0.69334876537323 Test Precision: 0.6216216216216216 Test Recall: 0.6216216216216216\n",
            "[[40 31]\n",
            " [25 52]]\n",
            "[Trial 79] Test acc: 0.6216216216216216, Best val acc: 0.7033898305084746\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:06:18,903] Trial 79 finished with value: 0.6216216216216216 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005634098834545182, 'learning_rate': 0.002641976550620845, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006003817503889841}\n",
            "Epoch 100/1000, Train Loss: 0.694996, Val Loss: 0.694796, Val Acc: 0.601695\n",
            "Epoch 200/1000, Train Loss: 0.693241, Val Loss: 0.693064, Val Acc: 0.644068\n",
            "Epoch 300/1000, Train Loss: 0.690528, Val Loss: 0.690370, Val Acc: 0.694915\n",
            "Epoch 400/1000, Train Loss: 0.683258, Val Loss: 0.685562, Val Acc: 0.694915\n",
            "Epoch 500/1000, Train Loss: 0.671528, Val Loss: 0.675171, Val Acc: 0.711864\n",
            "Epoch 600/1000, Train Loss: 0.649052, Val Loss: 0.653187, Val Acc: 0.703390\n",
            "Epoch 700/1000, Train Loss: 0.612049, Val Loss: 0.610383, Val Acc: 0.728814\n",
            "Epoch 800/1000, Train Loss: 0.533969, Val Loss: 0.564694, Val Acc: 0.720339\n",
            "Epoch 900/1000, Train Loss: 0.504342, Val Loss: 0.540946, Val Acc: 0.711864\n",
            "Epoch 1000/1000, Train Loss: 0.458171, Val Loss: 0.536362, Val Acc: 0.711864\n",
            "Test Loss: 0.5281041264533997 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.5281041264533997 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[60 11]\n",
            " [30 47]]\n",
            "[Trial 80] Test acc: 0.722972972972973, Best val acc: 0.7288135593220338\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:06:59,170] Trial 80 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006003817503889841, 'learning_rate': 0.005235438680123892, 'num_epoch': 1000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006826916938690699}\n",
            "Epoch 100/2000, Train Loss: 0.693198, Val Loss: 0.693195, Val Acc: 0.610169\n",
            "Epoch 200/2000, Train Loss: 0.689514, Val Loss: 0.688816, Val Acc: 0.644068\n",
            "Epoch 300/2000, Train Loss: 0.681065, Val Loss: 0.680425, Val Acc: 0.635593\n",
            "Epoch 400/2000, Train Loss: 0.650801, Val Loss: 0.661035, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.611162, Val Loss: 0.618375, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.544388, Val Loss: 0.572656, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.496197, Val Loss: 0.551699, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.464147, Val Loss: 0.545217, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.449195, Val Loss: 0.546954, Val Acc: 0.711864\n",
            "Epoch 1000/2000, Train Loss: 0.441125, Val Loss: 0.546685, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.437697, Val Loss: 0.541971, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.418778, Val Loss: 0.543964, Val Acc: 0.745763\n",
            "Epoch 1300/2000, Train Loss: 0.419424, Val Loss: 0.543420, Val Acc: 0.745763\n",
            "Epoch 1400/2000, Train Loss: 0.415276, Val Loss: 0.547157, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.401751, Val Loss: 0.552697, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.396132, Val Loss: 0.552039, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.378959, Val Loss: 0.554458, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.359528, Val Loss: 0.559984, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.364128, Val Loss: 0.570179, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.352882, Val Loss: 0.574259, Val Acc: 0.728814\n",
            "Test Loss: 0.5582792162895203 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.5582792162895203 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[60 11]\n",
            " [22 55]]\n",
            "[Trial 81] Test acc: 0.777027027027027, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:08:20,558] Trial 81 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006826916938690699, 'learning_rate': 0.005517793777452585, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006716419474934888}\n",
            "Epoch 100/2000, Train Loss: 0.688162, Val Loss: 0.690745, Val Acc: 0.618644\n",
            "Epoch 200/2000, Train Loss: 0.667968, Val Loss: 0.675866, Val Acc: 0.703390\n",
            "Epoch 300/2000, Train Loss: 0.616936, Val Loss: 0.629368, Val Acc: 0.737288\n",
            "Epoch 400/2000, Train Loss: 0.538790, Val Loss: 0.565115, Val Acc: 0.703390\n",
            "Epoch 500/2000, Train Loss: 0.474746, Val Loss: 0.538573, Val Acc: 0.711864\n",
            "Epoch 600/2000, Train Loss: 0.457020, Val Loss: 0.541085, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.417885, Val Loss: 0.543144, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.419633, Val Loss: 0.547649, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.423669, Val Loss: 0.552244, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.390066, Val Loss: 0.552354, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.401816, Val Loss: 0.558815, Val Acc: 0.745763\n",
            "Epoch 1200/2000, Train Loss: 0.374008, Val Loss: 0.568220, Val Acc: 0.754237\n",
            "Epoch 1300/2000, Train Loss: 0.369517, Val Loss: 0.577359, Val Acc: 0.745763\n",
            "Epoch 1400/2000, Train Loss: 0.363447, Val Loss: 0.593391, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.343917, Val Loss: 0.614389, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.340836, Val Loss: 0.626478, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.296774, Val Loss: 0.649097, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.290724, Val Loss: 0.668721, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.257819, Val Loss: 0.693170, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.286175, Val Loss: 0.725169, Val Acc: 0.703390\n",
            "Test Loss: 0.6766215562820435 Test Accuracy: 0.7027027027027027\n",
            "weighted: Test F1: 0.6766215562820435 Test Precision: 0.7027027027027027 Test Recall: 0.7027027027027027\n",
            "[[48 23]\n",
            " [21 56]]\n",
            "[Trial 82] Test acc: 0.7027027027027027, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:09:40,866] Trial 82 finished with value: 0.7027027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006716419474934888, 'learning_rate': 0.00765314521940174, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0053214869604931506}\n",
            "Epoch 100/2000, Train Loss: 0.690085, Val Loss: 0.691726, Val Acc: 0.635593\n",
            "Epoch 200/2000, Train Loss: 0.682423, Val Loss: 0.685621, Val Acc: 0.652542\n",
            "Epoch 300/2000, Train Loss: 0.664950, Val Loss: 0.671482, Val Acc: 0.686441\n",
            "Epoch 400/2000, Train Loss: 0.625519, Val Loss: 0.638067, Val Acc: 0.720339\n",
            "Epoch 500/2000, Train Loss: 0.557566, Val Loss: 0.583054, Val Acc: 0.728814\n",
            "Epoch 600/2000, Train Loss: 0.492392, Val Loss: 0.551141, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.471861, Val Loss: 0.543031, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.449462, Val Loss: 0.548646, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.441667, Val Loss: 0.553494, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.425142, Val Loss: 0.554969, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.416841, Val Loss: 0.556651, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.401774, Val Loss: 0.557360, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.386201, Val Loss: 0.570788, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.392265, Val Loss: 0.572748, Val Acc: 0.694915\n",
            "Epoch 1500/2000, Train Loss: 0.394852, Val Loss: 0.572046, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.365710, Val Loss: 0.574823, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.355636, Val Loss: 0.580739, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.335486, Val Loss: 0.595390, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.329851, Val Loss: 0.608884, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.311214, Val Loss: 0.627023, Val Acc: 0.703390\n",
            "Test Loss: 0.5972856879234314 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5972856879234314 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[59 12]\n",
            " [22 55]]\n",
            "[Trial 83] Test acc: 0.7702702702702703, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:11:02,188] Trial 83 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0053214869604931506, 'learning_rate': 0.006335344030630167, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006331179839573271}\n",
            "Epoch 100/2000, Train Loss: 0.694867, Val Loss: 0.695180, Val Acc: 0.516949\n",
            "Epoch 200/2000, Train Loss: 0.692788, Val Loss: 0.694130, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.690293, Val Loss: 0.692532, Val Acc: 0.644068\n",
            "Epoch 400/2000, Train Loss: 0.687867, Val Loss: 0.689829, Val Acc: 0.669492\n",
            "Epoch 500/2000, Train Loss: 0.677446, Val Loss: 0.685234, Val Acc: 0.677966\n",
            "Epoch 600/2000, Train Loss: 0.669970, Val Loss: 0.677152, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.657896, Val Loss: 0.663325, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.622238, Val Loss: 0.640894, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.577090, Val Loss: 0.609915, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.557788, Val Loss: 0.580845, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.522759, Val Loss: 0.560648, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.493420, Val Loss: 0.548637, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.470207, Val Loss: 0.544058, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.472078, Val Loss: 0.545971, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.451821, Val Loss: 0.547819, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.436330, Val Loss: 0.548241, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.437987, Val Loss: 0.549543, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.415833, Val Loss: 0.551169, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.431293, Val Loss: 0.554494, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.425176, Val Loss: 0.557091, Val Acc: 0.737288\n",
            "Test Loss: 0.5168706774711609 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.5168706774711609 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[62  9]\n",
            " [24 53]]\n",
            "[Trial 84] Test acc: 0.777027027027027, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:12:22,888] Trial 84 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006331179839573271, 'learning_rate': 0.00341717265366227, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006276720787157575}\n",
            "Epoch 100/2000, Train Loss: 0.694880, Val Loss: 0.696052, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.693126, Val Loss: 0.694793, Val Acc: 0.559322\n",
            "Epoch 300/2000, Train Loss: 0.689333, Val Loss: 0.692906, Val Acc: 0.627119\n",
            "Epoch 400/2000, Train Loss: 0.685343, Val Loss: 0.689563, Val Acc: 0.661017\n",
            "Epoch 500/2000, Train Loss: 0.677477, Val Loss: 0.683300, Val Acc: 0.669492\n",
            "Epoch 600/2000, Train Loss: 0.660196, Val Loss: 0.670729, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.630741, Val Loss: 0.647697, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.599984, Val Loss: 0.612049, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.556919, Val Loss: 0.577637, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.519044, Val Loss: 0.555736, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.474451, Val Loss: 0.546747, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.471870, Val Loss: 0.545871, Val Acc: 0.703390\n",
            "Epoch 1300/2000, Train Loss: 0.463871, Val Loss: 0.546909, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.445400, Val Loss: 0.549624, Val Acc: 0.703390\n",
            "Epoch 1500/2000, Train Loss: 0.434641, Val Loss: 0.552513, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.444929, Val Loss: 0.557171, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.419019, Val Loss: 0.554933, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.413886, Val Loss: 0.559040, Val Acc: 0.745763\n",
            "Epoch 1900/2000, Train Loss: 0.429909, Val Loss: 0.562232, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.412609, Val Loss: 0.560083, Val Acc: 0.728814\n",
            "Test Loss: 0.5326051712036133 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5326051712036133 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[62  9]\n",
            " [25 52]]\n",
            "[Trial 85] Test acc: 0.7702702702702703, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:13:42,880] Trial 85 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006276720787157575, 'learning_rate': 0.003825722399439219, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.006547017288066837}\n",
            "Epoch 100/200, Train Loss: 0.695936, Val Loss: 0.695421, Val Acc: 0.533898\n",
            "Epoch 200/200, Train Loss: 0.695417, Val Loss: 0.694496, Val Acc: 0.601695\n",
            "Test Loss: 0.6946378946304321 Test Accuracy: 0.5337837837837838\n",
            "weighted: Test F1: 0.6946378946304321 Test Precision: 0.5337837837837838 Test Recall: 0.5337837837837838\n",
            "[[32 39]\n",
            " [30 47]]\n",
            "[Trial 86] Test acc: 0.5337837837837838, Best val acc: 0.6016949152542372\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:13:51,136] Trial 86 finished with value: 0.5337837837837838 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.006547017288066837, 'learning_rate': 0.0032177639684185036, 'num_epoch': 200}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006813854125187977}\n",
            "Epoch 100/2000, Train Loss: 0.696528, Val Loss: 0.696554, Val Acc: 0.500000\n",
            "Epoch 200/2000, Train Loss: 0.696510, Val Loss: 0.696528, Val Acc: 0.550847\n",
            "Epoch 300/2000, Train Loss: 0.696495, Val Loss: 0.696504, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.696524, Val Loss: 0.696478, Val Acc: 0.593220\n",
            "Epoch 500/2000, Train Loss: 0.696471, Val Loss: 0.696461, Val Acc: 0.601695\n",
            "Epoch 600/2000, Train Loss: 0.696494, Val Loss: 0.696419, Val Acc: 0.567797\n",
            "Epoch 700/2000, Train Loss: 0.696436, Val Loss: 0.696391, Val Acc: 0.559322\n",
            "Epoch 800/2000, Train Loss: 0.696439, Val Loss: 0.696367, Val Acc: 0.567797\n",
            "Epoch 900/2000, Train Loss: 0.696433, Val Loss: 0.696335, Val Acc: 0.559322\n",
            "Epoch 1000/2000, Train Loss: 0.696363, Val Loss: 0.696322, Val Acc: 0.542373\n",
            "Epoch 1100/2000, Train Loss: 0.696463, Val Loss: 0.696312, Val Acc: 0.550847\n",
            "Epoch 1200/2000, Train Loss: 0.696454, Val Loss: 0.696297, Val Acc: 0.533898\n",
            "Epoch 1300/2000, Train Loss: 0.696372, Val Loss: 0.696301, Val Acc: 0.559322\n",
            "Epoch 1400/2000, Train Loss: 0.696429, Val Loss: 0.696306, Val Acc: 0.567797\n",
            "Epoch 1500/2000, Train Loss: 0.696331, Val Loss: 0.696301, Val Acc: 0.550847\n",
            "Epoch 1600/2000, Train Loss: 0.696398, Val Loss: 0.696293, Val Acc: 0.533898\n",
            "Epoch 1700/2000, Train Loss: 0.696421, Val Loss: 0.696288, Val Acc: 0.550847\n",
            "Epoch 1800/2000, Train Loss: 0.696340, Val Loss: 0.696290, Val Acc: 0.542373\n",
            "Epoch 1900/2000, Train Loss: 0.696373, Val Loss: 0.696276, Val Acc: 0.542373\n",
            "Epoch 2000/2000, Train Loss: 0.696416, Val Loss: 0.696283, Val Acc: 0.550847\n",
            "Test Loss: 0.6965452432632446 Test Accuracy: 0.47297297297297297\n",
            "weighted: Test F1: 0.6965452432632446 Test Precision: 0.47297297297297297 Test Recall: 0.47297297297297297\n",
            "[[42 29]\n",
            " [49 28]]\n",
            "[Trial 87] Test acc: 0.47297297297297297, Best val acc: 0.6016949152542372\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:15:16,540] Trial 87 finished with value: 0.47297297297297297 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006813854125187977, 'learning_rate': 0.0004411180181298664, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.007180491659283091}\n",
            "Epoch 100/2000, Train Loss: 0.696888, Val Loss: 0.696706, Val Acc: 0.533898\n",
            "Epoch 200/2000, Train Loss: 0.696773, Val Loss: 0.696634, Val Acc: 0.525424\n",
            "Epoch 300/2000, Train Loss: 0.696827, Val Loss: 0.696685, Val Acc: 0.567797\n",
            "Epoch 400/2000, Train Loss: 0.696775, Val Loss: 0.696676, Val Acc: 0.542373\n",
            "Epoch 500/2000, Train Loss: 0.696754, Val Loss: 0.696765, Val Acc: 0.466102\n",
            "Epoch 600/2000, Train Loss: 0.696830, Val Loss: 0.696735, Val Acc: 0.533898\n",
            "Epoch 700/2000, Train Loss: 0.696765, Val Loss: 0.696759, Val Acc: 0.474576\n",
            "Epoch 800/2000, Train Loss: 0.696854, Val Loss: 0.696805, Val Acc: 0.474576\n",
            "Epoch 900/2000, Train Loss: 0.696794, Val Loss: 0.696706, Val Acc: 0.483051\n",
            "Epoch 1000/2000, Train Loss: 0.696728, Val Loss: 0.696802, Val Acc: 0.474576\n",
            "Epoch 1100/2000, Train Loss: 0.696787, Val Loss: 0.696674, Val Acc: 0.508475\n",
            "Epoch 1200/2000, Train Loss: 0.696818, Val Loss: 0.696713, Val Acc: 0.516949\n",
            "Epoch 1300/2000, Train Loss: 0.696658, Val Loss: 0.696615, Val Acc: 0.542373\n",
            "Epoch 1400/2000, Train Loss: 0.696696, Val Loss: 0.696616, Val Acc: 0.542373\n",
            "Epoch 1500/2000, Train Loss: 0.696707, Val Loss: 0.696761, Val Acc: 0.474576\n",
            "Epoch 1600/2000, Train Loss: 0.696773, Val Loss: 0.696687, Val Acc: 0.533898\n",
            "Epoch 1700/2000, Train Loss: 0.696725, Val Loss: 0.696797, Val Acc: 0.474576\n",
            "Epoch 1800/2000, Train Loss: 0.696699, Val Loss: 0.696565, Val Acc: 0.525424\n",
            "Epoch 1900/2000, Train Loss: 0.696638, Val Loss: 0.696633, Val Acc: 0.516949\n",
            "Epoch 2000/2000, Train Loss: 0.696764, Val Loss: 0.696716, Val Acc: 0.474576\n",
            "Test Loss: 0.6965126991271973 Test Accuracy: 0.5202702702702703\n",
            "weighted: Test F1: 0.6965126991271973 Test Precision: 0.5202702702702703 Test Recall: 0.5202702702702703\n",
            "[[ 0 71]\n",
            " [ 0 77]]\n",
            "[Trial 88] Test acc: 0.5202702702702703, Best val acc: 0.5677966101694916\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:16:36,919] Trial 88 finished with value: 0.5202702702702703 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.007180491659283091, 'learning_rate': 0.00525714339880724, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006356968746690425}\n",
            "Epoch 100/500, Train Loss: 0.696386, Val Loss: 0.696098, Val Acc: 0.525424\n",
            "Epoch 200/500, Train Loss: 0.696444, Val Loss: 0.696104, Val Acc: 0.516949\n",
            "Epoch 300/500, Train Loss: 0.696362, Val Loss: 0.696109, Val Acc: 0.516949\n",
            "Epoch 400/500, Train Loss: 0.696354, Val Loss: 0.696113, Val Acc: 0.516949\n",
            "Epoch 500/500, Train Loss: 0.696332, Val Loss: 0.696118, Val Acc: 0.559322\n",
            "Test Loss: 0.6965097784996033 Test Accuracy: 0.4594594594594595\n",
            "weighted: Test F1: 0.6965097784996033 Test Precision: 0.4594594594594595 Test Recall: 0.4594594594594595\n",
            "[[58 13]\n",
            " [67 10]]\n",
            "[Trial 89] Test acc: 0.4594594594594595, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:16:56,673] Trial 89 finished with value: 0.4594594594594595 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006356968746690425, 'learning_rate': 6.806656778632316e-05, 'num_epoch': 500}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.006092628503307134}\n",
            "Epoch 100/2000, Train Loss: 0.692742, Val Loss: 0.695621, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.689337, Val Loss: 0.692659, Val Acc: 0.550847\n",
            "Epoch 300/2000, Train Loss: 0.687123, Val Loss: 0.689080, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.679746, Val Loss: 0.684283, Val Acc: 0.635593\n",
            "Epoch 500/2000, Train Loss: 0.671663, Val Loss: 0.677752, Val Acc: 0.644068\n",
            "Epoch 600/2000, Train Loss: 0.666014, Val Loss: 0.668682, Val Acc: 0.677966\n",
            "Epoch 700/2000, Train Loss: 0.654594, Val Loss: 0.656591, Val Acc: 0.686441\n",
            "Epoch 800/2000, Train Loss: 0.621270, Val Loss: 0.640219, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.608775, Val Loss: 0.620111, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.591076, Val Loss: 0.596719, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.552183, Val Loss: 0.578037, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.522763, Val Loss: 0.563237, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.511651, Val Loss: 0.553827, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.489436, Val Loss: 0.547061, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.475665, Val Loss: 0.547078, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.468415, Val Loss: 0.545113, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.465873, Val Loss: 0.547556, Val Acc: 0.694915\n",
            "Epoch 1800/2000, Train Loss: 0.469062, Val Loss: 0.547970, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.456375, Val Loss: 0.549641, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.454530, Val Loss: 0.550706, Val Acc: 0.728814\n",
            "Test Loss: 0.5331831574440002 Test Accuracy: 0.7162162162162162\n",
            "weighted: Test F1: 0.5331831574440002 Test Precision: 0.7162162162162162 Test Recall: 0.7162162162162162\n",
            "[[61 10]\n",
            " [32 45]]\n",
            "[Trial 90] Test acc: 0.7162162162162162, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:18:21,422] Trial 90 finished with value: 0.7162162162162162 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.006092628503307134, 'learning_rate': 0.0022343887105038046, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006665520920955658}\n",
            "Epoch 100/2000, Train Loss: 0.696560, Val Loss: 0.694910, Val Acc: 0.584746\n",
            "Epoch 200/2000, Train Loss: 0.694855, Val Loss: 0.693348, Val Acc: 0.669492\n",
            "Epoch 300/2000, Train Loss: 0.693147, Val Loss: 0.691127, Val Acc: 0.694915\n",
            "Epoch 400/2000, Train Loss: 0.688720, Val Loss: 0.687138, Val Acc: 0.745763\n",
            "Epoch 500/2000, Train Loss: 0.682876, Val Loss: 0.680359, Val Acc: 0.720339\n",
            "Epoch 600/2000, Train Loss: 0.667123, Val Loss: 0.668267, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.654177, Val Loss: 0.648243, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.625061, Val Loss: 0.617589, Val Acc: 0.762712\n",
            "Epoch 900/2000, Train Loss: 0.568703, Val Loss: 0.579778, Val Acc: 0.745763\n",
            "Epoch 1000/2000, Train Loss: 0.547417, Val Loss: 0.552471, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.492649, Val Loss: 0.537482, Val Acc: 0.745763\n",
            "Epoch 1200/2000, Train Loss: 0.465466, Val Loss: 0.533903, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.450911, Val Loss: 0.538541, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.445089, Val Loss: 0.543773, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.425585, Val Loss: 0.544607, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.438012, Val Loss: 0.545756, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.422678, Val Loss: 0.551105, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.420009, Val Loss: 0.550762, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.423796, Val Loss: 0.550467, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.414095, Val Loss: 0.554135, Val Acc: 0.737288\n",
            "Test Loss: 0.5435625910758972 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5435625910758972 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[63  8]\n",
            " [26 51]]\n",
            "[Trial 91] Test acc: 0.7702702702702703, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:19:41,959] Trial 91 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006665520920955658, 'learning_rate': 0.004237055095995651, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006501225025973693}\n",
            "Epoch 100/2000, Train Loss: 0.693572, Val Loss: 0.695258, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.687004, Val Loss: 0.691292, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.673878, Val Loss: 0.681138, Val Acc: 0.711864\n",
            "Epoch 400/2000, Train Loss: 0.646042, Val Loss: 0.655620, Val Acc: 0.694915\n",
            "Epoch 500/2000, Train Loss: 0.585630, Val Loss: 0.599100, Val Acc: 0.711864\n",
            "Epoch 600/2000, Train Loss: 0.526296, Val Loss: 0.553250, Val Acc: 0.703390\n",
            "Epoch 700/2000, Train Loss: 0.463568, Val Loss: 0.539731, Val Acc: 0.737288\n",
            "Epoch 800/2000, Train Loss: 0.452828, Val Loss: 0.539340, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.447218, Val Loss: 0.546287, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.434241, Val Loss: 0.548176, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.401960, Val Loss: 0.551693, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.396416, Val Loss: 0.559961, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.390633, Val Loss: 0.562852, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.370109, Val Loss: 0.579217, Val Acc: 0.703390\n",
            "Epoch 1500/2000, Train Loss: 0.349595, Val Loss: 0.582286, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.349903, Val Loss: 0.597298, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.323216, Val Loss: 0.614670, Val Acc: 0.745763\n",
            "Epoch 1800/2000, Train Loss: 0.299675, Val Loss: 0.638255, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.307701, Val Loss: 0.643274, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.316429, Val Loss: 0.639206, Val Acc: 0.745763\n",
            "Test Loss: 0.6418880224227905 Test Accuracy: 0.7297297297297297\n",
            "weighted: Test F1: 0.6418880224227905 Test Precision: 0.7297297297297297 Test Recall: 0.7297297297297297\n",
            "[[51 20]\n",
            " [20 57]]\n",
            "[Trial 92] Test acc: 0.7297297297297297, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:21:03,047] Trial 92 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006501225025973693, 'learning_rate': 0.0065722880179774346, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006879140064817666}\n",
            "Epoch 100/2000, Train Loss: 0.694035, Val Loss: 0.694146, Val Acc: 0.601695\n",
            "Epoch 200/2000, Train Loss: 0.691332, Val Loss: 0.690786, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.679252, Val Loss: 0.679943, Val Acc: 0.644068\n",
            "Epoch 400/2000, Train Loss: 0.642041, Val Loss: 0.648235, Val Acc: 0.677966\n",
            "Epoch 500/2000, Train Loss: 0.552492, Val Loss: 0.571526, Val Acc: 0.737288\n",
            "Epoch 600/2000, Train Loss: 0.483307, Val Loss: 0.541403, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.438851, Val Loss: 0.549920, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.436785, Val Loss: 0.547028, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.427597, Val Loss: 0.558849, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.400007, Val Loss: 0.559885, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.389411, Val Loss: 0.572430, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.379218, Val Loss: 0.581395, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.374881, Val Loss: 0.595554, Val Acc: 0.694915\n",
            "Epoch 1400/2000, Train Loss: 0.357737, Val Loss: 0.606681, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.318989, Val Loss: 0.634799, Val Acc: 0.686441\n",
            "Epoch 1600/2000, Train Loss: 0.313186, Val Loss: 0.649293, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.306371, Val Loss: 0.649481, Val Acc: 0.703390\n",
            "Epoch 1800/2000, Train Loss: 0.295164, Val Loss: 0.690971, Val Acc: 0.745763\n",
            "Epoch 1900/2000, Train Loss: 0.244185, Val Loss: 0.714103, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.243331, Val Loss: 0.729622, Val Acc: 0.737288\n",
            "Test Loss: 0.7140692472457886 Test Accuracy: 0.6959459459459459\n",
            "weighted: Test F1: 0.7140692472457886 Test Precision: 0.6959459459459459 Test Recall: 0.6959459459459459\n",
            "[[48 23]\n",
            " [22 55]]\n",
            "[Trial 93] Test acc: 0.6959459459459459, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:22:23,674] Trial 93 finished with value: 0.6959459459459459 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006879140064817666, 'learning_rate': 0.00895495868290863, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.00638686394227013}\n",
            "Epoch 100/2000, Train Loss: 0.693369, Val Loss: 0.691796, Val Acc: 0.677966\n",
            "Epoch 200/2000, Train Loss: 0.689611, Val Loss: 0.689180, Val Acc: 0.677966\n",
            "Epoch 300/2000, Train Loss: 0.683259, Val Loss: 0.684787, Val Acc: 0.635593\n",
            "Epoch 400/2000, Train Loss: 0.672243, Val Loss: 0.676110, Val Acc: 0.644068\n",
            "Epoch 500/2000, Train Loss: 0.659410, Val Loss: 0.658275, Val Acc: 0.669492\n",
            "Epoch 600/2000, Train Loss: 0.622343, Val Loss: 0.625733, Val Acc: 0.762712\n",
            "Epoch 700/2000, Train Loss: 0.584161, Val Loss: 0.583184, Val Acc: 0.754237\n",
            "Epoch 800/2000, Train Loss: 0.531449, Val Loss: 0.549827, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.489963, Val Loss: 0.534135, Val Acc: 0.745763\n",
            "Epoch 1000/2000, Train Loss: 0.450465, Val Loss: 0.536241, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.455111, Val Loss: 0.539604, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.432870, Val Loss: 0.543812, Val Acc: 0.703390\n",
            "Epoch 1300/2000, Train Loss: 0.439554, Val Loss: 0.546182, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.428701, Val Loss: 0.545226, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.411407, Val Loss: 0.548304, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.416439, Val Loss: 0.554078, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.417913, Val Loss: 0.551293, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.404736, Val Loss: 0.559717, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.405302, Val Loss: 0.557194, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.391889, Val Loss: 0.560719, Val Acc: 0.728814\n",
            "Test Loss: 0.5435487031936646 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.5435487031936646 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[62  9]\n",
            " [24 53]]\n",
            "[Trial 94] Test acc: 0.777027027027027, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:23:44,262] Trial 94 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.00638686394227013, 'learning_rate': 0.004363036194670324, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005914217534731548}\n",
            "Epoch 100/2000, Train Loss: 0.695823, Val Loss: 0.695620, Val Acc: 0.584746\n",
            "Epoch 200/2000, Train Loss: 0.695254, Val Loss: 0.694989, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.694488, Val Loss: 0.694025, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.692938, Val Loss: 0.692768, Val Acc: 0.618644\n",
            "Epoch 500/2000, Train Loss: 0.692064, Val Loss: 0.691168, Val Acc: 0.618644\n",
            "Epoch 600/2000, Train Loss: 0.688808, Val Loss: 0.688533, Val Acc: 0.627119\n",
            "Epoch 700/2000, Train Loss: 0.685251, Val Loss: 0.684261, Val Acc: 0.627119\n",
            "Epoch 800/2000, Train Loss: 0.676726, Val Loss: 0.677550, Val Acc: 0.661017\n",
            "Epoch 900/2000, Train Loss: 0.667827, Val Loss: 0.666639, Val Acc: 0.652542\n",
            "Epoch 1000/2000, Train Loss: 0.645077, Val Loss: 0.648485, Val Acc: 0.669492\n",
            "Epoch 1100/2000, Train Loss: 0.615325, Val Loss: 0.619503, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.575047, Val Loss: 0.586529, Val Acc: 0.703390\n",
            "Epoch 1300/2000, Train Loss: 0.536568, Val Loss: 0.561518, Val Acc: 0.677966\n",
            "Epoch 1400/2000, Train Loss: 0.497452, Val Loss: 0.548305, Val Acc: 0.703390\n",
            "Epoch 1500/2000, Train Loss: 0.484405, Val Loss: 0.542717, Val Acc: 0.703390\n",
            "Epoch 1600/2000, Train Loss: 0.450302, Val Loss: 0.542070, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.449856, Val Loss: 0.546224, Val Acc: 0.694915\n",
            "Epoch 1800/2000, Train Loss: 0.433522, Val Loss: 0.546491, Val Acc: 0.703390\n",
            "Epoch 1900/2000, Train Loss: 0.452928, Val Loss: 0.550228, Val Acc: 0.703390\n",
            "Epoch 2000/2000, Train Loss: 0.439671, Val Loss: 0.552491, Val Acc: 0.720339\n",
            "Test Loss: 0.525363028049469 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.525363028049469 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[62  9]\n",
            " [27 50]]\n",
            "[Trial 95] Test acc: 0.7567567567567568, Best val acc: 0.7203389830508474\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:25:04,932] Trial 95 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.005914217534731548, 'learning_rate': 0.003603915772892864, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'relu', 'lam': 0.0063736832481728995}\n",
            "Epoch 100/1500, Train Loss: 0.694661, Val Loss: 0.694182, Val Acc: 0.627119\n",
            "Epoch 200/1500, Train Loss: 0.692356, Val Loss: 0.692644, Val Acc: 0.618644\n",
            "Epoch 300/1500, Train Loss: 0.689564, Val Loss: 0.689553, Val Acc: 0.652542\n",
            "Epoch 400/1500, Train Loss: 0.679694, Val Loss: 0.682630, Val Acc: 0.652542\n",
            "Epoch 500/1500, Train Loss: 0.665130, Val Loss: 0.666066, Val Acc: 0.669492\n",
            "Epoch 600/1500, Train Loss: 0.627534, Val Loss: 0.628948, Val Acc: 0.686441\n",
            "Epoch 700/1500, Train Loss: 0.566895, Val Loss: 0.580182, Val Acc: 0.720339\n",
            "Epoch 800/1500, Train Loss: 0.494623, Val Loss: 0.548173, Val Acc: 0.711864\n",
            "Epoch 900/1500, Train Loss: 0.468858, Val Loss: 0.543043, Val Acc: 0.728814\n",
            "Epoch 1000/1500, Train Loss: 0.444031, Val Loss: 0.540517, Val Acc: 0.720339\n",
            "Epoch 1100/1500, Train Loss: 0.443709, Val Loss: 0.541711, Val Acc: 0.737288\n",
            "Epoch 1200/1500, Train Loss: 0.434492, Val Loss: 0.543165, Val Acc: 0.720339\n",
            "Epoch 1300/1500, Train Loss: 0.420918, Val Loss: 0.549606, Val Acc: 0.720339\n",
            "Epoch 1400/1500, Train Loss: 0.417424, Val Loss: 0.544250, Val Acc: 0.720339\n",
            "Epoch 1500/1500, Train Loss: 0.414461, Val Loss: 0.552842, Val Acc: 0.711864\n",
            "Test Loss: 0.5425739884376526 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5425739884376526 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[64  7]\n",
            " [28 49]]\n",
            "[Trial 96] Test acc: 0.7635135135135135, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:26:05,522] Trial 96 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'relu', 'lam': 0.0063736832481728995, 'learning_rate': 0.005610853539662921, 'num_epoch': 1500}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0065596647420889335}\n",
            "Epoch 100/2000, Train Loss: 0.696481, Val Loss: 0.694567, Val Acc: 0.559322\n",
            "Epoch 200/2000, Train Loss: 0.695428, Val Loss: 0.694529, Val Acc: 0.559322\n",
            "Epoch 300/2000, Train Loss: 0.695951, Val Loss: 0.694472, Val Acc: 0.559322\n",
            "Epoch 400/2000, Train Loss: 0.696156, Val Loss: 0.694416, Val Acc: 0.576271\n",
            "Epoch 500/2000, Train Loss: 0.695933, Val Loss: 0.694366, Val Acc: 0.567797\n",
            "Epoch 600/2000, Train Loss: 0.695854, Val Loss: 0.694287, Val Acc: 0.559322\n",
            "Epoch 700/2000, Train Loss: 0.695579, Val Loss: 0.694204, Val Acc: 0.576271\n",
            "Epoch 800/2000, Train Loss: 0.695834, Val Loss: 0.694103, Val Acc: 0.593220\n",
            "Epoch 900/2000, Train Loss: 0.695750, Val Loss: 0.693985, Val Acc: 0.618644\n",
            "Epoch 1000/2000, Train Loss: 0.695205, Val Loss: 0.693847, Val Acc: 0.610169\n",
            "Epoch 1100/2000, Train Loss: 0.695796, Val Loss: 0.693716, Val Acc: 0.610169\n",
            "Epoch 1200/2000, Train Loss: 0.695317, Val Loss: 0.693589, Val Acc: 0.627119\n",
            "Epoch 1300/2000, Train Loss: 0.695552, Val Loss: 0.693471, Val Acc: 0.618644\n",
            "Epoch 1400/2000, Train Loss: 0.695100, Val Loss: 0.693349, Val Acc: 0.610169\n",
            "Epoch 1500/2000, Train Loss: 0.694469, Val Loss: 0.693233, Val Acc: 0.610169\n",
            "Epoch 1600/2000, Train Loss: 0.694703, Val Loss: 0.693108, Val Acc: 0.618644\n",
            "Epoch 1700/2000, Train Loss: 0.694306, Val Loss: 0.692988, Val Acc: 0.593220\n",
            "Epoch 1800/2000, Train Loss: 0.694680, Val Loss: 0.692870, Val Acc: 0.601695\n",
            "Epoch 1900/2000, Train Loss: 0.695000, Val Loss: 0.692748, Val Acc: 0.610169\n",
            "Epoch 2000/2000, Train Loss: 0.694405, Val Loss: 0.692620, Val Acc: 0.601695\n",
            "Test Loss: 0.6948891878128052 Test Accuracy: 0.5608108108108109\n",
            "weighted: Test F1: 0.6948891878128052 Test Precision: 0.5608108108108109 Test Recall: 0.5608108108108109\n",
            "[[37 34]\n",
            " [31 46]]\n",
            "[Trial 97] Test acc: 0.5608108108108109, Best val acc: 0.6271186440677966\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:27:25,751] Trial 97 finished with value: 0.5608108108108109 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0065596647420889335, 'learning_rate': 0.00023079390611240426, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006225098605195037}\n",
            "Epoch 100/2000, Train Loss: 0.694278, Val Loss: 0.694903, Val Acc: 0.567797\n",
            "Epoch 200/2000, Train Loss: 0.694657, Val Loss: 0.693493, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.690008, Val Loss: 0.691858, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.690121, Val Loss: 0.689792, Val Acc: 0.627119\n",
            "Epoch 500/2000, Train Loss: 0.684587, Val Loss: 0.686848, Val Acc: 0.635593\n",
            "Epoch 600/2000, Train Loss: 0.687709, Val Loss: 0.682887, Val Acc: 0.652542\n",
            "Epoch 700/2000, Train Loss: 0.677936, Val Loss: 0.677722, Val Acc: 0.661017\n",
            "Epoch 800/2000, Train Loss: 0.668407, Val Loss: 0.670402, Val Acc: 0.677966\n",
            "Epoch 900/2000, Train Loss: 0.656743, Val Loss: 0.659685, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.654709, Val Loss: 0.644662, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.638415, Val Loss: 0.623946, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.592482, Val Loss: 0.598581, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.552463, Val Loss: 0.576732, Val Acc: 0.745763\n",
            "Epoch 1400/2000, Train Loss: 0.522063, Val Loss: 0.557995, Val Acc: 0.745763\n",
            "Epoch 1500/2000, Train Loss: 0.491245, Val Loss: 0.547240, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.472024, Val Loss: 0.542987, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.467193, Val Loss: 0.542743, Val Acc: 0.745763\n",
            "Epoch 1800/2000, Train Loss: 0.454509, Val Loss: 0.542251, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.458569, Val Loss: 0.544570, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.431004, Val Loss: 0.544338, Val Acc: 0.737288\n",
            "Test Loss: 0.530115008354187 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.530115008354187 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[61 10]\n",
            " [29 48]]\n",
            "[Trial 98] Test acc: 0.7364864864864865, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:28:46,493] Trial 98 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006225098605195037, 'learning_rate': 0.0029183225998844625, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.0064417149788473065}\n",
            "Epoch 100/2000, Train Loss: 0.696405, Val Loss: 0.696539, Val Acc: 0.457627\n",
            "Epoch 200/2000, Train Loss: 0.696464, Val Loss: 0.696349, Val Acc: 0.457627\n",
            "Epoch 300/2000, Train Loss: 0.696398, Val Loss: 0.696466, Val Acc: 0.474576\n",
            "Epoch 400/2000, Train Loss: 0.696246, Val Loss: 0.696331, Val Acc: 0.559322\n",
            "Epoch 500/2000, Train Loss: 0.696373, Val Loss: 0.696343, Val Acc: 0.542373\n",
            "Epoch 600/2000, Train Loss: 0.696274, Val Loss: 0.696316, Val Acc: 0.559322\n",
            "Epoch 700/2000, Train Loss: 0.696096, Val Loss: 0.696280, Val Acc: 0.550847\n",
            "Epoch 800/2000, Train Loss: 0.696235, Val Loss: 0.696169, Val Acc: 0.559322\n",
            "Epoch 900/2000, Train Loss: 0.695810, Val Loss: 0.695951, Val Acc: 0.559322\n",
            "Epoch 1000/2000, Train Loss: 0.695451, Val Loss: 0.695864, Val Acc: 0.567797\n",
            "Epoch 1100/2000, Train Loss: 0.695042, Val Loss: 0.695602, Val Acc: 0.576271\n",
            "Epoch 1200/2000, Train Loss: 0.694962, Val Loss: 0.695081, Val Acc: 0.576271\n",
            "Epoch 1300/2000, Train Loss: 0.692820, Val Loss: 0.694001, Val Acc: 0.593220\n",
            "Epoch 1400/2000, Train Loss: 0.691046, Val Loss: 0.691708, Val Acc: 0.601695\n",
            "Epoch 1500/2000, Train Loss: 0.684099, Val Loss: 0.684997, Val Acc: 0.635593\n",
            "Epoch 1600/2000, Train Loss: 0.661234, Val Loss: 0.664415, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.596765, Val Loss: 0.608689, Val Acc: 0.754237\n",
            "Epoch 1800/2000, Train Loss: 0.508284, Val Loss: 0.552626, Val Acc: 0.745763\n",
            "Epoch 1900/2000, Train Loss: 0.459974, Val Loss: 0.540659, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.458892, Val Loss: 0.546682, Val Acc: 0.728814\n",
            "Test Loss: 0.5301068425178528 Test Accuracy: 0.7297297297297297\n",
            "weighted: Test F1: 0.5301068425178528 Test Precision: 0.7297297297297297 Test Recall: 0.7297297297297297\n",
            "[[61 10]\n",
            " [30 47]]\n",
            "[Trial 99] Test acc: 0.7297297297297297, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:30:07,248] Trial 99 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.0064417149788473065, 'learning_rate': 0.007293994830105431, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006080263287240636}\n",
            "Epoch 100/2000, Train Loss: 0.698238, Val Loss: 0.697287, Val Acc: 0.466102\n",
            "Epoch 200/2000, Train Loss: 0.697186, Val Loss: 0.697126, Val Acc: 0.474576\n",
            "Epoch 300/2000, Train Loss: 0.696627, Val Loss: 0.696897, Val Acc: 0.500000\n",
            "Epoch 400/2000, Train Loss: 0.696405, Val Loss: 0.696662, Val Acc: 0.491525\n",
            "Epoch 500/2000, Train Loss: 0.696709, Val Loss: 0.696488, Val Acc: 0.483051\n",
            "Epoch 600/2000, Train Loss: 0.696141, Val Loss: 0.696313, Val Acc: 0.491525\n",
            "Epoch 700/2000, Train Loss: 0.695830, Val Loss: 0.696127, Val Acc: 0.483051\n",
            "Epoch 800/2000, Train Loss: 0.694780, Val Loss: 0.695912, Val Acc: 0.491525\n",
            "Epoch 900/2000, Train Loss: 0.695213, Val Loss: 0.695704, Val Acc: 0.500000\n",
            "Epoch 1000/2000, Train Loss: 0.695130, Val Loss: 0.695487, Val Acc: 0.516949\n",
            "Epoch 1100/2000, Train Loss: 0.694264, Val Loss: 0.695259, Val Acc: 0.576271\n",
            "Epoch 1200/2000, Train Loss: 0.694039, Val Loss: 0.695011, Val Acc: 0.576271\n",
            "Epoch 1300/2000, Train Loss: 0.694688, Val Loss: 0.694695, Val Acc: 0.584746\n",
            "Epoch 1400/2000, Train Loss: 0.693737, Val Loss: 0.694370, Val Acc: 0.576271\n",
            "Epoch 1500/2000, Train Loss: 0.691963, Val Loss: 0.694044, Val Acc: 0.584746\n",
            "Epoch 1600/2000, Train Loss: 0.691956, Val Loss: 0.693583, Val Acc: 0.576271\n",
            "Epoch 1700/2000, Train Loss: 0.691298, Val Loss: 0.693039, Val Acc: 0.584746\n",
            "Epoch 1800/2000, Train Loss: 0.691596, Val Loss: 0.692448, Val Acc: 0.593220\n",
            "Epoch 1900/2000, Train Loss: 0.692034, Val Loss: 0.691752, Val Acc: 0.593220\n",
            "Epoch 2000/2000, Train Loss: 0.687900, Val Loss: 0.690972, Val Acc: 0.593220\n",
            "Test Loss: 0.6890608072280884 Test Accuracy: 0.6418918918918919\n",
            "weighted: Test F1: 0.6890608072280884 Test Precision: 0.6418918918918919 Test Recall: 0.6418918918918919\n",
            "[[45 26]\n",
            " [27 50]]\n",
            "[Trial 100] Test acc: 0.6418918918918919, Best val acc: 0.5932203389830508\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:31:27,441] Trial 100 finished with value: 0.6418918918918919 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006080263287240636, 'learning_rate': 0.0010987718164374612, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006807328165056578}\n",
            "Epoch 100/2000, Train Loss: 0.697012, Val Loss: 0.694711, Val Acc: 0.576271\n",
            "Epoch 200/2000, Train Loss: 0.693684, Val Loss: 0.692843, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.691441, Val Loss: 0.690842, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.689779, Val Loss: 0.687889, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.687169, Val Loss: 0.683470, Val Acc: 0.661017\n",
            "Epoch 600/2000, Train Loss: 0.679969, Val Loss: 0.676311, Val Acc: 0.677966\n",
            "Epoch 700/2000, Train Loss: 0.661859, Val Loss: 0.664371, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.640478, Val Loss: 0.644658, Val Acc: 0.669492\n",
            "Epoch 900/2000, Train Loss: 0.601692, Val Loss: 0.614223, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.566887, Val Loss: 0.581785, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.515859, Val Loss: 0.556656, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.494967, Val Loss: 0.543331, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.469055, Val Loss: 0.539269, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.450530, Val Loss: 0.541605, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.432312, Val Loss: 0.540222, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.435270, Val Loss: 0.542406, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.423968, Val Loss: 0.543087, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.417749, Val Loss: 0.542206, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.415840, Val Loss: 0.547722, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.417936, Val Loss: 0.546964, Val Acc: 0.737288\n",
            "Test Loss: 0.5371555089950562 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.5371555089950562 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[59 12]\n",
            " [21 56]]\n",
            "[Trial 101] Test acc: 0.777027027027027, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:32:48,411] Trial 101 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006807328165056578, 'learning_rate': 0.004326587325467637, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006752984556064722}\n",
            "Epoch 100/2000, Train Loss: 0.695283, Val Loss: 0.695963, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.693575, Val Loss: 0.694490, Val Acc: 0.559322\n",
            "Epoch 300/2000, Train Loss: 0.690988, Val Loss: 0.691788, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.684516, Val Loss: 0.685962, Val Acc: 0.627119\n",
            "Epoch 500/2000, Train Loss: 0.664863, Val Loss: 0.672276, Val Acc: 0.661017\n",
            "Epoch 600/2000, Train Loss: 0.630740, Val Loss: 0.641682, Val Acc: 0.703390\n",
            "Epoch 700/2000, Train Loss: 0.585152, Val Loss: 0.593333, Val Acc: 0.754237\n",
            "Epoch 800/2000, Train Loss: 0.518309, Val Loss: 0.554468, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.487678, Val Loss: 0.541356, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.459880, Val Loss: 0.542077, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.464794, Val Loss: 0.547804, Val Acc: 0.737288\n",
            "Epoch 1200/2000, Train Loss: 0.444147, Val Loss: 0.547033, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.434272, Val Loss: 0.547005, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.436849, Val Loss: 0.549790, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.419028, Val Loss: 0.553409, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.404755, Val Loss: 0.549639, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.419505, Val Loss: 0.549458, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.408299, Val Loss: 0.552168, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.397141, Val Loss: 0.557462, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.388107, Val Loss: 0.562346, Val Acc: 0.728814\n",
            "Test Loss: 0.5569782853126526 Test Accuracy: 0.7837837837837838\n",
            "weighted: Test F1: 0.5569782853126526 Test Precision: 0.7837837837837838 Test Recall: 0.7837837837837838\n",
            "[[62  9]\n",
            " [23 54]]\n",
            "[Trial 102] Test acc: 0.7837837837837838, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:34:09,166] Trial 102 finished with value: 0.7837837837837838 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006752984556064722, 'learning_rate': 0.00503260369433995, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006799190289258722}\n",
            "Epoch 100/2000, Train Loss: 0.694394, Val Loss: 0.694852, Val Acc: 0.567797\n",
            "Epoch 200/2000, Train Loss: 0.691583, Val Loss: 0.692764, Val Acc: 0.610169\n",
            "Epoch 300/2000, Train Loss: 0.688587, Val Loss: 0.689632, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.678745, Val Loss: 0.684271, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.671125, Val Loss: 0.674196, Val Acc: 0.669492\n",
            "Epoch 600/2000, Train Loss: 0.647247, Val Loss: 0.656524, Val Acc: 0.669492\n",
            "Epoch 700/2000, Train Loss: 0.614020, Val Loss: 0.626431, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.570487, Val Loss: 0.588600, Val Acc: 0.745763\n",
            "Epoch 900/2000, Train Loss: 0.528869, Val Loss: 0.559227, Val Acc: 0.711864\n",
            "Epoch 1000/2000, Train Loss: 0.477836, Val Loss: 0.544663, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.463468, Val Loss: 0.541133, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.447848, Val Loss: 0.544524, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.455556, Val Loss: 0.544930, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.442670, Val Loss: 0.547086, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.428258, Val Loss: 0.550366, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.422146, Val Loss: 0.551466, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.429891, Val Loss: 0.554700, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.409959, Val Loss: 0.555532, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.403458, Val Loss: 0.556708, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.406737, Val Loss: 0.560493, Val Acc: 0.728814\n",
            "Test Loss: 0.5335207581520081 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5335207581520081 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[64  7]\n",
            " [28 49]]\n",
            "[Trial 103] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:35:29,278] Trial 103 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006799190289258722, 'learning_rate': 0.0040767817627852514, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007047758810175122}\n",
            "Epoch 100/2000, Train Loss: 0.693832, Val Loss: 0.695321, Val Acc: 0.550847\n",
            "Epoch 200/2000, Train Loss: 0.691071, Val Loss: 0.693157, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.684410, Val Loss: 0.689346, Val Acc: 0.669492\n",
            "Epoch 400/2000, Train Loss: 0.678757, Val Loss: 0.681967, Val Acc: 0.711864\n",
            "Epoch 500/2000, Train Loss: 0.653403, Val Loss: 0.665428, Val Acc: 0.720339\n",
            "Epoch 600/2000, Train Loss: 0.625198, Val Loss: 0.634324, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.574126, Val Loss: 0.591466, Val Acc: 0.703390\n",
            "Epoch 800/2000, Train Loss: 0.524544, Val Loss: 0.562297, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.487900, Val Loss: 0.548991, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.462059, Val Loss: 0.546795, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.451282, Val Loss: 0.551527, Val Acc: 0.703390\n",
            "Epoch 1200/2000, Train Loss: 0.448460, Val Loss: 0.554856, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.429697, Val Loss: 0.556098, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.426308, Val Loss: 0.558718, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.426341, Val Loss: 0.562654, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.421128, Val Loss: 0.565795, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.411141, Val Loss: 0.572348, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.430711, Val Loss: 0.570941, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.410650, Val Loss: 0.575411, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.400867, Val Loss: 0.585846, Val Acc: 0.720339\n",
            "Test Loss: 0.546567440032959 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.546567440032959 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[59 12]\n",
            " [23 54]]\n",
            "[Trial 104] Test acc: 0.7635135135135135, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:36:50,137] Trial 104 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007047758810175122, 'learning_rate': 0.004922267076128953, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006899785336328029}\n",
            "Epoch 100/2000, Train Loss: 0.694895, Val Loss: 0.696356, Val Acc: 0.516949\n",
            "Epoch 200/2000, Train Loss: 0.692739, Val Loss: 0.694448, Val Acc: 0.610169\n",
            "Epoch 300/2000, Train Loss: 0.690398, Val Loss: 0.690890, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.682291, Val Loss: 0.683604, Val Acc: 0.686441\n",
            "Epoch 500/2000, Train Loss: 0.657170, Val Loss: 0.667166, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.630810, Val Loss: 0.631048, Val Acc: 0.737288\n",
            "Epoch 700/2000, Train Loss: 0.559905, Val Loss: 0.578801, Val Acc: 0.762712\n",
            "Epoch 800/2000, Train Loss: 0.492460, Val Loss: 0.546803, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.478396, Val Loss: 0.539721, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.444358, Val Loss: 0.542181, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.441290, Val Loss: 0.544877, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.441728, Val Loss: 0.548334, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.424090, Val Loss: 0.552796, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.418001, Val Loss: 0.552739, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.404462, Val Loss: 0.556690, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.418603, Val Loss: 0.557119, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.389793, Val Loss: 0.558172, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.384914, Val Loss: 0.562146, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.405585, Val Loss: 0.575308, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.380028, Val Loss: 0.578605, Val Acc: 0.737288\n",
            "Test Loss: 0.5734774470329285 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5734774470329285 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[61 10]\n",
            " [24 53]]\n",
            "[Trial 105] Test acc: 0.7702702702702703, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:38:10,656] Trial 105 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006899785336328029, 'learning_rate': 0.005742858450609081, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.006575853355202719}\n",
            "Epoch 100/1000, Train Loss: 0.696498, Val Loss: 0.696411, Val Acc: 0.525424\n",
            "Epoch 200/1000, Train Loss: 0.696571, Val Loss: 0.696443, Val Acc: 0.474576\n",
            "Epoch 300/1000, Train Loss: 0.696554, Val Loss: 0.696441, Val Acc: 0.466102\n",
            "Epoch 400/1000, Train Loss: 0.696513, Val Loss: 0.696411, Val Acc: 0.525424\n",
            "Epoch 500/1000, Train Loss: 0.696536, Val Loss: 0.696439, Val Acc: 0.466102\n",
            "Epoch 600/1000, Train Loss: 0.696531, Val Loss: 0.696543, Val Acc: 0.474576\n",
            "Epoch 700/1000, Train Loss: 0.696529, Val Loss: 0.696377, Val Acc: 0.525424\n",
            "Epoch 800/1000, Train Loss: 0.696473, Val Loss: 0.696478, Val Acc: 0.474576\n",
            "Epoch 900/1000, Train Loss: 0.696504, Val Loss: 0.696383, Val Acc: 0.525424\n",
            "Epoch 1000/1000, Train Loss: 0.696607, Val Loss: 0.696515, Val Acc: 0.474576\n",
            "Test Loss: 0.6963586807250977 Test Accuracy: 0.5202702702702703\n",
            "weighted: Test F1: 0.6963586807250977 Test Precision: 0.5202702702702703 Test Recall: 0.5202702702702703\n",
            "[[ 0 71]\n",
            " [ 0 77]]\n",
            "[Trial 106] Test acc: 0.5202702702702703, Best val acc: 0.5254237288135594\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:38:53,040] Trial 106 finished with value: 0.5202702702702703 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.006575853355202719, 'learning_rate': 0.004220892258550874, 'num_epoch': 1000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.007134028642202653}\n",
            "Epoch 100/2000, Train Loss: 0.692417, Val Loss: 0.692993, Val Acc: 0.550847\n",
            "Epoch 200/2000, Train Loss: 0.685995, Val Loss: 0.688732, Val Acc: 0.618644\n",
            "Epoch 300/2000, Train Loss: 0.678864, Val Loss: 0.682119, Val Acc: 0.618644\n",
            "Epoch 400/2000, Train Loss: 0.663860, Val Loss: 0.671833, Val Acc: 0.661017\n",
            "Epoch 500/2000, Train Loss: 0.647244, Val Loss: 0.655055, Val Acc: 0.686441\n",
            "Epoch 600/2000, Train Loss: 0.605878, Val Loss: 0.628705, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.574139, Val Loss: 0.594949, Val Acc: 0.703390\n",
            "Epoch 800/2000, Train Loss: 0.542138, Val Loss: 0.570455, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.510171, Val Loss: 0.556917, Val Acc: 0.711864\n",
            "Epoch 1000/2000, Train Loss: 0.478368, Val Loss: 0.549895, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.476120, Val Loss: 0.548091, Val Acc: 0.703390\n",
            "Epoch 1200/2000, Train Loss: 0.468086, Val Loss: 0.549731, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.447632, Val Loss: 0.554489, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.447277, Val Loss: 0.550507, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.451154, Val Loss: 0.556004, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.452623, Val Loss: 0.557837, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.449079, Val Loss: 0.555124, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.447310, Val Loss: 0.557709, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.439760, Val Loss: 0.560655, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.434128, Val Loss: 0.561969, Val Acc: 0.720339\n",
            "Test Loss: 0.55208420753479 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.55208420753479 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[60 11]\n",
            " [30 47]]\n",
            "[Trial 107] Test acc: 0.722972972972973, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:40:17,971] Trial 107 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.007134028642202653, 'learning_rate': 0.0035469426222431537, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006317683017470168}\n",
            "Epoch 100/200, Train Loss: 0.696128, Val Loss: 0.695487, Val Acc: 0.576271\n",
            "Epoch 200/200, Train Loss: 0.695284, Val Loss: 0.694693, Val Acc: 0.559322\n",
            "Test Loss: 0.696074903011322 Test Accuracy: 0.4864864864864865\n",
            "weighted: Test F1: 0.696074903011322 Test Precision: 0.4864864864864865 Test Recall: 0.4864864864864865\n",
            "[[31 40]\n",
            " [36 41]]\n",
            "[Trial 108] Test acc: 0.4864864864864865, Best val acc: 0.576271186440678\n",
            "---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-06-14 18:40:25,736] Trial 108 finished with value: 0.4864864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006317683017470168, 'learning_rate': 0.0024838591487564275, 'num_epoch': 200}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0066889040077094146}\n",
            "Epoch 100/2000, Train Loss: 0.695070, Val Loss: 0.694856, Val Acc: 0.677966\n",
            "Epoch 200/2000, Train Loss: 0.692916, Val Loss: 0.693038, Val Acc: 0.686441\n",
            "Epoch 300/2000, Train Loss: 0.690382, Val Loss: 0.689833, Val Acc: 0.703390\n",
            "Epoch 400/2000, Train Loss: 0.682989, Val Loss: 0.683859, Val Acc: 0.711864\n",
            "Epoch 500/2000, Train Loss: 0.669013, Val Loss: 0.671007, Val Acc: 0.720339\n",
            "Epoch 600/2000, Train Loss: 0.639166, Val Loss: 0.641245, Val Acc: 0.745763\n",
            "Epoch 700/2000, Train Loss: 0.574396, Val Loss: 0.594382, Val Acc: 0.694915\n",
            "Epoch 800/2000, Train Loss: 0.532618, Val Loss: 0.556843, Val Acc: 0.694915\n",
            "Epoch 900/2000, Train Loss: 0.488158, Val Loss: 0.539022, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.462182, Val Loss: 0.535469, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.457439, Val Loss: 0.537027, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.433209, Val Loss: 0.535560, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.433847, Val Loss: 0.540081, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.415762, Val Loss: 0.539117, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.428907, Val Loss: 0.547405, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.408286, Val Loss: 0.551041, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.400887, Val Loss: 0.552933, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.400696, Val Loss: 0.555456, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.392023, Val Loss: 0.561393, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.383985, Val Loss: 0.565833, Val Acc: 0.737288\n",
            "Test Loss: 0.5593840479850769 Test Accuracy: 0.7837837837837838\n",
            "weighted: Test F1: 0.5593840479850769 Test Precision: 0.7837837837837838 Test Recall: 0.7837837837837838\n",
            "[[61 10]\n",
            " [22 55]]\n",
            "[Trial 109] Test acc: 0.7837837837837838, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:41:46,523] Trial 109 finished with value: 0.7837837837837838 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0066889040077094146, 'learning_rate': 0.005288204072694681, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006697633816583637}\n",
            "Epoch 100/2000, Train Loss: 0.696458, Val Loss: 0.696314, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.696193, Val Loss: 0.696206, Val Acc: 0.610169\n",
            "Epoch 300/2000, Train Loss: 0.696220, Val Loss: 0.696151, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.696028, Val Loss: 0.695984, Val Acc: 0.593220\n",
            "Epoch 500/2000, Train Loss: 0.695965, Val Loss: 0.695885, Val Acc: 0.584746\n",
            "Epoch 600/2000, Train Loss: 0.695690, Val Loss: 0.695709, Val Acc: 0.584746\n",
            "Epoch 700/2000, Train Loss: 0.695768, Val Loss: 0.695502, Val Acc: 0.593220\n",
            "Epoch 800/2000, Train Loss: 0.695575, Val Loss: 0.695252, Val Acc: 0.601695\n",
            "Epoch 900/2000, Train Loss: 0.695207, Val Loss: 0.694964, Val Acc: 0.610169\n",
            "Epoch 1000/2000, Train Loss: 0.694775, Val Loss: 0.694652, Val Acc: 0.618644\n",
            "Epoch 1100/2000, Train Loss: 0.694650, Val Loss: 0.694192, Val Acc: 0.644068\n",
            "Epoch 1200/2000, Train Loss: 0.693247, Val Loss: 0.693605, Val Acc: 0.652542\n",
            "Epoch 1300/2000, Train Loss: 0.693544, Val Loss: 0.692760, Val Acc: 0.644068\n",
            "Epoch 1400/2000, Train Loss: 0.690986, Val Loss: 0.691653, Val Acc: 0.635593\n",
            "Epoch 1500/2000, Train Loss: 0.691005, Val Loss: 0.690106, Val Acc: 0.627119\n",
            "Epoch 1600/2000, Train Loss: 0.687834, Val Loss: 0.687880, Val Acc: 0.644068\n",
            "Epoch 1700/2000, Train Loss: 0.683394, Val Loss: 0.684129, Val Acc: 0.644068\n",
            "Epoch 1800/2000, Train Loss: 0.675256, Val Loss: 0.678026, Val Acc: 0.669492\n",
            "Epoch 1900/2000, Train Loss: 0.669365, Val Loss: 0.667639, Val Acc: 0.686441\n",
            "Epoch 2000/2000, Train Loss: 0.651900, Val Loss: 0.649056, Val Acc: 0.711864\n",
            "Test Loss: 0.655704915523529 Test Accuracy: 0.6283783783783784\n",
            "weighted: Test F1: 0.655704915523529 Test Precision: 0.6283783783783784 Test Recall: 0.6283783783783784\n",
            "[[48 23]\n",
            " [32 45]]\n",
            "[Trial 110] Test acc: 0.6283783783783784, Best val acc: 0.711864406779661\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:43:12,301] Trial 110 finished with value: 0.6283783783783784 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006697633816583637, 'learning_rate': 0.0030807013144964943, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006960381294332367}\n",
            "Epoch 100/2000, Train Loss: 0.694815, Val Loss: 0.694050, Val Acc: 0.644068\n",
            "Epoch 200/2000, Train Loss: 0.690955, Val Loss: 0.691008, Val Acc: 0.686441\n",
            "Epoch 300/2000, Train Loss: 0.683186, Val Loss: 0.685186, Val Acc: 0.694915\n",
            "Epoch 400/2000, Train Loss: 0.673829, Val Loss: 0.674182, Val Acc: 0.686441\n",
            "Epoch 500/2000, Train Loss: 0.649260, Val Loss: 0.653058, Val Acc: 0.694915\n",
            "Epoch 600/2000, Train Loss: 0.610602, Val Loss: 0.615066, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.561945, Val Loss: 0.573957, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.500440, Val Loss: 0.549563, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.460970, Val Loss: 0.541695, Val Acc: 0.703390\n",
            "Epoch 1000/2000, Train Loss: 0.436986, Val Loss: 0.543558, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.436688, Val Loss: 0.546370, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.435921, Val Loss: 0.544282, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.434120, Val Loss: 0.549241, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.414748, Val Loss: 0.548965, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.430102, Val Loss: 0.550870, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.401855, Val Loss: 0.553616, Val Acc: 0.711864\n",
            "Epoch 1700/2000, Train Loss: 0.399833, Val Loss: 0.558021, Val Acc: 0.694915\n",
            "Epoch 1800/2000, Train Loss: 0.393752, Val Loss: 0.565287, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.375887, Val Loss: 0.562035, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.376846, Val Loss: 0.567706, Val Acc: 0.745763\n",
            "Test Loss: 0.5396242737770081 Test Accuracy: 0.7837837837837838\n",
            "weighted: Test F1: 0.5396242737770081 Test Precision: 0.7837837837837838 Test Recall: 0.7837837837837838\n",
            "[[61 10]\n",
            " [22 55]]\n",
            "[Trial 111] Test acc: 0.7837837837837838, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:44:32,966] Trial 111 finished with value: 0.7837837837837838 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006960381294332367, 'learning_rate': 0.005185159436638664, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007514912192139539}\n",
            "Epoch 100/2000, Train Loss: 0.696086, Val Loss: 0.696639, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.694224, Val Loss: 0.695808, Val Acc: 0.567797\n",
            "Epoch 300/2000, Train Loss: 0.691297, Val Loss: 0.694339, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.686537, Val Loss: 0.691418, Val Acc: 0.627119\n",
            "Epoch 500/2000, Train Loss: 0.676979, Val Loss: 0.685059, Val Acc: 0.652542\n",
            "Epoch 600/2000, Train Loss: 0.664399, Val Loss: 0.669905, Val Acc: 0.677966\n",
            "Epoch 700/2000, Train Loss: 0.617886, Val Loss: 0.637074, Val Acc: 0.686441\n",
            "Epoch 800/2000, Train Loss: 0.572799, Val Loss: 0.589166, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.501225, Val Loss: 0.557956, Val Acc: 0.711864\n",
            "Epoch 1000/2000, Train Loss: 0.475991, Val Loss: 0.542931, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.457115, Val Loss: 0.543120, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.432782, Val Loss: 0.544912, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.444015, Val Loss: 0.545771, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.427299, Val Loss: 0.545180, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.410582, Val Loss: 0.548579, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.414412, Val Loss: 0.548633, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.399385, Val Loss: 0.554495, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.393627, Val Loss: 0.562096, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.395343, Val Loss: 0.561151, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.373406, Val Loss: 0.572425, Val Acc: 0.728814\n",
            "Test Loss: 0.5432631969451904 Test Accuracy: 0.7432432432432432\n",
            "weighted: Test F1: 0.5432631969451904 Test Precision: 0.7432432432432432 Test Recall: 0.7432432432432432\n",
            "[[57 14]\n",
            " [24 53]]\n",
            "[Trial 112] Test acc: 0.7432432432432432, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:45:53,694] Trial 112 finished with value: 0.7432432432432432 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007514912192139539, 'learning_rate': 0.0051020334214397145, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006996089171548239}\n",
            "Epoch 100/2000, Train Loss: 0.695252, Val Loss: 0.696500, Val Acc: 0.474576\n",
            "Epoch 200/2000, Train Loss: 0.693370, Val Loss: 0.695312, Val Acc: 0.500000\n",
            "Epoch 300/2000, Train Loss: 0.687630, Val Loss: 0.692430, Val Acc: 0.533898\n",
            "Epoch 400/2000, Train Loss: 0.673422, Val Loss: 0.684892, Val Acc: 0.567797\n",
            "Epoch 500/2000, Train Loss: 0.650922, Val Loss: 0.665926, Val Acc: 0.635593\n",
            "Epoch 600/2000, Train Loss: 0.590757, Val Loss: 0.618560, Val Acc: 0.694915\n",
            "Epoch 700/2000, Train Loss: 0.527709, Val Loss: 0.564347, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.473883, Val Loss: 0.544838, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.439182, Val Loss: 0.542643, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.431856, Val Loss: 0.547950, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.409290, Val Loss: 0.554422, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.405632, Val Loss: 0.552744, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.392682, Val Loss: 0.563784, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.393103, Val Loss: 0.566167, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.373917, Val Loss: 0.571033, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.385844, Val Loss: 0.573319, Val Acc: 0.754237\n",
            "Epoch 1700/2000, Train Loss: 0.340900, Val Loss: 0.586984, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.320990, Val Loss: 0.599633, Val Acc: 0.754237\n",
            "Epoch 1900/2000, Train Loss: 0.328223, Val Loss: 0.611158, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.299563, Val Loss: 0.630682, Val Acc: 0.754237\n",
            "Test Loss: 0.5999390482902527 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.5999390482902527 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[54 17]\n",
            " [22 55]]\n",
            "[Trial 113] Test acc: 0.7364864864864865, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:47:14,569] Trial 113 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006996089171548239, 'learning_rate': 0.006544824274015426, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006921903421261589}\n",
            "Epoch 100/2000, Train Loss: 0.694760, Val Loss: 0.694770, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.691079, Val Loss: 0.691804, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.687858, Val Loss: 0.688082, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.678416, Val Loss: 0.681498, Val Acc: 0.661017\n",
            "Epoch 500/2000, Train Loss: 0.663744, Val Loss: 0.669306, Val Acc: 0.661017\n",
            "Epoch 600/2000, Train Loss: 0.632787, Val Loss: 0.646547, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.603080, Val Loss: 0.610816, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.556793, Val Loss: 0.576286, Val Acc: 0.728814\n",
            "Epoch 900/2000, Train Loss: 0.491486, Val Loss: 0.552317, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.486769, Val Loss: 0.544682, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.451275, Val Loss: 0.545949, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.438396, Val Loss: 0.546687, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.434631, Val Loss: 0.549480, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.435362, Val Loss: 0.551071, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.439236, Val Loss: 0.555899, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.423433, Val Loss: 0.558994, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.422041, Val Loss: 0.564358, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.401560, Val Loss: 0.563826, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.394673, Val Loss: 0.566298, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.388427, Val Loss: 0.575798, Val Acc: 0.737288\n",
            "Test Loss: 0.5439351201057434 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5439351201057434 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[58 13]\n",
            " [24 53]]\n",
            "[Trial 114] Test acc: 0.75, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:48:35,456] Trial 114 finished with value: 0.75 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006921903421261589, 'learning_rate': 0.004391166957256538, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006779405168917952}\n",
            "Epoch 100/2000, Train Loss: 0.693533, Val Loss: 0.693915, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.689219, Val Loss: 0.691249, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.684328, Val Loss: 0.686313, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.671179, Val Loss: 0.676892, Val Acc: 0.635593\n",
            "Epoch 500/2000, Train Loss: 0.649756, Val Loss: 0.659471, Val Acc: 0.686441\n",
            "Epoch 600/2000, Train Loss: 0.616261, Val Loss: 0.627121, Val Acc: 0.737288\n",
            "Epoch 700/2000, Train Loss: 0.550594, Val Loss: 0.582957, Val Acc: 0.745763\n",
            "Epoch 800/2000, Train Loss: 0.499384, Val Loss: 0.555982, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.466596, Val Loss: 0.541641, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.441425, Val Loss: 0.543774, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.432550, Val Loss: 0.549865, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.408681, Val Loss: 0.552933, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.430870, Val Loss: 0.554048, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.402069, Val Loss: 0.562184, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.377793, Val Loss: 0.570369, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.382593, Val Loss: 0.579607, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.367245, Val Loss: 0.582566, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.361414, Val Loss: 0.608853, Val Acc: 0.703390\n",
            "Epoch 1900/2000, Train Loss: 0.339935, Val Loss: 0.610446, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.351477, Val Loss: 0.606508, Val Acc: 0.728814\n",
            "Test Loss: 0.5715507864952087 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5715507864952087 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[58 13]\n",
            " [22 55]]\n",
            "[Trial 115] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:49:56,337] Trial 115 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006779405168917952, 'learning_rate': 0.005104563386348908, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006622548598066294}\n",
            "Epoch 100/500, Train Loss: 0.694813, Val Loss: 0.695364, Val Acc: 0.567797\n",
            "Epoch 200/500, Train Loss: 0.691782, Val Loss: 0.692463, Val Acc: 0.610169\n",
            "Epoch 300/500, Train Loss: 0.684765, Val Loss: 0.685427, Val Acc: 0.618644\n",
            "Epoch 400/500, Train Loss: 0.660032, Val Loss: 0.665500, Val Acc: 0.661017\n",
            "Epoch 500/500, Train Loss: 0.592347, Val Loss: 0.614085, Val Acc: 0.694915\n",
            "Test Loss: 0.6048485636711121 Test Accuracy: 0.7162162162162162\n",
            "weighted: Test F1: 0.6048485636711121 Test Precision: 0.7162162162162162 Test Recall: 0.7162162162162162\n",
            "[[51 20]\n",
            " [22 55]]\n",
            "[Trial 116] Test acc: 0.7162162162162162, Best val acc: 0.6949152542372882\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:50:16,674] Trial 116 finished with value: 0.7162162162162162 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006622548598066294, 'learning_rate': 0.00760463070411359, 'num_epoch': 500}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007087404223898329}\n",
            "Epoch 100/2000, Train Loss: 0.694125, Val Loss: 0.695094, Val Acc: 0.567797\n",
            "Epoch 200/2000, Train Loss: 0.690110, Val Loss: 0.691579, Val Acc: 0.627119\n",
            "Epoch 300/2000, Train Loss: 0.677278, Val Loss: 0.681108, Val Acc: 0.618644\n",
            "Epoch 400/2000, Train Loss: 0.639126, Val Loss: 0.645956, Val Acc: 0.694915\n",
            "Epoch 500/2000, Train Loss: 0.564555, Val Loss: 0.580254, Val Acc: 0.737288\n",
            "Epoch 600/2000, Train Loss: 0.494667, Val Loss: 0.537438, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.460787, Val Loss: 0.540150, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.436156, Val Loss: 0.548803, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.432811, Val Loss: 0.555696, Val Acc: 0.694915\n",
            "Epoch 1000/2000, Train Loss: 0.421556, Val Loss: 0.553445, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.422765, Val Loss: 0.553560, Val Acc: 0.745763\n",
            "Epoch 1200/2000, Train Loss: 0.408883, Val Loss: 0.557103, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.378581, Val Loss: 0.558942, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.392751, Val Loss: 0.573955, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.369628, Val Loss: 0.571732, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.368217, Val Loss: 0.587851, Val Acc: 0.694915\n",
            "Epoch 1700/2000, Train Loss: 0.331381, Val Loss: 0.589301, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.348003, Val Loss: 0.639684, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.309465, Val Loss: 0.620165, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.301610, Val Loss: 0.637188, Val Acc: 0.728814\n",
            "Test Loss: 0.6312369704246521 Test Accuracy: 0.7297297297297297\n",
            "weighted: Test F1: 0.6312369704246521 Test Precision: 0.7297297297297297 Test Recall: 0.7297297297297297\n",
            "[[50 21]\n",
            " [19 58]]\n",
            "[Trial 117] Test acc: 0.7297297297297297, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:51:37,962] Trial 117 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007087404223898329, 'learning_rate': 0.008816429271347893, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006171952763816719}\n",
            "Epoch 100/2000, Train Loss: 0.696256, Val Loss: 0.696248, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.696259, Val Loss: 0.696232, Val Acc: 0.457627\n",
            "Epoch 300/2000, Train Loss: 0.696236, Val Loss: 0.696213, Val Acc: 0.500000\n",
            "Epoch 400/2000, Train Loss: 0.696228, Val Loss: 0.696202, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.696280, Val Loss: 0.696180, Val Acc: 0.525424\n",
            "Epoch 600/2000, Train Loss: 0.696224, Val Loss: 0.696208, Val Acc: 0.516949\n",
            "Epoch 700/2000, Train Loss: 0.696224, Val Loss: 0.696252, Val Acc: 0.483051\n",
            "Epoch 800/2000, Train Loss: 0.696221, Val Loss: 0.696226, Val Acc: 0.491525\n",
            "Epoch 900/2000, Train Loss: 0.696227, Val Loss: 0.696211, Val Acc: 0.516949\n",
            "Epoch 1000/2000, Train Loss: 0.696234, Val Loss: 0.696198, Val Acc: 0.525424\n",
            "Epoch 1100/2000, Train Loss: 0.696230, Val Loss: 0.696202, Val Acc: 0.516949\n",
            "Epoch 1200/2000, Train Loss: 0.696235, Val Loss: 0.696171, Val Acc: 0.525424\n",
            "Epoch 1300/2000, Train Loss: 0.696253, Val Loss: 0.696190, Val Acc: 0.542373\n",
            "Epoch 1400/2000, Train Loss: 0.696246, Val Loss: 0.696189, Val Acc: 0.525424\n",
            "Epoch 1500/2000, Train Loss: 0.696248, Val Loss: 0.696207, Val Acc: 0.457627\n",
            "Epoch 1600/2000, Train Loss: 0.696192, Val Loss: 0.696210, Val Acc: 0.457627\n",
            "Epoch 1700/2000, Train Loss: 0.696211, Val Loss: 0.696211, Val Acc: 0.474576\n",
            "Epoch 1800/2000, Train Loss: 0.696195, Val Loss: 0.696171, Val Acc: 0.559322\n",
            "Epoch 1900/2000, Train Loss: 0.696233, Val Loss: 0.696194, Val Acc: 0.457627\n",
            "Epoch 2000/2000, Train Loss: 0.696178, Val Loss: 0.696181, Val Acc: 0.508475\n",
            "Test Loss: 0.6961676478385925 Test Accuracy: 0.47297297297297297\n",
            "weighted: Test F1: 0.6961676478385925 Test Precision: 0.47297297297297297 Test Recall: 0.47297297297297297\n",
            "[[58 13]\n",
            " [65 12]]\n",
            "[Trial 118] Test acc: 0.47297297297297297, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:53:04,327] Trial 118 finished with value: 0.47297297297297297 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006171952763816719, 'learning_rate': 0.0038268933708957326, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007252642042016768}\n",
            "Epoch 100/2000, Train Loss: 0.692799, Val Loss: 0.692162, Val Acc: 0.618644\n",
            "Epoch 200/2000, Train Loss: 0.688140, Val Loss: 0.686236, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.672814, Val Loss: 0.674976, Val Acc: 0.677966\n",
            "Epoch 400/2000, Train Loss: 0.647574, Val Loss: 0.651153, Val Acc: 0.703390\n",
            "Epoch 500/2000, Train Loss: 0.583559, Val Loss: 0.602053, Val Acc: 0.728814\n",
            "Epoch 600/2000, Train Loss: 0.529164, Val Loss: 0.554689, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.474062, Val Loss: 0.536169, Val Acc: 0.737288\n",
            "Epoch 800/2000, Train Loss: 0.455075, Val Loss: 0.540333, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.449982, Val Loss: 0.544053, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.433323, Val Loss: 0.543432, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.420844, Val Loss: 0.545810, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.420465, Val Loss: 0.554046, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.397175, Val Loss: 0.558623, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.401849, Val Loss: 0.563733, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.386975, Val Loss: 0.563815, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.402309, Val Loss: 0.576326, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.358698, Val Loss: 0.585330, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.359050, Val Loss: 0.624398, Val Acc: 0.703390\n",
            "Epoch 1900/2000, Train Loss: 0.345511, Val Loss: 0.603225, Val Acc: 0.694915\n",
            "Epoch 2000/2000, Train Loss: 0.344698, Val Loss: 0.621148, Val Acc: 0.711864\n",
            "Test Loss: 0.5523770451545715 Test Accuracy: 0.7432432432432432\n",
            "weighted: Test F1: 0.5523770451545715 Test Precision: 0.7432432432432432 Test Recall: 0.7432432432432432\n",
            "[[54 17]\n",
            " [21 56]]\n",
            "[Trial 119] Test acc: 0.7432432432432432, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:54:25,432] Trial 119 finished with value: 0.7432432432432432 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007252642042016768, 'learning_rate': 0.005811487757172895, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'relu', 'lam': 0.0068321476361711654}\n",
            "Epoch 100/1500, Train Loss: 0.695506, Val Loss: 0.694416, Val Acc: 0.593220\n",
            "Epoch 200/1500, Train Loss: 0.691120, Val Loss: 0.691072, Val Acc: 0.618644\n",
            "Epoch 300/1500, Train Loss: 0.681742, Val Loss: 0.684097, Val Acc: 0.694915\n",
            "Epoch 400/1500, Train Loss: 0.664215, Val Loss: 0.666411, Val Acc: 0.694915\n",
            "Epoch 500/1500, Train Loss: 0.628500, Val Loss: 0.626482, Val Acc: 0.728814\n",
            "Epoch 600/1500, Train Loss: 0.551655, Val Loss: 0.569307, Val Acc: 0.745763\n",
            "Epoch 700/1500, Train Loss: 0.482213, Val Loss: 0.540246, Val Acc: 0.720339\n",
            "Epoch 800/1500, Train Loss: 0.460640, Val Loss: 0.539087, Val Acc: 0.720339\n",
            "Epoch 900/1500, Train Loss: 0.443124, Val Loss: 0.548686, Val Acc: 0.728814\n",
            "Epoch 1000/1500, Train Loss: 0.438302, Val Loss: 0.550488, Val Acc: 0.728814\n",
            "Epoch 1100/1500, Train Loss: 0.422357, Val Loss: 0.559438, Val Acc: 0.728814\n",
            "Epoch 1200/1500, Train Loss: 0.417593, Val Loss: 0.563610, Val Acc: 0.737288\n",
            "Epoch 1300/1500, Train Loss: 0.393433, Val Loss: 0.568013, Val Acc: 0.728814\n",
            "Epoch 1400/1500, Train Loss: 0.380399, Val Loss: 0.573130, Val Acc: 0.737288\n",
            "Epoch 1500/1500, Train Loss: 0.388395, Val Loss: 0.582056, Val Acc: 0.737288\n",
            "Test Loss: 0.5365830659866333 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5365830659866333 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[61 10]\n",
            " [24 53]]\n",
            "[Trial 120] Test acc: 0.7702702702702703, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:55:25,939] Trial 120 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'relu', 'lam': 0.0068321476361711654, 'learning_rate': 0.0066677972630105505, 'num_epoch': 1500}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006488548052746084}\n",
            "Epoch 100/2000, Train Loss: 0.694200, Val Loss: 0.696420, Val Acc: 0.474576\n",
            "Epoch 200/2000, Train Loss: 0.690311, Val Loss: 0.693108, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.686301, Val Loss: 0.687326, Val Acc: 0.635593\n",
            "Epoch 400/2000, Train Loss: 0.676860, Val Loss: 0.675296, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.649108, Val Loss: 0.648897, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.590642, Val Loss: 0.598713, Val Acc: 0.745763\n",
            "Epoch 700/2000, Train Loss: 0.518038, Val Loss: 0.556130, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.479173, Val Loss: 0.539820, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.448164, Val Loss: 0.532584, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.444287, Val Loss: 0.531845, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.408705, Val Loss: 0.534749, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.401190, Val Loss: 0.542194, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.399401, Val Loss: 0.543880, Val Acc: 0.703390\n",
            "Epoch 1400/2000, Train Loss: 0.385377, Val Loss: 0.547785, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.376622, Val Loss: 0.550694, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.358222, Val Loss: 0.560404, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.340393, Val Loss: 0.574461, Val Acc: 0.677966\n",
            "Epoch 1800/2000, Train Loss: 0.327944, Val Loss: 0.576232, Val Acc: 0.694915\n",
            "Epoch 1900/2000, Train Loss: 0.322849, Val Loss: 0.597532, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.296095, Val Loss: 0.623235, Val Acc: 0.677966\n",
            "Test Loss: 0.5806823372840881 Test Accuracy: 0.7297297297297297\n",
            "weighted: Test F1: 0.5806823372840881 Test Precision: 0.7297297297297297 Test Recall: 0.7297297297297297\n",
            "[[50 21]\n",
            " [19 58]]\n",
            "[Trial 121] Test acc: 0.7297297297297297, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:56:46,737] Trial 121 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006488548052746084, 'learning_rate': 0.005810390717663159, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006439912694527043}\n",
            "Epoch 100/2000, Train Loss: 0.694562, Val Loss: 0.696188, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.689526, Val Loss: 0.693786, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.683820, Val Loss: 0.689136, Val Acc: 0.644068\n",
            "Epoch 400/2000, Train Loss: 0.676556, Val Loss: 0.679233, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.650974, Val Loss: 0.658149, Val Acc: 0.661017\n",
            "Epoch 600/2000, Train Loss: 0.601565, Val Loss: 0.620478, Val Acc: 0.711864\n",
            "Epoch 700/2000, Train Loss: 0.546662, Val Loss: 0.579267, Val Acc: 0.737288\n",
            "Epoch 800/2000, Train Loss: 0.503890, Val Loss: 0.552642, Val Acc: 0.694915\n",
            "Epoch 900/2000, Train Loss: 0.463331, Val Loss: 0.545557, Val Acc: 0.711864\n",
            "Epoch 1000/2000, Train Loss: 0.448626, Val Loss: 0.541672, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.428327, Val Loss: 0.542842, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.439744, Val Loss: 0.540653, Val Acc: 0.745763\n",
            "Epoch 1300/2000, Train Loss: 0.430041, Val Loss: 0.546061, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.421536, Val Loss: 0.553238, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.410115, Val Loss: 0.566905, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.412974, Val Loss: 0.570760, Val Acc: 0.754237\n",
            "Epoch 1700/2000, Train Loss: 0.389582, Val Loss: 0.571344, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.383173, Val Loss: 0.568043, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.367603, Val Loss: 0.580598, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.370513, Val Loss: 0.584568, Val Acc: 0.694915\n",
            "Test Loss: 0.5381393432617188 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5381393432617188 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[55 16]\n",
            " [21 56]]\n",
            "[Trial 122] Test acc: 0.75, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:58:06,887] Trial 122 finished with value: 0.75 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.006439912694527043, 'learning_rate': 0.00482257549211467, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.00671730665896722}\n",
            "Epoch 100/2000, Train Loss: 0.695004, Val Loss: 0.695521, Val Acc: 0.533898\n",
            "Epoch 200/2000, Train Loss: 0.695667, Val Loss: 0.694566, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.693074, Val Loss: 0.693376, Val Acc: 0.542373\n",
            "Epoch 400/2000, Train Loss: 0.692338, Val Loss: 0.691559, Val Acc: 0.593220\n",
            "Epoch 500/2000, Train Loss: 0.687126, Val Loss: 0.688794, Val Acc: 0.627119\n",
            "Epoch 600/2000, Train Loss: 0.680637, Val Loss: 0.684574, Val Acc: 0.635593\n",
            "Epoch 700/2000, Train Loss: 0.680249, Val Loss: 0.678335, Val Acc: 0.635593\n",
            "Epoch 800/2000, Train Loss: 0.659175, Val Loss: 0.667871, Val Acc: 0.652542\n",
            "Epoch 900/2000, Train Loss: 0.646259, Val Loss: 0.652137, Val Acc: 0.686441\n",
            "Epoch 1000/2000, Train Loss: 0.623242, Val Loss: 0.628233, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.598595, Val Loss: 0.595052, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.545353, Val Loss: 0.569330, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.517244, Val Loss: 0.552579, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.483717, Val Loss: 0.542946, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.451029, Val Loss: 0.540404, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.469044, Val Loss: 0.540966, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.469183, Val Loss: 0.541905, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.439019, Val Loss: 0.544226, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.432767, Val Loss: 0.544890, Val Acc: 0.720339\n",
            "Epoch 2000/2000, Train Loss: 0.420592, Val Loss: 0.547423, Val Acc: 0.711864\n",
            "Test Loss: 0.5287984013557434 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.5287984013557434 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[62  9]\n",
            " [27 50]]\n",
            "[Trial 123] Test acc: 0.7567567567567568, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 18:59:27,372] Trial 123 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.00671730665896722, 'learning_rate': 0.0033863571458798967, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006595914044135224}\n",
            "Epoch 100/2000, Train Loss: 0.696652, Val Loss: 0.696553, Val Acc: 0.491525\n",
            "Epoch 200/2000, Train Loss: 0.694462, Val Loss: 0.694863, Val Acc: 0.593220\n",
            "Epoch 300/2000, Train Loss: 0.691641, Val Loss: 0.693320, Val Acc: 0.542373\n",
            "Epoch 400/2000, Train Loss: 0.689293, Val Loss: 0.690283, Val Acc: 0.610169\n",
            "Epoch 500/2000, Train Loss: 0.681984, Val Loss: 0.684431, Val Acc: 0.644068\n",
            "Epoch 600/2000, Train Loss: 0.666928, Val Loss: 0.672460, Val Acc: 0.669492\n",
            "Epoch 700/2000, Train Loss: 0.645491, Val Loss: 0.649176, Val Acc: 0.694915\n",
            "Epoch 800/2000, Train Loss: 0.602130, Val Loss: 0.609822, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.541352, Val Loss: 0.573514, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.497765, Val Loss: 0.552878, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.464067, Val Loss: 0.546114, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.444172, Val Loss: 0.544622, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.448122, Val Loss: 0.546107, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.427107, Val Loss: 0.551219, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.425118, Val Loss: 0.553065, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.404395, Val Loss: 0.558034, Val Acc: 0.737288\n",
            "Epoch 1700/2000, Train Loss: 0.405627, Val Loss: 0.559262, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.376497, Val Loss: 0.561213, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.402910, Val Loss: 0.572197, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.368707, Val Loss: 0.569057, Val Acc: 0.728814\n",
            "Test Loss: 0.527717113494873 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.527717113494873 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[59 12]\n",
            " [22 55]]\n",
            "[Trial 124] Test acc: 0.7702702702702703, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:00:48,346] Trial 124 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006595914044135224, 'learning_rate': 0.004394265023259821, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.00695644964089217}\n",
            "Epoch 100/2000, Train Loss: 0.695025, Val Loss: 0.695046, Val Acc: 0.601695\n",
            "Epoch 200/2000, Train Loss: 0.691293, Val Loss: 0.692155, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.685198, Val Loss: 0.686010, Val Acc: 0.703390\n",
            "Epoch 400/2000, Train Loss: 0.664702, Val Loss: 0.670101, Val Acc: 0.711864\n",
            "Epoch 500/2000, Train Loss: 0.634150, Val Loss: 0.634766, Val Acc: 0.728814\n",
            "Epoch 600/2000, Train Loss: 0.565006, Val Loss: 0.584672, Val Acc: 0.720339\n",
            "Epoch 700/2000, Train Loss: 0.491020, Val Loss: 0.553164, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.449850, Val Loss: 0.549765, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.440738, Val Loss: 0.549349, Val Acc: 0.703390\n",
            "Epoch 1000/2000, Train Loss: 0.432162, Val Loss: 0.555371, Val Acc: 0.728814\n",
            "Epoch 1100/2000, Train Loss: 0.434591, Val Loss: 0.553163, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.424307, Val Loss: 0.552000, Val Acc: 0.737288\n",
            "Epoch 1300/2000, Train Loss: 0.398930, Val Loss: 0.549893, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.416213, Val Loss: 0.556965, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.388900, Val Loss: 0.554544, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.382231, Val Loss: 0.561324, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.382503, Val Loss: 0.564600, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.377319, Val Loss: 0.569146, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.355518, Val Loss: 0.577645, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.330399, Val Loss: 0.577943, Val Acc: 0.737288\n",
            "Test Loss: 0.56791752576828 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.56791752576828 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[57 14]\n",
            " [25 52]]\n",
            "[Trial 125] Test acc: 0.7364864864864865, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:02:08,378] Trial 125 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.00695644964089217, 'learning_rate': 0.006307144090315463, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006656026600935354}\n",
            "Epoch 100/2000, Train Loss: 0.694583, Val Loss: 0.694575, Val Acc: 0.550847\n",
            "Epoch 200/2000, Train Loss: 0.691702, Val Loss: 0.692774, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.685421, Val Loss: 0.688669, Val Acc: 0.601695\n",
            "Epoch 400/2000, Train Loss: 0.673476, Val Loss: 0.680372, Val Acc: 0.677966\n",
            "Epoch 500/2000, Train Loss: 0.659165, Val Loss: 0.663967, Val Acc: 0.694915\n",
            "Epoch 600/2000, Train Loss: 0.621782, Val Loss: 0.632390, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.574823, Val Loss: 0.584985, Val Acc: 0.754237\n",
            "Epoch 800/2000, Train Loss: 0.503582, Val Loss: 0.552422, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.483233, Val Loss: 0.538735, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.458175, Val Loss: 0.541284, Val Acc: 0.711864\n",
            "Epoch 1100/2000, Train Loss: 0.450430, Val Loss: 0.538154, Val Acc: 0.728814\n",
            "Epoch 1200/2000, Train Loss: 0.411566, Val Loss: 0.536885, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.426386, Val Loss: 0.540514, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.416247, Val Loss: 0.542517, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.406409, Val Loss: 0.545604, Val Acc: 0.720339\n",
            "Epoch 1600/2000, Train Loss: 0.397240, Val Loss: 0.554354, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.381902, Val Loss: 0.557112, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.378131, Val Loss: 0.561024, Val Acc: 0.694915\n",
            "Epoch 1900/2000, Train Loss: 0.367333, Val Loss: 0.558549, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.355069, Val Loss: 0.571931, Val Acc: 0.703390\n",
            "Test Loss: 0.5633022785186768 Test Accuracy: 0.7094594594594594\n",
            "weighted: Test F1: 0.5633022785186768 Test Precision: 0.7094594594594594 Test Recall: 0.7094594594594594\n",
            "[[50 21]\n",
            " [22 55]]\n",
            "[Trial 126] Test acc: 0.7094594594594594, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:03:29,192] Trial 126 finished with value: 0.7094594594594594 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006656026600935354, 'learning_rate': 0.00514468364649361, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.006849381359078332}\n",
            "Epoch 100/2000, Train Loss: 0.693834, Val Loss: 0.694300, Val Acc: 0.593220\n",
            "Epoch 200/2000, Train Loss: 0.691073, Val Loss: 0.691136, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.679681, Val Loss: 0.682680, Val Acc: 0.644068\n",
            "Epoch 400/2000, Train Loss: 0.656452, Val Loss: 0.661263, Val Acc: 0.686441\n",
            "Epoch 500/2000, Train Loss: 0.608725, Val Loss: 0.612377, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.511281, Val Loss: 0.558578, Val Acc: 0.703390\n",
            "Epoch 700/2000, Train Loss: 0.455638, Val Loss: 0.539131, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.446424, Val Loss: 0.542586, Val Acc: 0.737288\n",
            "Epoch 900/2000, Train Loss: 0.439558, Val Loss: 0.545135, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.410278, Val Loss: 0.550139, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.415786, Val Loss: 0.554672, Val Acc: 0.703390\n",
            "Epoch 1200/2000, Train Loss: 0.399180, Val Loss: 0.560908, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.377800, Val Loss: 0.562217, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.353769, Val Loss: 0.572212, Val Acc: 0.703390\n",
            "Epoch 1500/2000, Train Loss: 0.357470, Val Loss: 0.567070, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.332961, Val Loss: 0.575177, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.317174, Val Loss: 0.597620, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.308669, Val Loss: 0.596453, Val Acc: 0.711864\n",
            "Epoch 1900/2000, Train Loss: 0.286860, Val Loss: 0.621326, Val Acc: 0.694915\n",
            "Epoch 2000/2000, Train Loss: 0.265194, Val Loss: 0.637415, Val Acc: 0.728814\n",
            "Test Loss: 0.6140223741531372 Test Accuracy: 0.7567567567567568\n",
            "weighted: Test F1: 0.6140223741531372 Test Precision: 0.7567567567567568 Test Recall: 0.7567567567567568\n",
            "[[57 14]\n",
            " [22 55]]\n",
            "[Trial 127] Test acc: 0.7567567567567568, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:04:49,832] Trial 127 finished with value: 0.7567567567567568 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.006849381359078332, 'learning_rate': 0.007434768076456093, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.005440343960293166}\n",
            "Epoch 100/2000, Train Loss: 0.696001, Val Loss: 0.695786, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.695985, Val Loss: 0.695899, Val Acc: 0.500000\n",
            "Epoch 300/2000, Train Loss: 0.695980, Val Loss: 0.695781, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.695959, Val Loss: 0.695663, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.695838, Val Loss: 0.695888, Val Acc: 0.525424\n",
            "Epoch 600/2000, Train Loss: 0.695769, Val Loss: 0.695886, Val Acc: 0.533898\n",
            "Epoch 700/2000, Train Loss: 0.695898, Val Loss: 0.695852, Val Acc: 0.516949\n",
            "Epoch 800/2000, Train Loss: 0.695965, Val Loss: 0.695949, Val Acc: 0.474576\n",
            "Epoch 900/2000, Train Loss: 0.695790, Val Loss: 0.695884, Val Acc: 0.525424\n",
            "Epoch 1000/2000, Train Loss: 0.695768, Val Loss: 0.695798, Val Acc: 0.508475\n",
            "Epoch 1100/2000, Train Loss: 0.695969, Val Loss: 0.695724, Val Acc: 0.508475\n",
            "Epoch 1200/2000, Train Loss: 0.695826, Val Loss: 0.695746, Val Acc: 0.474576\n",
            "Epoch 1300/2000, Train Loss: 0.695948, Val Loss: 0.695825, Val Acc: 0.542373\n",
            "Epoch 1400/2000, Train Loss: 0.695912, Val Loss: 0.695699, Val Acc: 0.508475\n",
            "Epoch 1500/2000, Train Loss: 0.695916, Val Loss: 0.695745, Val Acc: 0.525424\n",
            "Epoch 1600/2000, Train Loss: 0.695689, Val Loss: 0.695804, Val Acc: 0.550847\n",
            "Epoch 1700/2000, Train Loss: 0.695804, Val Loss: 0.695757, Val Acc: 0.525424\n",
            "Epoch 1800/2000, Train Loss: 0.695727, Val Loss: 0.695770, Val Acc: 0.550847\n",
            "Epoch 1900/2000, Train Loss: 0.695668, Val Loss: 0.695793, Val Acc: 0.559322\n",
            "Epoch 2000/2000, Train Loss: 0.695595, Val Loss: 0.695727, Val Acc: 0.542373\n",
            "Test Loss: 0.695518434047699 Test Accuracy: 0.6013513513513513\n",
            "weighted: Test F1: 0.695518434047699 Test Precision: 0.6013513513513513 Test Recall: 0.6013513513513513\n",
            "[[28 43]\n",
            " [16 61]]\n",
            "[Trial 128] Test acc: 0.6013513513513513, Best val acc: 0.559322033898305\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:06:09,718] Trial 128 finished with value: 0.6013513513513513 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.005440343960293166, 'learning_rate': 0.004032713171939977, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.006320499444735424}\n",
            "Epoch 100/2000, Train Loss: 0.695235, Val Loss: 0.695683, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.695184, Val Loss: 0.694889, Val Acc: 0.601695\n",
            "Epoch 300/2000, Train Loss: 0.693624, Val Loss: 0.693790, Val Acc: 0.627119\n",
            "Epoch 400/2000, Train Loss: 0.690883, Val Loss: 0.691826, Val Acc: 0.627119\n",
            "Epoch 500/2000, Train Loss: 0.687392, Val Loss: 0.688751, Val Acc: 0.652542\n",
            "Epoch 600/2000, Train Loss: 0.681793, Val Loss: 0.682684, Val Acc: 0.661017\n",
            "Epoch 700/2000, Train Loss: 0.664854, Val Loss: 0.671466, Val Acc: 0.686441\n",
            "Epoch 800/2000, Train Loss: 0.648035, Val Loss: 0.652701, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.631382, Val Loss: 0.621888, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.557195, Val Loss: 0.586367, Val Acc: 0.694915\n",
            "Epoch 1100/2000, Train Loss: 0.492114, Val Loss: 0.559954, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.462048, Val Loss: 0.543410, Val Acc: 0.745763\n",
            "Epoch 1300/2000, Train Loss: 0.448779, Val Loss: 0.544239, Val Acc: 0.737288\n",
            "Epoch 1400/2000, Train Loss: 0.455644, Val Loss: 0.546769, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.445248, Val Loss: 0.546950, Val Acc: 0.745763\n",
            "Epoch 1600/2000, Train Loss: 0.438927, Val Loss: 0.553575, Val Acc: 0.745763\n",
            "Epoch 1700/2000, Train Loss: 0.434299, Val Loss: 0.559391, Val Acc: 0.737288\n",
            "Epoch 1800/2000, Train Loss: 0.429935, Val Loss: 0.564368, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.429655, Val Loss: 0.562822, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.432283, Val Loss: 0.571688, Val Acc: 0.737288\n",
            "Test Loss: 0.5635764598846436 Test Accuracy: 0.7027027027027027\n",
            "weighted: Test F1: 0.5635764598846436 Test Precision: 0.7027027027027027 Test Recall: 0.7027027027027027\n",
            "[[59 12]\n",
            " [32 45]]\n",
            "[Trial 129] Test acc: 0.7027027027027027, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:07:30,566] Trial 129 finished with value: 0.7027027027027027 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.006320499444735424, 'learning_rate': 0.005371734450016302, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006517158581451462}\n",
            "Epoch 100/1000, Train Loss: 0.693325, Val Loss: 0.694091, Val Acc: 0.559322\n",
            "Epoch 200/1000, Train Loss: 0.688186, Val Loss: 0.690740, Val Acc: 0.576271\n",
            "Epoch 300/1000, Train Loss: 0.677966, Val Loss: 0.683569, Val Acc: 0.627119\n",
            "Epoch 400/1000, Train Loss: 0.663774, Val Loss: 0.668773, Val Acc: 0.669492\n",
            "Epoch 500/1000, Train Loss: 0.636572, Val Loss: 0.640019, Val Acc: 0.703390\n",
            "Epoch 600/1000, Train Loss: 0.567731, Val Loss: 0.592618, Val Acc: 0.728814\n",
            "Epoch 700/1000, Train Loss: 0.495271, Val Loss: 0.556282, Val Acc: 0.694915\n",
            "Epoch 800/1000, Train Loss: 0.460423, Val Loss: 0.547181, Val Acc: 0.686441\n",
            "Epoch 900/1000, Train Loss: 0.448202, Val Loss: 0.549199, Val Acc: 0.703390\n",
            "Epoch 1000/1000, Train Loss: 0.421950, Val Loss: 0.550622, Val Acc: 0.703390\n",
            "Test Loss: 0.5188000202178955 Test Accuracy: 0.7432432432432432\n",
            "weighted: Test F1: 0.5188000202178955 Test Precision: 0.7432432432432432 Test Recall: 0.7432432432432432\n",
            "[[63  8]\n",
            " [30 47]]\n",
            "[Trial 130] Test acc: 0.7432432432432432, Best val acc: 0.7288135593220338\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:08:10,781] Trial 130 finished with value: 0.7432432432432432 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006517158581451462, 'learning_rate': 0.0060929360705358395, 'num_epoch': 1000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006772863688509744}\n",
            "Epoch 100/2000, Train Loss: 0.694426, Val Loss: 0.694127, Val Acc: 0.627119\n",
            "Epoch 200/2000, Train Loss: 0.693269, Val Loss: 0.692126, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.687745, Val Loss: 0.688901, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.678383, Val Loss: 0.682107, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.664447, Val Loss: 0.668864, Val Acc: 0.635593\n",
            "Epoch 600/2000, Train Loss: 0.632762, Val Loss: 0.641261, Val Acc: 0.703390\n",
            "Epoch 700/2000, Train Loss: 0.594133, Val Loss: 0.596262, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.530036, Val Loss: 0.558135, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.493429, Val Loss: 0.538288, Val Acc: 0.703390\n",
            "Epoch 1000/2000, Train Loss: 0.460150, Val Loss: 0.532358, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.449350, Val Loss: 0.532910, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.442700, Val Loss: 0.537921, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.426357, Val Loss: 0.536702, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.433577, Val Loss: 0.539957, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.408234, Val Loss: 0.543458, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.415609, Val Loss: 0.544289, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.402836, Val Loss: 0.545325, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.412630, Val Loss: 0.547174, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.379476, Val Loss: 0.553457, Val Acc: 0.737288\n",
            "Epoch 2000/2000, Train Loss: 0.389836, Val Loss: 0.551785, Val Acc: 0.728814\n",
            "Test Loss: 0.5254396796226501 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5254396796226501 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[63  8]\n",
            " [27 50]]\n",
            "[Trial 131] Test acc: 0.7635135135135135, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:09:31,648] Trial 131 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006772863688509744, 'learning_rate': 0.004599685094508326, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006662970258374231}\n",
            "Epoch 100/2000, Train Loss: 0.694163, Val Loss: 0.694794, Val Acc: 0.601695\n",
            "Epoch 200/2000, Train Loss: 0.691868, Val Loss: 0.692280, Val Acc: 0.661017\n",
            "Epoch 300/2000, Train Loss: 0.687259, Val Loss: 0.688738, Val Acc: 0.686441\n",
            "Epoch 400/2000, Train Loss: 0.681380, Val Loss: 0.683808, Val Acc: 0.677966\n",
            "Epoch 500/2000, Train Loss: 0.671316, Val Loss: 0.676277, Val Acc: 0.677966\n",
            "Epoch 600/2000, Train Loss: 0.662957, Val Loss: 0.664322, Val Acc: 0.677966\n",
            "Epoch 700/2000, Train Loss: 0.637790, Val Loss: 0.645772, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.602875, Val Loss: 0.618923, Val Acc: 0.720339\n",
            "Epoch 900/2000, Train Loss: 0.588095, Val Loss: 0.587350, Val Acc: 0.745763\n",
            "Epoch 1000/2000, Train Loss: 0.542832, Val Loss: 0.563203, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.496064, Val Loss: 0.547827, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.470923, Val Loss: 0.541894, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.448204, Val Loss: 0.540361, Val Acc: 0.728814\n",
            "Epoch 1400/2000, Train Loss: 0.443621, Val Loss: 0.543210, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.445855, Val Loss: 0.543679, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.432942, Val Loss: 0.546484, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.427847, Val Loss: 0.543016, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.408401, Val Loss: 0.545064, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.422851, Val Loss: 0.546220, Val Acc: 0.745763\n",
            "Epoch 2000/2000, Train Loss: 0.423151, Val Loss: 0.545913, Val Acc: 0.728814\n",
            "Test Loss: 0.5359048247337341 Test Accuracy: 0.7635135135135135\n",
            "weighted: Test F1: 0.5359048247337341 Test Precision: 0.7635135135135135 Test Recall: 0.7635135135135135\n",
            "[[62  9]\n",
            " [26 51]]\n",
            "[Trial 132] Test acc: 0.7635135135135135, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:10:52,461] Trial 132 finished with value: 0.7635135135135135 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006662970258374231, 'learning_rate': 0.00344025921713248, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006731156693558143}\n",
            "Epoch 100/2000, Train Loss: 0.694254, Val Loss: 0.695018, Val Acc: 0.483051\n",
            "Epoch 200/2000, Train Loss: 0.691495, Val Loss: 0.693405, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.691036, Val Loss: 0.690826, Val Acc: 0.610169\n",
            "Epoch 400/2000, Train Loss: 0.685653, Val Loss: 0.686745, Val Acc: 0.627119\n",
            "Epoch 500/2000, Train Loss: 0.676145, Val Loss: 0.680155, Val Acc: 0.644068\n",
            "Epoch 600/2000, Train Loss: 0.664088, Val Loss: 0.669405, Val Acc: 0.677966\n",
            "Epoch 700/2000, Train Loss: 0.639961, Val Loss: 0.650618, Val Acc: 0.711864\n",
            "Epoch 800/2000, Train Loss: 0.617605, Val Loss: 0.620604, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.567131, Val Loss: 0.582834, Val Acc: 0.745763\n",
            "Epoch 1000/2000, Train Loss: 0.529867, Val Loss: 0.554705, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.494030, Val Loss: 0.540591, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.476072, Val Loss: 0.535436, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.444532, Val Loss: 0.536226, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.443073, Val Loss: 0.540434, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.453544, Val Loss: 0.543582, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.432148, Val Loss: 0.545737, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.444368, Val Loss: 0.544785, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.416196, Val Loss: 0.547193, Val Acc: 0.745763\n",
            "Epoch 1900/2000, Train Loss: 0.415414, Val Loss: 0.547694, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.419056, Val Loss: 0.554105, Val Acc: 0.720339\n",
            "Test Loss: 0.5463032126426697 Test Accuracy: 0.7702702702702703\n",
            "weighted: Test F1: 0.5463032126426697 Test Precision: 0.7702702702702703 Test Recall: 0.7702702702702703\n",
            "[[64  7]\n",
            " [27 50]]\n",
            "[Trial 133] Test acc: 0.7702702702702703, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:12:12,936] Trial 133 finished with value: 0.7702702702702703 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.006731156693558143, 'learning_rate': 0.0038609428095205114, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.00699494427309137}\n",
            "Epoch 100/2000, Train Loss: 0.693273, Val Loss: 0.692891, Val Acc: 0.627119\n",
            "Epoch 200/2000, Train Loss: 0.691374, Val Loss: 0.689252, Val Acc: 0.627119\n",
            "Epoch 300/2000, Train Loss: 0.681034, Val Loss: 0.683859, Val Acc: 0.661017\n",
            "Epoch 400/2000, Train Loss: 0.671485, Val Loss: 0.674262, Val Acc: 0.652542\n",
            "Epoch 500/2000, Train Loss: 0.653332, Val Loss: 0.656859, Val Acc: 0.686441\n",
            "Epoch 600/2000, Train Loss: 0.614878, Val Loss: 0.624976, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.560781, Val Loss: 0.583765, Val Acc: 0.694915\n",
            "Epoch 800/2000, Train Loss: 0.516641, Val Loss: 0.555630, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.461895, Val Loss: 0.545591, Val Acc: 0.728814\n",
            "Epoch 1000/2000, Train Loss: 0.446852, Val Loss: 0.543396, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.457562, Val Loss: 0.544655, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.432794, Val Loss: 0.548240, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.432019, Val Loss: 0.551197, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.416393, Val Loss: 0.550898, Val Acc: 0.737288\n",
            "Epoch 1500/2000, Train Loss: 0.416159, Val Loss: 0.553641, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.409364, Val Loss: 0.556931, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.408715, Val Loss: 0.560409, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.411754, Val Loss: 0.561261, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.390118, Val Loss: 0.563584, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.382069, Val Loss: 0.567741, Val Acc: 0.711864\n",
            "Test Loss: 0.539239764213562 Test Accuracy: 0.777027027027027\n",
            "weighted: Test F1: 0.539239764213562 Test Precision: 0.777027027027027 Test Recall: 0.777027027027027\n",
            "[[61 10]\n",
            " [23 54]]\n",
            "[Trial 134] Test acc: 0.777027027027027, Best val acc: 0.7372881355932204\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:13:34,069] Trial 134 finished with value: 0.777027027027027 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.00699494427309137, 'learning_rate': 0.004700627168105955, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007040012231269837}\n",
            "Epoch 100/2000, Train Loss: 0.694269, Val Loss: 0.694373, Val Acc: 0.576271\n",
            "Epoch 200/2000, Train Loss: 0.687748, Val Loss: 0.689717, Val Acc: 0.644068\n",
            "Epoch 300/2000, Train Loss: 0.677376, Val Loss: 0.678015, Val Acc: 0.686441\n",
            "Epoch 400/2000, Train Loss: 0.641190, Val Loss: 0.642244, Val Acc: 0.677966\n",
            "Epoch 500/2000, Train Loss: 0.557763, Val Loss: 0.578972, Val Acc: 0.762712\n",
            "Epoch 600/2000, Train Loss: 0.490576, Val Loss: 0.544078, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.454453, Val Loss: 0.542433, Val Acc: 0.720339\n",
            "Epoch 800/2000, Train Loss: 0.437317, Val Loss: 0.545778, Val Acc: 0.703390\n",
            "Epoch 900/2000, Train Loss: 0.437786, Val Loss: 0.545766, Val Acc: 0.737288\n",
            "Epoch 1000/2000, Train Loss: 0.420106, Val Loss: 0.556385, Val Acc: 0.703390\n",
            "Epoch 1100/2000, Train Loss: 0.419897, Val Loss: 0.562944, Val Acc: 0.720339\n",
            "Epoch 1200/2000, Train Loss: 0.402932, Val Loss: 0.574264, Val Acc: 0.703390\n",
            "Epoch 1300/2000, Train Loss: 0.390543, Val Loss: 0.577503, Val Acc: 0.703390\n",
            "Epoch 1400/2000, Train Loss: 0.395287, Val Loss: 0.583635, Val Acc: 0.711864\n",
            "Epoch 1500/2000, Train Loss: 0.381234, Val Loss: 0.583119, Val Acc: 0.694915\n",
            "Epoch 1600/2000, Train Loss: 0.353185, Val Loss: 0.590246, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.344655, Val Loss: 0.604807, Val Acc: 0.686441\n",
            "Epoch 1800/2000, Train Loss: 0.329665, Val Loss: 0.612964, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.306994, Val Loss: 0.651273, Val Acc: 0.703390\n",
            "Epoch 2000/2000, Train Loss: 0.284436, Val Loss: 0.655812, Val Acc: 0.711864\n",
            "Test Loss: 0.5963155031204224 Test Accuracy: 0.722972972972973\n",
            "weighted: Test F1: 0.5963155031204224 Test Precision: 0.722972972972973 Test Recall: 0.722972972972973\n",
            "[[51 20]\n",
            " [21 56]]\n",
            "[Trial 135] Test acc: 0.722972972972973, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:14:55,265] Trial 135 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.007040012231269837, 'learning_rate': 0.0070188892927513236, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'l_relu', 'lam': 0.007188992945783845}\n",
            "Epoch 100/2000, Train Loss: 0.696360, Val Loss: 0.696388, Val Acc: 0.542373\n",
            "Epoch 200/2000, Train Loss: 0.696519, Val Loss: 0.696242, Val Acc: 0.584746\n",
            "Epoch 300/2000, Train Loss: 0.696181, Val Loss: 0.696104, Val Acc: 0.593220\n",
            "Epoch 400/2000, Train Loss: 0.695854, Val Loss: 0.695900, Val Acc: 0.567797\n",
            "Epoch 500/2000, Train Loss: 0.696021, Val Loss: 0.695638, Val Acc: 0.601695\n",
            "Epoch 600/2000, Train Loss: 0.695267, Val Loss: 0.695239, Val Acc: 0.627119\n",
            "Epoch 700/2000, Train Loss: 0.694582, Val Loss: 0.694640, Val Acc: 0.644068\n",
            "Epoch 800/2000, Train Loss: 0.693361, Val Loss: 0.693684, Val Acc: 0.661017\n",
            "Epoch 900/2000, Train Loss: 0.693158, Val Loss: 0.692030, Val Acc: 0.661017\n",
            "Epoch 1000/2000, Train Loss: 0.689300, Val Loss: 0.689122, Val Acc: 0.669492\n",
            "Epoch 1100/2000, Train Loss: 0.683614, Val Loss: 0.683449, Val Acc: 0.669492\n",
            "Epoch 1200/2000, Train Loss: 0.672694, Val Loss: 0.671718, Val Acc: 0.669492\n",
            "Epoch 1300/2000, Train Loss: 0.649391, Val Loss: 0.647200, Val Acc: 0.703390\n",
            "Epoch 1400/2000, Train Loss: 0.604958, Val Loss: 0.596670, Val Acc: 0.754237\n",
            "Epoch 1500/2000, Train Loss: 0.513168, Val Loss: 0.543686, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.470450, Val Loss: 0.534340, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.441182, Val Loss: 0.533876, Val Acc: 0.720339\n",
            "Epoch 1800/2000, Train Loss: 0.440062, Val Loss: 0.538885, Val Acc: 0.728814\n",
            "Epoch 1900/2000, Train Loss: 0.431568, Val Loss: 0.538255, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.419961, Val Loss: 0.538277, Val Acc: 0.720339\n",
            "Test Loss: 0.5544795393943787 Test Accuracy: 0.75\n",
            "weighted: Test F1: 0.5544795393943787 Test Precision: 0.75 Test Recall: 0.75\n",
            "[[64  7]\n",
            " [30 47]]\n",
            "[Trial 136] Test acc: 0.75, Best val acc: 0.7542372881355932\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:16:26,235] Trial 136 finished with value: 0.75 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'l_relu', 'lam': 0.007188992945783845, 'learning_rate': 0.005247313928527471, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0069176602789504694}\n",
            "Epoch 100/200, Train Loss: 0.695026, Val Loss: 0.695847, Val Acc: 0.533898\n",
            "Epoch 200/200, Train Loss: 0.693366, Val Loss: 0.693794, Val Acc: 0.525424\n",
            "Test Loss: 0.6950463652610779 Test Accuracy: 0.5405405405405406\n",
            "weighted: Test F1: 0.6950463652610779 Test Precision: 0.5405405405405406 Test Recall: 0.5405405405405406\n",
            "[[33 38]\n",
            " [30 47]]\n",
            "[Trial 137] Test acc: 0.5405405405405406, Best val acc: 0.5338983050847458\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:16:34,577] Trial 137 finished with value: 0.5405405405405406 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0069176602789504694, 'learning_rate': 0.004304483292606738, 'num_epoch': 200}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006572903691044938}\n",
            "Epoch 100/2000, Train Loss: 0.692873, Val Loss: 0.693716, Val Acc: 0.559322\n",
            "Epoch 200/2000, Train Loss: 0.685797, Val Loss: 0.685907, Val Acc: 0.635593\n",
            "Epoch 300/2000, Train Loss: 0.651067, Val Loss: 0.661725, Val Acc: 0.669492\n",
            "Epoch 400/2000, Train Loss: 0.577479, Val Loss: 0.595247, Val Acc: 0.745763\n",
            "Epoch 500/2000, Train Loss: 0.496325, Val Loss: 0.548374, Val Acc: 0.703390\n",
            "Epoch 600/2000, Train Loss: 0.454397, Val Loss: 0.547906, Val Acc: 0.728814\n",
            "Epoch 700/2000, Train Loss: 0.443472, Val Loss: 0.549667, Val Acc: 0.728814\n",
            "Epoch 800/2000, Train Loss: 0.402094, Val Loss: 0.557975, Val Acc: 0.711864\n",
            "Epoch 900/2000, Train Loss: 0.395232, Val Loss: 0.573193, Val Acc: 0.720339\n",
            "Epoch 1000/2000, Train Loss: 0.380391, Val Loss: 0.578130, Val Acc: 0.737288\n",
            "Epoch 1100/2000, Train Loss: 0.350039, Val Loss: 0.599005, Val Acc: 0.703390\n",
            "Epoch 1200/2000, Train Loss: 0.350381, Val Loss: 0.607578, Val Acc: 0.728814\n",
            "Epoch 1300/2000, Train Loss: 0.318216, Val Loss: 0.633016, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.305110, Val Loss: 0.641863, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.280928, Val Loss: 0.669969, Val Acc: 0.737288\n",
            "Epoch 1600/2000, Train Loss: 0.264006, Val Loss: 0.702011, Val Acc: 0.720339\n",
            "Epoch 1700/2000, Train Loss: 0.252768, Val Loss: 0.727388, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.243744, Val Loss: 0.781023, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.228563, Val Loss: 0.809884, Val Acc: 0.703390\n",
            "Epoch 2000/2000, Train Loss: 0.230495, Val Loss: 0.823965, Val Acc: 0.720339\n",
            "Test Loss: 0.695517897605896 Test Accuracy: 0.7094594594594594\n",
            "weighted: Test F1: 0.695517897605896 Test Precision: 0.7094594594594594 Test Recall: 0.7094594594594594\n",
            "[[47 24]\n",
            " [19 58]]\n",
            "[Trial 138] Test acc: 0.7094594594594594, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:17:55,979] Trial 138 finished with value: 0.7094594594594594 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'relu', 'lam': 0.006572903691044938, 'learning_rate': 0.00811675372357913, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0064416858110364576}\n",
            "Epoch 100/2000, Train Loss: 0.696076, Val Loss: 0.696326, Val Acc: 0.466102\n",
            "Epoch 200/2000, Train Loss: 0.695130, Val Loss: 0.695911, Val Acc: 0.491525\n",
            "Epoch 300/2000, Train Loss: 0.694552, Val Loss: 0.695518, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.693072, Val Loss: 0.694987, Val Acc: 0.516949\n",
            "Epoch 500/2000, Train Loss: 0.691547, Val Loss: 0.694294, Val Acc: 0.525424\n",
            "Epoch 600/2000, Train Loss: 0.690716, Val Loss: 0.693381, Val Acc: 0.567797\n",
            "Epoch 700/2000, Train Loss: 0.688499, Val Loss: 0.691673, Val Acc: 0.559322\n",
            "Epoch 800/2000, Train Loss: 0.686287, Val Loss: 0.688931, Val Acc: 0.542373\n",
            "Epoch 900/2000, Train Loss: 0.679430, Val Loss: 0.684827, Val Acc: 0.550847\n",
            "Epoch 1000/2000, Train Loss: 0.670260, Val Loss: 0.678386, Val Acc: 0.576271\n",
            "Epoch 1100/2000, Train Loss: 0.661178, Val Loss: 0.669357, Val Acc: 0.593220\n",
            "Epoch 1200/2000, Train Loss: 0.646413, Val Loss: 0.656073, Val Acc: 0.644068\n",
            "Epoch 1300/2000, Train Loss: 0.620163, Val Loss: 0.637064, Val Acc: 0.686441\n",
            "Epoch 1400/2000, Train Loss: 0.607680, Val Loss: 0.612092, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.569626, Val Loss: 0.587345, Val Acc: 0.762712\n",
            "Epoch 1600/2000, Train Loss: 0.535904, Val Loss: 0.566163, Val Acc: 0.745763\n",
            "Epoch 1700/2000, Train Loss: 0.505732, Val Loss: 0.550791, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.487879, Val Loss: 0.544204, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.460225, Val Loss: 0.541423, Val Acc: 0.711864\n",
            "Epoch 2000/2000, Train Loss: 0.446026, Val Loss: 0.540293, Val Acc: 0.711864\n",
            "Test Loss: 0.5256317257881165 Test Accuracy: 0.7364864864864865\n",
            "weighted: Test F1: 0.5256317257881165 Test Precision: 0.7364864864864865 Test Recall: 0.7364864864864865\n",
            "[[62  9]\n",
            " [30 47]]\n",
            "[Trial 139] Test acc: 0.7364864864864865, Best val acc: 0.7627118644067796\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:19:16,734] Trial 139 finished with value: 0.7364864864864865 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'relu', 'lam': 0.0064416858110364576, 'learning_rate': 0.002780494914741856, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006845037963647262}\n",
            "Epoch 100/2000, Train Loss: 0.696149, Val Loss: 0.696431, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.695934, Val Loss: 0.696260, Val Acc: 0.542373\n",
            "Epoch 300/2000, Train Loss: 0.695672, Val Loss: 0.696136, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.695381, Val Loss: 0.695902, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.694627, Val Loss: 0.695533, Val Acc: 0.584746\n",
            "Epoch 600/2000, Train Loss: 0.693225, Val Loss: 0.694859, Val Acc: 0.576271\n",
            "Epoch 700/2000, Train Loss: 0.691055, Val Loss: 0.693489, Val Acc: 0.567797\n",
            "Epoch 800/2000, Train Loss: 0.684978, Val Loss: 0.690499, Val Acc: 0.593220\n",
            "Epoch 900/2000, Train Loss: 0.677618, Val Loss: 0.681489, Val Acc: 0.652542\n",
            "Epoch 1000/2000, Train Loss: 0.631336, Val Loss: 0.648074, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.548171, Val Loss: 0.577789, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.488414, Val Loss: 0.540589, Val Acc: 0.711864\n",
            "Epoch 1300/2000, Train Loss: 0.448259, Val Loss: 0.543666, Val Acc: 0.711864\n",
            "Epoch 1400/2000, Train Loss: 0.436180, Val Loss: 0.554821, Val Acc: 0.728814\n",
            "Epoch 1500/2000, Train Loss: 0.415135, Val Loss: 0.564459, Val Acc: 0.728814\n",
            "Epoch 1600/2000, Train Loss: 0.405295, Val Loss: 0.570662, Val Acc: 0.728814\n",
            "Epoch 1700/2000, Train Loss: 0.389300, Val Loss: 0.576480, Val Acc: 0.728814\n",
            "Epoch 1800/2000, Train Loss: 0.394958, Val Loss: 0.574394, Val Acc: 0.737288\n",
            "Epoch 1900/2000, Train Loss: 0.372535, Val Loss: 0.581221, Val Acc: 0.728814\n",
            "Epoch 2000/2000, Train Loss: 0.360485, Val Loss: 0.600133, Val Acc: 0.745763\n",
            "Test Loss: 0.5462905764579773 Test Accuracy: 0.7837837837837838\n",
            "weighted: Test F1: 0.5462905764579773 Test Precision: 0.7837837837837838 Test Recall: 0.7837837837837838\n",
            "[[61 10]\n",
            " [22 55]]\n",
            "[Trial 140] Test acc: 0.7837837837837838, Best val acc: 0.7457627118644068\n",
            "---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 19:20:38,118] Trial 140 finished with value: 0.7837837837837838 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.006845037963647262, 'learning_rate': 0.005643456843915773, 'num_epoch': 2000}. Best is trial 57 with value: 0.7905405405405406.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.0068412787476224}\n",
            "Epoch 100/2000, Train Loss: 0.696541, Val Loss: 0.696296, Val Acc: 0.584746\n",
            "Epoch 200/2000, Train Loss: 0.696408, Val Loss: 0.696078, Val Acc: 0.618644\n",
            "Epoch 300/2000, Train Loss: 0.696245, Val Loss: 0.695912, Val Acc: 0.652542\n",
            "Epoch 400/2000, Train Loss: 0.696059, Val Loss: 0.695794, Val Acc: 0.677966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MROMTXcU4-Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.trial_logs"
      ],
      "metadata": {
        "id": "2hTwWHApMRdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Сохраняем в JSON\n",
        "with open(\"trial_logs.json\", \"w\") as f:\n",
        "    json.dump(clf.trial_logs, f, indent=4)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('trial_logs.json')"
      ],
      "metadata": {
        "id": "A9o_O9U-Utx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the locally sparse model\n",
        "device = get_device()\n",
        "\n",
        "# Initialize the model\n",
        "clf = LocallySparse(data=data_norm, n_classes=2)\n",
        "\n",
        "# Set up model parameters\n",
        "clf.create_model(feature_selection=True)\n",
        "\n",
        "# Optimize model hyperparameters\n",
        "clf.optimize(n_trials=250, n_jobs=1)\n",
        "\n",
        "# Generate and save result visualizations\n",
        "clf.get_results()\n",
        "\n",
        "# Save the trained model\n",
        "clf.save_model()\n",
        "\n",
        "#old logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zy0GmVMwGjyT",
        "outputId": "f5864fad-5180-4539-edc4-d63215dfdb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:44:34,149] A new study created in memory with name: no-name-fdc310f0-08fe-4e4a-9ba2-c38b85f19b28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: Tesla T4\n",
            "Using device: cuda\n",
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'sigmoid', 'lam': 0.0088116660810683}\n",
            "Epoch 100/500, Train Loss: 0.698867, Val Loss: 0.696261, Val Acc: 0.525424\n",
            "Epoch 200/500, Train Loss: 0.697818, Val Loss: 0.696661, Val Acc: 0.525424\n",
            "Epoch 300/500, Train Loss: 0.697649, Val Loss: 0.697099, Val Acc: 0.525424\n",
            "Epoch 400/500, Train Loss: 0.697561, Val Loss: 0.697314, Val Acc: 0.525424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:45:02,582] Trial 0 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'sigmoid', 'lam': 0.0088116660810683, 'learning_rate': 0.00030001975479687014, 'num_epoch': 500}. Best is trial 0 with value: 0.4797297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/500, Train Loss: 0.697568, Val Loss: 0.697449, Val Acc: 0.525424\n",
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.009212716555321767}\n",
            "Epoch 100/500, Train Loss: 0.697918, Val Loss: 0.697872, Val Acc: 0.381356\n",
            "Epoch 200/500, Train Loss: 0.697882, Val Loss: 0.698051, Val Acc: 0.474576\n",
            "Epoch 300/500, Train Loss: 0.697820, Val Loss: 0.697548, Val Acc: 0.525424\n",
            "Epoch 400/500, Train Loss: 0.698169, Val Loss: 0.697621, Val Acc: 0.525424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:45:22,879] Trial 1 finished with value: 0.5135135135135135 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.009212716555321767, 'learning_rate': 0.00560560635458387, 'num_epoch': 500}. Best is trial 1 with value: 0.5135135135135135.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/500, Train Loss: 0.697876, Val Loss: 0.697835, Val Acc: 0.474576\n",
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.0067626260483382925}\n",
            "Epoch 100/1500, Train Loss: 0.696588, Val Loss: 0.696503, Val Acc: 0.474576\n",
            "Epoch 200/1500, Train Loss: 0.696575, Val Loss: 0.696442, Val Acc: 0.525424\n",
            "Epoch 300/1500, Train Loss: 0.696541, Val Loss: 0.696442, Val Acc: 0.533898\n",
            "Epoch 400/1500, Train Loss: 0.696567, Val Loss: 0.696479, Val Acc: 0.508475\n",
            "Epoch 500/1500, Train Loss: 0.696504, Val Loss: 0.696473, Val Acc: 0.533898\n",
            "Epoch 600/1500, Train Loss: 0.696454, Val Loss: 0.696517, Val Acc: 0.508475\n",
            "Epoch 700/1500, Train Loss: 0.696430, Val Loss: 0.696498, Val Acc: 0.508475\n",
            "Epoch 800/1500, Train Loss: 0.696461, Val Loss: 0.696492, Val Acc: 0.533898\n",
            "Epoch 900/1500, Train Loss: 0.696421, Val Loss: 0.696467, Val Acc: 0.542373\n",
            "Epoch 1000/1500, Train Loss: 0.696495, Val Loss: 0.696510, Val Acc: 0.491525\n",
            "Epoch 1100/1500, Train Loss: 0.696385, Val Loss: 0.696471, Val Acc: 0.550847\n",
            "Epoch 1200/1500, Train Loss: 0.696383, Val Loss: 0.696481, Val Acc: 0.576271\n",
            "Epoch 1300/1500, Train Loss: 0.696370, Val Loss: 0.696461, Val Acc: 0.533898\n",
            "Epoch 1400/1500, Train Loss: 0.696424, Val Loss: 0.696466, Val Acc: 0.559322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:46:29,105] Trial 2 finished with value: 0.5067567567567568 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.0067626260483382925, 'learning_rate': 0.001767542643047017, 'num_epoch': 1500}. Best is trial 1 with value: 0.5135135135135135.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500/1500, Train Loss: 0.696508, Val Loss: 0.696449, Val Acc: 0.559322\n",
            "{'input_node': 18, 'output_node': 2, 'feature_selection': True, 'activation_gating': 'tanh', 'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.005892462432875085}\n",
            "Epoch 100/2000, Train Loss: 0.696000, Val Loss: 0.696057, Val Acc: 0.474576\n",
            "Epoch 200/2000, Train Loss: 0.696003, Val Loss: 0.696047, Val Acc: 0.483051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2025-06-14 15:46:39,023] Trial 3 failed with parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'relu', 'lam': 0.005892462432875085, 'learning_rate': 0.00010997743359536784, 'num_epoch': 2000} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-35-1225702920>\", line 429, in __objective\n",
            "    _, _, _ = self.train_model(\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-35-1225702920>\", line 323, in train_model\n",
            "    for x_batch, y_batch, z_batch in train_loader:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 704, in __next__\n",
            "    with torch.autograd.profiler.record_function(self._profile_name):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py\", line 752, in __enter__\n",
            "    self.record = torch.ops.profiler._record_function_enter_new(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_ops.py\", line 1123, in __call__\n",
            "    return self._op(*args, **(kwargs or {}))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-06-14 15:46:39,028] Trial 3 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-567933576>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Optimize model hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Generate and save result visualizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1225702920>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_trials, n_jobs)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# Get best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1225702920>\u001b[0m in \u001b[0;36m__objective\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         _, _, _ = self.train_model(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1225702920>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, optimizer, criterion, train_loader, val_loader, epochs, compute_sim)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         self.record = torch.ops.profiler._record_function_enter_new(\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the locally sparse model\n",
        "device = get_device()\n",
        "\n",
        "# Initialize the model\n",
        "clf = LocallySparse(data=data_norm, n_classes=2)\n",
        "\n",
        "# Set up model parameters\n",
        "clf.create_model(feature_selection=True)\n",
        "\n",
        "# Optimize model hyperparameters\n",
        "clf.optimize(n_trials=250, n_jobs=1)\n",
        "\n",
        "# Generate and save result visualizations\n",
        "clf.get_results()\n",
        "\n",
        "# Save the trained model\n",
        "clf.save_model()\n",
        "\n",
        "#old logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FWBor1sk7SFW",
        "outputId": "b7e35a22-6cf6-4f93-a91c-eb5f4d192c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:27:54,301] A new study created in memory with name: no-name-9242693f-84f7-4d27-8d73-67b674c7fe76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: Tesla T4\n",
            "Using device: cuda\n",
            "Epoch 100/1000, Train Loss: 0.697431, Val Loss: 0.697427, Val Acc: 0.533898\n",
            "Epoch 200/1000, Train Loss: 0.697398, Val Loss: 0.697432, Val Acc: 0.491525\n",
            "Epoch 300/1000, Train Loss: 0.697394, Val Loss: 0.697409, Val Acc: 0.542373\n",
            "Epoch 400/1000, Train Loss: 0.697395, Val Loss: 0.697405, Val Acc: 0.542373\n",
            "Epoch 500/1000, Train Loss: 0.697423, Val Loss: 0.697416, Val Acc: 0.500000\n",
            "Epoch 600/1000, Train Loss: 0.697349, Val Loss: 0.697386, Val Acc: 0.559322\n",
            "Epoch 700/1000, Train Loss: 0.697375, Val Loss: 0.697373, Val Acc: 0.542373\n",
            "Epoch 800/1000, Train Loss: 0.697360, Val Loss: 0.697400, Val Acc: 0.516949\n",
            "Epoch 900/1000, Train Loss: 0.697346, Val Loss: 0.697381, Val Acc: 0.593220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:28:40,055] Trial 0 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'l_relu', 'lam': 0.008570572123184622, 'learning_rate': 0.0012115288725070266, 'num_epoch': 1000}. Best is trial 0 with value: 0.4797297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000/1000, Train Loss: 0.697367, Val Loss: 0.697363, Val Acc: 0.576271\n",
            "Epoch 100/2000, Train Loss: 0.694288, Val Loss: 0.695952, Val Acc: 0.533898\n",
            "Epoch 200/2000, Train Loss: 0.691712, Val Loss: 0.693614, Val Acc: 0.576271\n",
            "Epoch 300/2000, Train Loss: 0.686780, Val Loss: 0.690565, Val Acc: 0.635593\n",
            "Epoch 400/2000, Train Loss: 0.681601, Val Loss: 0.686527, Val Acc: 0.661017\n",
            "Epoch 500/2000, Train Loss: 0.674212, Val Loss: 0.680995, Val Acc: 0.677966\n",
            "Epoch 600/2000, Train Loss: 0.665435, Val Loss: 0.673271, Val Acc: 0.686441\n",
            "Epoch 700/2000, Train Loss: 0.652623, Val Loss: 0.662609, Val Acc: 0.677966\n",
            "Epoch 800/2000, Train Loss: 0.630983, Val Loss: 0.647426, Val Acc: 0.694915\n",
            "Epoch 900/2000, Train Loss: 0.613719, Val Loss: 0.627299, Val Acc: 0.703390\n",
            "Epoch 1000/2000, Train Loss: 0.588473, Val Loss: 0.602228, Val Acc: 0.720339\n",
            "Epoch 1100/2000, Train Loss: 0.559886, Val Loss: 0.580894, Val Acc: 0.711864\n",
            "Epoch 1200/2000, Train Loss: 0.535864, Val Loss: 0.566383, Val Acc: 0.720339\n",
            "Epoch 1300/2000, Train Loss: 0.502576, Val Loss: 0.555220, Val Acc: 0.720339\n",
            "Epoch 1400/2000, Train Loss: 0.491384, Val Loss: 0.548882, Val Acc: 0.720339\n",
            "Epoch 1500/2000, Train Loss: 0.484446, Val Loss: 0.547513, Val Acc: 0.711864\n",
            "Epoch 1600/2000, Train Loss: 0.472020, Val Loss: 0.547108, Val Acc: 0.703390\n",
            "Epoch 1700/2000, Train Loss: 0.464616, Val Loss: 0.549298, Val Acc: 0.711864\n",
            "Epoch 1800/2000, Train Loss: 0.482656, Val Loss: 0.551254, Val Acc: 0.720339\n",
            "Epoch 1900/2000, Train Loss: 0.450774, Val Loss: 0.548629, Val Acc: 0.720339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:30:09,101] Trial 1 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.006088131829751003, 'learning_rate': 0.0024120189000188196, 'num_epoch': 2000}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000/2000, Train Loss: 0.467277, Val Loss: 0.551972, Val Acc: 0.720339\n",
            "Epoch 100/2000, Train Loss: 0.698779, Val Loss: 0.695313, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.697225, Val Loss: 0.695460, Val Acc: 0.525424\n",
            "Epoch 300/2000, Train Loss: 0.696625, Val Loss: 0.695922, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.696573, Val Loss: 0.696199, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.696559, Val Loss: 0.696363, Val Acc: 0.525424\n",
            "Epoch 600/2000, Train Loss: 0.696548, Val Loss: 0.696462, Val Acc: 0.525424\n",
            "Epoch 700/2000, Train Loss: 0.696549, Val Loss: 0.696489, Val Acc: 0.525424\n",
            "Epoch 800/2000, Train Loss: 0.696537, Val Loss: 0.696515, Val Acc: 0.525424\n",
            "Epoch 900/2000, Train Loss: 0.696560, Val Loss: 0.696526, Val Acc: 0.525424\n",
            "Epoch 1000/2000, Train Loss: 0.696545, Val Loss: 0.696554, Val Acc: 0.474576\n",
            "Epoch 1100/2000, Train Loss: 0.696539, Val Loss: 0.696550, Val Acc: 0.474576\n",
            "Epoch 1200/2000, Train Loss: 0.696540, Val Loss: 0.696542, Val Acc: 0.474576\n",
            "Epoch 1300/2000, Train Loss: 0.696536, Val Loss: 0.696538, Val Acc: 0.500000\n",
            "Epoch 1400/2000, Train Loss: 0.696546, Val Loss: 0.696526, Val Acc: 0.525424\n",
            "Epoch 1500/2000, Train Loss: 0.696547, Val Loss: 0.696532, Val Acc: 0.533898\n",
            "Epoch 1600/2000, Train Loss: 0.696547, Val Loss: 0.696552, Val Acc: 0.474576\n",
            "Epoch 1700/2000, Train Loss: 0.696543, Val Loss: 0.696556, Val Acc: 0.474576\n",
            "Epoch 1800/2000, Train Loss: 0.696547, Val Loss: 0.696558, Val Acc: 0.474576\n",
            "Epoch 1900/2000, Train Loss: 0.696541, Val Loss: 0.696548, Val Acc: 0.474576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:31:37,159] Trial 2 finished with value: 0.5202702702702703 and parameters: {'hidden_layers_node': [50, 20, 10], 'gating_net_hidden_layers_node': [8, 2], 'activation_pred': 'sigmoid', 'lam': 0.0067899880670510655, 'learning_rate': 0.00028461007278087885, 'num_epoch': 2000}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000/2000, Train Loss: 0.696543, Val Loss: 0.696547, Val Acc: 0.474576\n",
            "Epoch 100/200, Train Loss: 0.696728, Val Loss: 0.696641, Val Acc: 0.533898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:31:45,230] Trial 3 finished with value: 0.49324324324324326 and parameters: {'hidden_layers_node': [70, 20], 'gating_net_hidden_layers_node': [2, 2], 'activation_pred': 'sigmoid', 'lam': 0.007218746247524108, 'learning_rate': 0.0018101869232163476, 'num_epoch': 200}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200/200, Train Loss: 0.696611, Val Loss: 0.696596, Val Acc: 0.559322\n",
            "Epoch 100/2000, Train Loss: 0.696789, Val Loss: 0.696875, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.696899, Val Loss: 0.696748, Val Acc: 0.550847\n",
            "Epoch 300/2000, Train Loss: 0.696859, Val Loss: 0.696709, Val Acc: 0.559322\n",
            "Epoch 400/2000, Train Loss: 0.696799, Val Loss: 0.696715, Val Acc: 0.593220\n",
            "Epoch 500/2000, Train Loss: 0.696827, Val Loss: 0.696718, Val Acc: 0.576271\n",
            "Epoch 600/2000, Train Loss: 0.696667, Val Loss: 0.696666, Val Acc: 0.593220\n",
            "Epoch 700/2000, Train Loss: 0.696752, Val Loss: 0.696573, Val Acc: 0.627119\n",
            "Epoch 800/2000, Train Loss: 0.696636, Val Loss: 0.696574, Val Acc: 0.610169\n",
            "Epoch 900/2000, Train Loss: 0.696508, Val Loss: 0.696527, Val Acc: 0.610169\n",
            "Epoch 1000/2000, Train Loss: 0.696454, Val Loss: 0.696430, Val Acc: 0.627119\n",
            "Epoch 1100/2000, Train Loss: 0.696489, Val Loss: 0.696382, Val Acc: 0.618644\n",
            "Epoch 1200/2000, Train Loss: 0.696451, Val Loss: 0.696342, Val Acc: 0.601695\n",
            "Epoch 1300/2000, Train Loss: 0.696402, Val Loss: 0.696257, Val Acc: 0.618644\n",
            "Epoch 1400/2000, Train Loss: 0.696408, Val Loss: 0.696190, Val Acc: 0.618644\n",
            "Epoch 1500/2000, Train Loss: 0.696300, Val Loss: 0.696090, Val Acc: 0.618644\n",
            "Epoch 1600/2000, Train Loss: 0.696374, Val Loss: 0.696010, Val Acc: 0.627119\n",
            "Epoch 1700/2000, Train Loss: 0.696465, Val Loss: 0.695893, Val Acc: 0.652542\n",
            "Epoch 1800/2000, Train Loss: 0.695890, Val Loss: 0.695780, Val Acc: 0.635593\n",
            "Epoch 1900/2000, Train Loss: 0.695913, Val Loss: 0.695605, Val Acc: 0.644068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:33:19,039] Trial 4 finished with value: 0.5675675675675675 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'l_relu', 'lam': 0.0075396428346099515, 'learning_rate': 0.0031031939750717076, 'num_epoch': 2000}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000/2000, Train Loss: 0.695721, Val Loss: 0.695391, Val Acc: 0.661017\n",
            "Epoch 100/200, Train Loss: 0.696875, Val Loss: 0.696853, Val Acc: 0.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:33:27,768] Trial 5 finished with value: 0.5135135135135135 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'tanh', 'lam': 0.007287453309872219, 'learning_rate': 0.0006868170426281215, 'num_epoch': 200}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200/200, Train Loss: 0.696890, Val Loss: 0.696851, Val Acc: 0.491525\n",
            "Epoch 100/2000, Train Loss: 0.697669, Val Loss: 0.695573, Val Acc: 0.525424\n",
            "Epoch 200/2000, Train Loss: 0.697526, Val Loss: 0.695668, Val Acc: 0.525424\n",
            "Epoch 300/2000, Train Loss: 0.697248, Val Loss: 0.695785, Val Acc: 0.525424\n",
            "Epoch 400/2000, Train Loss: 0.697026, Val Loss: 0.695908, Val Acc: 0.525424\n",
            "Epoch 500/2000, Train Loss: 0.696962, Val Loss: 0.696022, Val Acc: 0.525424\n",
            "Epoch 600/2000, Train Loss: 0.696928, Val Loss: 0.696132, Val Acc: 0.525424\n",
            "Epoch 700/2000, Train Loss: 0.696848, Val Loss: 0.696235, Val Acc: 0.525424\n",
            "Epoch 800/2000, Train Loss: 0.696876, Val Loss: 0.696319, Val Acc: 0.525424\n",
            "Epoch 900/2000, Train Loss: 0.696831, Val Loss: 0.696393, Val Acc: 0.525424\n",
            "Epoch 1000/2000, Train Loss: 0.696806, Val Loss: 0.696457, Val Acc: 0.525424\n",
            "Epoch 1100/2000, Train Loss: 0.696819, Val Loss: 0.696509, Val Acc: 0.525424\n",
            "Epoch 1200/2000, Train Loss: 0.696831, Val Loss: 0.696553, Val Acc: 0.525424\n",
            "Epoch 1300/2000, Train Loss: 0.696845, Val Loss: 0.696591, Val Acc: 0.525424\n",
            "Epoch 1400/2000, Train Loss: 0.696804, Val Loss: 0.696632, Val Acc: 0.525424\n",
            "Epoch 1500/2000, Train Loss: 0.696769, Val Loss: 0.696654, Val Acc: 0.525424\n",
            "Epoch 1600/2000, Train Loss: 0.696839, Val Loss: 0.696686, Val Acc: 0.525424\n",
            "Epoch 1700/2000, Train Loss: 0.696848, Val Loss: 0.696706, Val Acc: 0.525424\n",
            "Epoch 1800/2000, Train Loss: 0.696813, Val Loss: 0.696723, Val Acc: 0.525424\n",
            "Epoch 1900/2000, Train Loss: 0.696807, Val Loss: 0.696730, Val Acc: 0.516949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:34:51,515] Trial 6 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [50, 10], 'gating_net_hidden_layers_node': [20, 10], 'activation_pred': 'sigmoid', 'lam': 0.007367762356841888, 'learning_rate': 6.893697249860774e-05, 'num_epoch': 2000}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000/2000, Train Loss: 0.696808, Val Loss: 0.696737, Val Acc: 0.516949\n",
            "Epoch 100/2000, Train Loss: 0.697957, Val Loss: 0.698134, Val Acc: 0.466102\n",
            "Epoch 200/2000, Train Loss: 0.697745, Val Loss: 0.698130, Val Acc: 0.466102\n",
            "Epoch 300/2000, Train Loss: 0.697872, Val Loss: 0.698127, Val Acc: 0.466102\n",
            "Epoch 400/2000, Train Loss: 0.698010, Val Loss: 0.698122, Val Acc: 0.449153\n",
            "Epoch 500/2000, Train Loss: 0.697742, Val Loss: 0.698120, Val Acc: 0.457627\n",
            "Epoch 600/2000, Train Loss: 0.698039, Val Loss: 0.698114, Val Acc: 0.457627\n",
            "Epoch 700/2000, Train Loss: 0.697884, Val Loss: 0.698111, Val Acc: 0.457627\n",
            "Epoch 800/2000, Train Loss: 0.697806, Val Loss: 0.698109, Val Acc: 0.449153\n",
            "Epoch 900/2000, Train Loss: 0.697934, Val Loss: 0.698107, Val Acc: 0.449153\n",
            "Epoch 1000/2000, Train Loss: 0.697794, Val Loss: 0.698106, Val Acc: 0.449153\n",
            "Epoch 1100/2000, Train Loss: 0.697816, Val Loss: 0.698103, Val Acc: 0.449153\n",
            "Epoch 1200/2000, Train Loss: 0.697875, Val Loss: 0.698099, Val Acc: 0.449153\n",
            "Epoch 1300/2000, Train Loss: 0.698058, Val Loss: 0.698096, Val Acc: 0.449153\n",
            "Epoch 1400/2000, Train Loss: 0.697863, Val Loss: 0.698094, Val Acc: 0.457627\n",
            "Epoch 1500/2000, Train Loss: 0.697622, Val Loss: 0.698092, Val Acc: 0.474576\n",
            "Epoch 1600/2000, Train Loss: 0.698012, Val Loss: 0.698090, Val Acc: 0.474576\n",
            "Epoch 1700/2000, Train Loss: 0.698036, Val Loss: 0.698088, Val Acc: 0.483051\n",
            "Epoch 1800/2000, Train Loss: 0.697655, Val Loss: 0.698087, Val Acc: 0.474576\n",
            "Epoch 1900/2000, Train Loss: 0.697971, Val Loss: 0.698085, Val Acc: 0.474576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:36:08,042] Trial 7 finished with value: 0.49324324324324326 and parameters: {'hidden_layers_node': [10, 5], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'tanh', 'lam': 0.009395315796895691, 'learning_rate': 5.575403555443914e-05, 'num_epoch': 2000}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2000/2000, Train Loss: 0.697808, Val Loss: 0.698080, Val Acc: 0.491525\n",
            "Epoch 100/500, Train Loss: 0.698269, Val Loss: 0.695082, Val Acc: 0.525424\n",
            "Epoch 200/500, Train Loss: 0.697212, Val Loss: 0.695050, Val Acc: 0.525424\n",
            "Epoch 300/500, Train Loss: 0.696397, Val Loss: 0.695257, Val Acc: 0.525424\n",
            "Epoch 400/500, Train Loss: 0.696536, Val Loss: 0.695502, Val Acc: 0.525424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:36:28,696] Trial 8 finished with value: 0.4797297297297297 and parameters: {'hidden_layers_node': [10, 10, 10], 'gating_net_hidden_layers_node': [8], 'activation_pred': 'sigmoid', 'lam': 0.006299497114587912, 'learning_rate': 0.0001542169672675274, 'num_epoch': 500}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/500, Train Loss: 0.696448, Val Loss: 0.695713, Val Acc: 0.525424\n",
            "Epoch 100/500, Train Loss: 0.696544, Val Loss: 0.696699, Val Acc: 0.483051\n",
            "Epoch 200/500, Train Loss: 0.696540, Val Loss: 0.696687, Val Acc: 0.483051\n",
            "Epoch 300/500, Train Loss: 0.696512, Val Loss: 0.696680, Val Acc: 0.483051\n",
            "Epoch 400/500, Train Loss: 0.696498, Val Loss: 0.696683, Val Acc: 0.457627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:36:50,291] Trial 9 finished with value: 0.5 and parameters: {'hidden_layers_node': [40, 20, 10], 'gating_net_hidden_layers_node': [4, 4], 'activation_pred': 'relu', 'lam': 0.0068837133940546765, 'learning_rate': 0.0013004282888372676, 'num_epoch': 500}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/500, Train Loss: 0.696451, Val Loss: 0.696678, Val Acc: 0.440678\n",
            "Epoch 100/1500, Train Loss: 0.686376, Val Loss: 0.688245, Val Acc: 0.576271\n",
            "Epoch 200/1500, Train Loss: 0.653054, Val Loss: 0.658579, Val Acc: 0.652542\n",
            "Epoch 300/1500, Train Loss: 0.569028, Val Loss: 0.577642, Val Acc: 0.745763\n",
            "Epoch 400/1500, Train Loss: 0.494375, Val Loss: 0.544868, Val Acc: 0.720339\n",
            "Epoch 500/1500, Train Loss: 0.467915, Val Loss: 0.545812, Val Acc: 0.711864\n",
            "Epoch 600/1500, Train Loss: 0.447219, Val Loss: 0.553300, Val Acc: 0.728814\n",
            "Epoch 700/1500, Train Loss: 0.441149, Val Loss: 0.559984, Val Acc: 0.720339\n",
            "Epoch 800/1500, Train Loss: 0.442058, Val Loss: 0.563688, Val Acc: 0.728814\n",
            "Epoch 900/1500, Train Loss: 0.443772, Val Loss: 0.569212, Val Acc: 0.737288\n",
            "Epoch 1000/1500, Train Loss: 0.436717, Val Loss: 0.569453, Val Acc: 0.737288\n",
            "Epoch 1100/1500, Train Loss: 0.436288, Val Loss: 0.575625, Val Acc: 0.728814\n",
            "Epoch 1200/1500, Train Loss: 0.425963, Val Loss: 0.573631, Val Acc: 0.737288\n",
            "Epoch 1300/1500, Train Loss: 0.444640, Val Loss: 0.569268, Val Acc: 0.728814\n",
            "Epoch 1400/1500, Train Loss: 0.434268, Val Loss: 0.574240, Val Acc: 0.737288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:37:55,470] Trial 10 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.005068418755265379, 'learning_rate': 0.009669238778082855, 'num_epoch': 1500}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500/1500, Train Loss: 0.430159, Val Loss: 0.574879, Val Acc: 0.745763\n",
            "Epoch 100/1500, Train Loss: 0.662595, Val Loss: 0.675039, Val Acc: 0.686441\n",
            "Epoch 200/1500, Train Loss: 0.573550, Val Loss: 0.600297, Val Acc: 0.720339\n",
            "Epoch 300/1500, Train Loss: 0.494824, Val Loss: 0.547249, Val Acc: 0.694915\n",
            "Epoch 400/1500, Train Loss: 0.461200, Val Loss: 0.550744, Val Acc: 0.720339\n",
            "Epoch 500/1500, Train Loss: 0.435447, Val Loss: 0.553671, Val Acc: 0.720339\n",
            "Epoch 600/1500, Train Loss: 0.439538, Val Loss: 0.559392, Val Acc: 0.728814\n",
            "Epoch 700/1500, Train Loss: 0.447522, Val Loss: 0.565686, Val Acc: 0.728814\n",
            "Epoch 800/1500, Train Loss: 0.441381, Val Loss: 0.561178, Val Acc: 0.720339\n",
            "Epoch 900/1500, Train Loss: 0.433727, Val Loss: 0.567580, Val Acc: 0.737288\n",
            "Epoch 1000/1500, Train Loss: 0.451593, Val Loss: 0.567399, Val Acc: 0.737288\n",
            "Epoch 1100/1500, Train Loss: 0.441102, Val Loss: 0.565223, Val Acc: 0.728814\n",
            "Epoch 1200/1500, Train Loss: 0.428157, Val Loss: 0.568244, Val Acc: 0.745763\n",
            "Epoch 1300/1500, Train Loss: 0.430779, Val Loss: 0.565237, Val Acc: 0.728814\n",
            "Epoch 1400/1500, Train Loss: 0.428233, Val Loss: 0.568845, Val Acc: 0.728814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:39:05,020] Trial 11 finished with value: 0.722972972972973 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.005131192050478897, 'learning_rate': 0.009990181985584184, 'num_epoch': 1500}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500/1500, Train Loss: 0.431489, Val Loss: 0.581375, Val Acc: 0.728814\n",
            "Epoch 100/1500, Train Loss: 0.687180, Val Loss: 0.690505, Val Acc: 0.618644\n",
            "Epoch 200/1500, Train Loss: 0.659255, Val Loss: 0.671924, Val Acc: 0.686441\n",
            "Epoch 300/1500, Train Loss: 0.584359, Val Loss: 0.616424, Val Acc: 0.728814\n",
            "Epoch 400/1500, Train Loss: 0.517733, Val Loss: 0.554205, Val Acc: 0.711864\n",
            "Epoch 500/1500, Train Loss: 0.473903, Val Loss: 0.545436, Val Acc: 0.711864\n",
            "Epoch 600/1500, Train Loss: 0.454636, Val Loss: 0.552154, Val Acc: 0.728814\n",
            "Epoch 700/1500, Train Loss: 0.435938, Val Loss: 0.555290, Val Acc: 0.720339\n",
            "Epoch 800/1500, Train Loss: 0.451470, Val Loss: 0.559459, Val Acc: 0.737288\n",
            "Epoch 900/1500, Train Loss: 0.431627, Val Loss: 0.563123, Val Acc: 0.728814\n",
            "Epoch 1000/1500, Train Loss: 0.448157, Val Loss: 0.566474, Val Acc: 0.737288\n",
            "Epoch 1100/1500, Train Loss: 0.437435, Val Loss: 0.567459, Val Acc: 0.737288\n",
            "Epoch 1200/1500, Train Loss: 0.441559, Val Loss: 0.570003, Val Acc: 0.728814\n",
            "Epoch 1300/1500, Train Loss: 0.442732, Val Loss: 0.569337, Val Acc: 0.728814\n",
            "Epoch 1400/1500, Train Loss: 0.426314, Val Loss: 0.578721, Val Acc: 0.728814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-14 15:40:22,487] Trial 12 finished with value: 0.7297297297297297 and parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.005052839611909299, 'learning_rate': 0.008464775375021192, 'num_epoch': 1500}. Best is trial 1 with value: 0.7297297297297297.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1500/1500, Train Loss: 0.425425, Val Loss: 0.583897, Val Acc: 0.737288\n",
            "Epoch 100/1500, Train Loss: 0.691099, Val Loss: 0.690772, Val Acc: 0.576271\n",
            "Epoch 200/1500, Train Loss: 0.681774, Val Loss: 0.683357, Val Acc: 0.618644\n",
            "Epoch 300/1500, Train Loss: 0.658289, Val Loss: 0.669756, Val Acc: 0.652542\n",
            "Epoch 400/1500, Train Loss: 0.644577, Val Loss: 0.645698, Val Acc: 0.711864\n",
            "Epoch 500/1500, Train Loss: 0.593297, Val Loss: 0.608662, Val Acc: 0.728814\n",
            "Epoch 600/1500, Train Loss: 0.542519, Val Loss: 0.572245, Val Acc: 0.720339\n",
            "Epoch 700/1500, Train Loss: 0.516724, Val Loss: 0.551672, Val Acc: 0.728814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2025-06-14 15:40:57,113] Trial 13 failed with parameters: {'hidden_layers_node': [100, 20], 'gating_net_hidden_layers_node': [2, 2, 2], 'activation_pred': 'tanh', 'lam': 0.005725920403100939, 'learning_rate': 0.004136140592470334, 'num_epoch': 1500} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-26-2909853089>\", line 427, in __objective\n",
            "    _, _, _ = self.train_model(\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-26-2909853089>\", line 335, in train_model\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-06-14 15:40:57,117] Trial 13 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-567933576>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Optimize model hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Generate and save result visualizations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2909853089>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, n_trials, n_jobs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;31m# Get best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2909853089>\u001b[0m in \u001b[0;36m__objective\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         _, _, _ = self.train_model(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2909853089>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, optimizer, criterion, train_loader, val_loader, epochs, compute_sim)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;31m# Backward pass and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if X_test is not None:\n",
        "        print(\"Evaluating on test dataset...\")\n",
        "\n",
        "        # Prepare test data\n",
        "        if 'Прогрессия' in X_test.columns:\n",
        "            y_test = X_test.pop('Прогрессия')\n",
        "            X_test_features = X_test\n",
        "        else:\n",
        "            X_test_features = X_test\n",
        "            y_test = None\n",
        "\n",
        "        # Make predictions if we have labels to compare against\n",
        "        if y_test is not None:\n",
        "            # Convert to PyTorch tensors\n",
        "            X_test_tensor = torch.FloatTensor(X_test_features.values).to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            clf.best_model.eval()\n",
        "            with torch.no_grad():\n",
        "                predictions, _ = clf.best_model(X_test_tensor, train_gates=False)\n",
        "                y_pred = torch.argmax(predictions, dim=1).cpu().numpy()\n",
        "\n",
        "            # Calculate and print metrics\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "            precision = precision_score(y_test, y_pred, average='weighted')\n",
        "            recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "            print(f\"Test dataset results:\")\n",
        "            print(f\"Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"F1 Score: {f1:.4f}\")\n",
        "            print(f\"Precision: {precision:.4f}\")\n",
        "            print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "            # Generate confusion matrix\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "            plt.title('Confusion Matrix on Test Dataset')\n",
        "            plt.ylabel('True Label')\n",
        "            plt.xlabel('Predicted Label')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(\"results\", \"test_confusion_matrix.png\"))\n",
        "            plt.close()\n",
        "\n",
        "            # Print classification report\n",
        "            print(\"\\nClassification Report:\")\n",
        "            print(classification_report(y_test, y_pred))\n",
        "\n",
        "            # Save test results\n",
        "            with open(os.path.join(\"results\", 'test_results.txt'), \"w\") as file:\n",
        "                file.write(f\"Test Accuracy: {accuracy:.4f}\\n\")\n",
        "                file.write(f\"Test F1 Score: {f1:.4f}\\n\")\n",
        "                file.write(f\"Test Precision: {precision:.4f}\\n\")\n",
        "                file.write(f\"Test Recall: {recall:.4f}\\n\\n\")\n",
        "                file.write(\"Classification Report:\\n\")\n",
        "                file.write(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "v9D5fpVREmwj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}